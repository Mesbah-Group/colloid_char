{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Summary\n",
    "\n",
    "The following code reduces the dimensionality of structural and compositional neighborhood graphs and uses agglomerative hierarchical clustering to partition the low-dimensional spaces and assign classifications to the resulting partitions\n",
    "\n",
    "Specifically, this code:\n",
    "\n",
    "**(1)** Takes as input \".gdv\" files and \"vapor.npy\" files that (i) contain structural and compositional neighborhood graphs and (ii) identify vapor particles. These files can describe multiple trajectories with particles that have different interaction potentials, sizes, etc. Note that the corresponding \".xyz\" files should be in the same folder.\n",
    "\n",
    "**(2)** Trains a deep neural network called an \"autoencoder\" (using only the unique neighborhood graphs). An \"encoder\" is extracted from the \"autoencoder\" and is then used for dimensionality reduction. Note that both \"structural\" and \"compositional\" autoencoders/encoders are created.\n",
    "\n",
    "**(3)** Uses agglomerative hierarchical clustering (via Ward's linkage) to partition the structural and compositional low-dimensional spaces and assign classifications to the resulting partitions.\n",
    "\n",
    "**(4)** Modifies the \".xyz\" files such that individual particles are colored according to their discrete classifications. These \".xyz\" files can be visualized in OVITO. Qualitative analyses of these images can provide a general idea of what each class physically represents.\n",
    "\n",
    "**Note**: Example data and results of this entire framework can be found in the \"Example\" folder. This folder contains a \"filled out\" example of this code (called Train_example.ipynb) that we recommend reading through. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not write bytecode to maintain clean directories\n",
    "import sys\n",
    "sys.dont_write_bytecode = True\n",
    "\n",
    "# Import required packages and helper functions\n",
    "import os\n",
    "import core\n",
    "import importlib\n",
    "# importlib.reload(core)\n",
    "\n",
    "# Prepare TensorFlow\n",
    "core.prepare_tensorflow()\n",
    "\n",
    "# import importlib\n",
    "# importlib.reload(core)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose name of folder where all classification results will be stored\n",
    "\n",
    "This folder will be referred to as the \"mother directory\" going forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mother directory\n",
    "mother_dir = \"Your Directory Name\"\n",
    "os.mkdir(mother_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place .gdv, .xyz, and vapor.npy files for all trajectories in unique folders\n",
    "\n",
    "An \".xyz\" file for each given trajectory should be processed according to the crayon package discussed/shown in the \"BGD_Example\" folder. These \".xyz\" files and corresponding \".gdv\" and \"vapor.npy\" files should all be placed in the same folder. For example, an \".xyz\" file named \"cry_x_ds.xyz\" should be placed in a folder labeled \"cry_x_ds\" along with its \".gdv\" and \"vapor.npy\" files. Please make sure that the .xyz files are the \"extended\" .xyz format and at a minimum contain data for species type, radius, and position coordinates. See \"Example_Data.zip\" within the \"Example\" folder for an example. \n",
    "\n",
    "Record the names of these folders once they are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of directories with \".gdv\", \".xyz\", and \"vapor.npy\" files for each trajectory of interest\n",
    "traj_dirs = []\n",
    "traj_dirs.append(\"ss/Cry_x_ss\")\n",
    "traj_dirs.append(\"ss/Cry_x_ss\") # etc. Add as many trajectories as you would like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract unique structural and compositional neighborhood graphs.\n",
    "\n",
    "Note that neighborhood graphs of vapor particles are not recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that \"st\" refers to \"structural\" and \"co\" refers to \"compositional\n",
    "[gdv_unique_st, \n",
    " gdv_unique_co]= core.process_gdvs_train(traj_dirs,\n",
    "                                         mother_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split unique neighborhood graphs into training/validation/testing data sets\n",
    "\n",
    "This function first normalizes the unique neighborhood graphs (by weighing them to account for correlations between individual graphlet nodes) and then scales these weighted neighborhood graphs from -1 to 1. The unique, normalized neighborhood graphs are split into training/validation/testing data sets. that are used to train/validate/test the structural and compositional autoencoders. Note that the validation and testing data set sizes are constrained to be identical. Here, a 60%/20%/20% split is chosen as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_per = 60 # % of data points used in training data\n",
    "[x_train_st, \n",
    " x_val_st, \n",
    " x_test_st, \n",
    " min_st, \n",
    " max_st] = core.train_prep(gdv_unique_st, \n",
    "                           train_per, \n",
    "                           mother_dir,\n",
    "                           model_type=\"struct\")\n",
    "\n",
    "[x_train_co, \n",
    " x_val_co, \n",
    " x_test_co, \n",
    " min_co, \n",
    " max_co] = core.train_prep(gdv_unique_co, \n",
    "                           train_per, \n",
    "                           mother_dir,\n",
    "                           model_type=\"comp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore architectural choices for structural and compositional autoencoders.\n",
    "\n",
    "Enter potential autoencoder architectural choices as a list. The code will train separate autoencoders for each of these combinations and output an \"elbow\" plot that compares their performance. Each model will be saved along with the training loss and validation loss at each epoch, testing loss, and total training time in the mother directory. Other architectural choices (e.g., dropout probability, learning rate) can be adjusted in core.py. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make architectural choices\n",
    "# The architecture choices below represent our suggestions -- but\n",
    "# feel free to change these\n",
    "h_nodes = [25, 50, 100, 200] # number of nodes per hidden layer\n",
    "bn_nodes = [1, 2, 3, 4, 5, 6] # number of bottleneck layer nodes\n",
    "h_layers = [2] # number of hidden layers\n",
    "patience_st = 50 # patience for early stopping. We suggeset between 25-250,\n",
    "# with smaller patiences being used for larger data sets\n",
    "patience_co = 100\n",
    "\n",
    "# Train structural and compositional autoencoders\n",
    "core.train_autoencoders(x_train_st, \n",
    "                        x_val_st, \n",
    "                        x_test_st, \n",
    "                        h_nodes, \n",
    "                        bn_nodes, \n",
    "                        h_layers, \n",
    "                        patience_st, \n",
    "                        mother_dir)\n",
    "\n",
    "core.train_autoencoders(x_train_co, \n",
    "                        x_val_co, \n",
    "                        x_test_co, \n",
    "                        h_nodes, \n",
    "                        bn_nodes, \n",
    "                        h_layers, \n",
    "                        patience_co, \n",
    "                        mother_dir)\n",
    "   \n",
    "\n",
    "# Create elbow plots -- only options for model type are \"struct\" and \"comp\"\n",
    "core.create_elbow(mother_dir, \n",
    "                  model_type = \"struct\")\n",
    "\n",
    "core.create_elbow(mother_dir, \n",
    "                  model_type = \"comp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make final autoencoder architectural choices\n",
    "\n",
    "After examining the elbow plots, choose the \"final\" architectural choices for both the structural and compositional autoencoders below. Note that the \"encoders\" are extracted from the \"autoencoders\" for dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make final architectural choices for structrual autoencoder\n",
    "hn_st = 'Write Integer Here' # number of nodes per hidden layer\n",
    "bn_st = 'Write Integer Here' # number of bottleneck layer nodes\n",
    "hl_st = 'Write Integer Here' # number of hidden layers\n",
    "\n",
    "# Make final architectural choices for compositional autoencoder\n",
    "hn_co = 'Write Integer Here' # number of nodes per hidden layer\n",
    "bn_co = 'Write Integer Here' # number of bottleneck layer nodes\n",
    "hl_co = 'Write Integer Here' # number of hidden layers\n",
    "\n",
    "# Load chosen structural and compositional encoders (and directories\n",
    "# in which these encoders are saved)\n",
    "[enc_st, \n",
    " enc_dir_st] = core.get_encoder(hn_st, \n",
    "                                bn_st, \n",
    "                                hl_st, \n",
    "                                mother_dir, \n",
    "                                model_type = \"struct\")\n",
    "[enc_co, \n",
    " enc_dir_co] = core.get_encoder(hn_co, \n",
    "                                bn_co, \n",
    "                                hl_co, \n",
    "                                mother_dir, \n",
    "                                model_type = \"comp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce dimensionality of the neighborhood graphs using the  models\n",
    "\n",
    "Now that the encoder models are chosen, the dimensionality of the unique neighborhood graphs and the neighborhood graphs corresponding to each particle in each .xyz/.gdv file is reduced. \n",
    "\n",
    "**Note** All results are saved under the folder of the appropriate autoencoder architecture (i.e., mother_dir/Autoencoder_Struct/xx_HL_xx_Nodes/xx_OP or mother_dir/Autoencoder_Comp/xx_HL_xx_Nodes/xx_OP). This trend continues for the rest of the code blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensionality of unique neighborhood graphs\n",
    "lowd_st_unique = core.reduce_dim_uniquegdvs(enc_st, \n",
    "                                            gdv_unique_st, \n",
    "                                            min_st, \n",
    "                                            max_st, \n",
    "                                            enc_dir_st)\n",
    "\n",
    "lowd_co_unique = core.reduce_dim_uniquegdvs(enc_co, \n",
    "                                            gdv_unique_co, \n",
    "                                            min_co, \n",
    "                                            max_co, \n",
    "                                            enc_dir_co)\n",
    "\n",
    "# Reduce dimensionality of each neighborhood graph of each particle in each .xyz file\n",
    "lowd_all_st = {}\n",
    "for traj_dir in traj_dirs:\n",
    "    lowd_all_st[traj_dir] = core.reduce_dim_allgdvs(enc_st, \n",
    "                                                    min_st, \n",
    "                                                    max_st, \n",
    "                                                    traj_dir, \n",
    "                                                    enc_dir_st)\n",
    "\n",
    "lowd_all_co = {}\n",
    "for traj_dir in traj_dirs:\n",
    "    lowd_all_co[traj_dir] = core.reduce_dim_allgdvs(enc_co, \n",
    "                                                    min_co, \n",
    "                                                    max_co,\n",
    "                                                    traj_dir, \n",
    "                                                    enc_dir_co)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create cluster trees\n",
    "Agglomerative hierarchical clustering (via Ward's linkage) is next implemented to cluster the low-dimensional representations of all unique neighborhood graphs. The first step here is to create a cluster tree, which is done below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cluster trees (i.e., linkage) based on low-dimensional representations of\n",
    "# unique stuctural and compositional neighborhood graphs\n",
    "Z_st = core.calc_linkage(lowd_st_unique)\n",
    "Z_co = core.calc_linkage(lowd_co_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the \"best\" number of clusters for classification\n",
    "Because agglomerative hierarchical clustering creates a \"cluster tree\", it is important to find the \"best\" number of clusters for classification.\n",
    "\n",
    "To choose the \"best\" number of clusters, the code below plots the number of low-dimensional points (i.e., neighborhood graphs) corresponding to \"target lattices\" against the number of clusters in each branch of the resulting cluster tree. The \"best' cluster number can be chosen as the point in which the target lattice cluster sizes (qualitatively) stabilize. \n",
    "\n",
    "Here, a \"target lattice\" cluster is defined as a cluster that contains a low-dimensional coordinate that corresponds to a theoretically perfect lattice. So, a \"BCC\" cluster contains the low-dimensional representation of the theoretically perfect BCC neighborhood graph.\n",
    "\n",
    "The attached works classifiy colloidal lattices that form FCC, HCP, BCC, DCsCl, and IrV-like structures. In this code, the target choices currently available are:\n",
    "\n",
    "Structural: \"FCC\", \"HCP\", \"BCC\", \"IrVA\", \"IrVB\", \"DCsClA\", \"DCsClB\", \"Weak\"\n",
    "Compositional: \"FCC_HCP_IrVB\", \"BCC_DCsClB\", \"IrVA_DCsClA\"\n",
    "\n",
    "However, more structures can easily be added into core.py.\n",
    "\n",
    "**Note #1**: We recognize that the user's trajectory data may form BCC/FCC/HCP-like structures but not actually contain particles that have \"theoretically perfect\" lattice neighborhood graphs/low-dimensional coordinates. As a result, the target lattice cluster is defined as a cluster that contains the low-dimensional coordinate with the smallest distance to its theoretically perfect analog. For example, let's say the low-dimensional representation of the perfect BCC lattice is [1, 1, 1]<sup>T</sup>, but only [1 ,1, 1.01]<sup>T</sup> exists in the provided data. Then, [1, 1, 1.01]<sup>T</sup> will be treated as the \"perfect\" BCC coordinate.\n",
    "\n",
    "**Note #2**: We further recognize that the user may not want to choose the cluster number based on the use of target lattices. If this is the case, feel free to skip this step.\n",
    "\n",
    "**Note #3**: Notice that certain structures (e.g., FCC/HCP/IrVB) have identical compositional neighborhood graphs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose target lattices for structrual and compositional models\n",
    "target_st = [\"FCC\", \"HCP\", \"BCC\"]\n",
    "target_co = [\"FCC_HCP_IrVB\", \"BCC_DCsClB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot populations of structural and compositional target clusters versus\n",
    "# the total number of clusters in each branch of the cluster tree\n",
    "# Note that the indices of the these target clusters are also returned.\n",
    "# These indices are useful for tracking/book-keeping\n",
    "[lowd_target_st, \n",
    " target_ind_st, \n",
    " clust_count_st] = core.choose_cluster_num(enc_st,\n",
    "                                           target_st, \n",
    "                                           min_st, \n",
    "                                           max_st, \n",
    "                                           lowd_st_unique, \n",
    "                                           Z_st,\n",
    "                                           enc_dir_st, \n",
    "                                           model_type=\"struct\")\n",
    "\n",
    "\n",
    "[lowd_target_co, \n",
    " target_ind_co, \n",
    " clust_count_co] = core.choose_cluster_num(enc_co,\n",
    "                                           target_co, \n",
    "                                           min_co, \n",
    "                                           max_co, \n",
    "                                           lowd_co_unique, \n",
    "                                           Z_co,\n",
    "                                           enc_dir_co, \n",
    "                                           model_type=\"comp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster the low-dimensional spaces\n",
    "\n",
    "Based on the above plots (or not), choose the number of structural and compositonal clusters you would like to continue with. The code below then clusters these low-dimensional spaces according to this cluster number. The code even outputs associated dendograms that show the hierarchical structure of the resulting clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose number of clusters for structural and compositional spaces\n",
    "nc_st = 'Write Integer Here'\n",
    "nc_co = 'Write Integer Here'\n",
    "\n",
    "# Cluster structural and compositional low-dimensional spaces. Note that these\n",
    "# are the cluster ids of the unique neighborhood graphs\n",
    "clust_ids_st = core.cluster(lowd_st_unique, \n",
    "                            Z_st, \n",
    "                            target_ind_st, \n",
    "                            nc_st, \n",
    "                            enc_dir_st, \n",
    "                            model_type=\"struct\")\n",
    "\n",
    "clust_ids_co = core.cluster(lowd_co_unique, \n",
    "                            Z_co, target_ind_co, \n",
    "                            nc_co, \n",
    "                            enc_dir_co, \n",
    "                            model_type=\"comp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign structrual and compositional clusters to all particles in all .xyz files\n",
    "clust_ids_all_st = {}\n",
    "clust_ids_all_co = {}\n",
    "for traj_dir in traj_dirs:\n",
    "    clust_ids_all_st[traj_dir] = core.assign_clusters(lowd_st_unique, \n",
    "                                                     clust_ids_st, \n",
    "                                                     lowd_all_st[traj_dir],\n",
    "                                                     traj_dir, \n",
    "                                                     enc_dir_st)\n",
    "    \n",
    "    clust_ids_all_co[traj_dir] = core.assign_clusters(lowd_co_unique,\n",
    "                                                     clust_ids_co, \n",
    "                                                     lowd_all_co[traj_dir],\n",
    "                                                     traj_dir, \n",
    "                                                     enc_dir_co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cluster labels of target lattices for structrual and compositional models\n",
    "target_clust_st = core.get_target_clusters(clust_ids_st, \n",
    "                                           target_ind_st)\n",
    "\n",
    "target_clust_co = core.get_target_clusters(clust_ids_co, \n",
    "                                           target_ind_co)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Classification\n",
    "\n",
    "Now the structural and compositional low-dimensional spaces have been clustered, it is time to classify the particles in the XYZ files. We determine this classification based on the chosen target lattices, and structural and compositional clusters.For example, if a given particle’s structural and compositional low-dimensional representations fall under “FCC” identified clusters, the particle will be labeled as a “structurally and compositionally ordered FCC particle” (i.e., “CO-FCC”). If only the particle’s structural low-dimensional representation falls under an FCC cluster, the particle will be labeled as “structurally ordered, yet compositionally disordered FCC” (i.e., “CD-FCC”). If the particle’s low dimensional representation does not fall under any target lattice cluster, the particle is left unlabeled. These “unlabeled” particles often correspond to vapor particles, structurally defective particles, surface particles, etc. Note that we will use the \"CO\" and \"CD\" abbreviations in the next few code blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on target lattices from before, we create and assign clusters for \"CO\" and \"CD\"\n",
    "# target lattices.\n",
    "target_comb = core.get_combined_cluster_ids(target_clust_st, target_clust_co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classify all particles in all provided trajectories\n",
    "clust_ids_all_comb = {}\n",
    "for traj_dir in traj_dirs:\n",
    "    clust_ids_all_comb[traj_dir] = core.assign_clusters_combined(target_comb,\n",
    "                                                                clust_ids_all_st[traj_dir], \n",
    "                                                                clust_ids_all_co[traj_dir], \n",
    "                                                                traj_dir, \n",
    "                                                                enc_dir_st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OVITO Visualization and Classification\n",
    "\n",
    "The original .xyz files are re-written such that each particle is colored according to its classification. These .xyz files can be visualized in OVITO. Use the qualitative analyses from these visualizations along with the cluster tree to assign physical meaning(s) to each class.\n",
    "\n",
    "**Note** The re-written  are saved under the folder of the appropriate structural autoencoder architecture (i.e., mother_dir/Autoencoder_Struct/xx_HL_xx_Nodes/xx_OP/traj_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First assign colors to combined cluster IDs. Note that this function assigns \"true\"\n",
    "# colors to \"CO\" particles, light colors to \"CD\" particles, and white to unabeled particles.\n",
    "# Feel free to modify this in the core.py file. For example, CO-FCC could be red, while CD-\n",
    "# CD-FCC would be light red. The function outputs a list of used colors (and their RGB\n",
    "# values) and their corresponding classifications.\n",
    "colors_list, colors_dict = core.assign_colors(target_comb,\n",
    "                                              mother_dir)\n",
    "\n",
    "# Print color/classification assignments for user clarity. Dictionary is also saved as\n",
    "# text file\n",
    "print (colors_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write XYZ files \n",
    "for traj_dir in traj_dirs:\n",
    "    core.create_XYZ(clust_ids_all_comb[traj_dir], \n",
    "                    colors_list, \n",
    "                    traj_dir, \n",
    "                    enc_dir_st)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
