{"cells":[{"cell_type":"markdown","metadata":{"id":"BpiJ8gxOsAN6"},"source":["## Code Summary\n","\n","The following code reduces the dimensionality of structural and compositional neighborhood graphs and uses agglomerative hierarchical clustering to partition the low-dimensional spaces and assign classifications to the resulting partitions\n","\n","Specifically, this code:\n","\n","**(1)** Takes as input \".gdv\" files and \"vapor.npy\" files that (i) contain structural and compositional neighborhood graphs and (ii) identify vapor particles. These files can describe multiple trajectories with particles that have different interaction potentials, sizes, etc. Note that the corresponding \".xyz\" files should be in the same folder.\n","\n","**(2)** Trains a deep neural network called an \"autoencoder\" (using only the unique neighborhood graphs). An \"encoder\" is extracted from the \"autoencoder\" and is then used for dimensionality reduction. Note that both \"structural\" and \"compositional\" autoencoders/encoders are created.\n","\n","**(3)** Uses agglomerative hierarchical clustering (via Ward's linkage) to partition the structural and compositional low-dimensional spaces and assign classifications to the resulting partitions.\n","\n","**(4)** Modifies the \".xyz\" files such that individual particles are colored according to their discrete classifications. These \".xyz\" files can be visualized in OVITO. Qualitative analyses of these images can provide a general idea of what each class physically represents.\n","\n","**Note #1**: Example data and results of this entire framework can be found in the \"Example\" folder. This folder contains a \"filled out\" example of this code (called Train_example.ipynb) that we recommend reading through. \n","\n","**Note #2**: If only interested in structural order, do not run cells that contain \"co\" flag in variables"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PS3pLjjGsAN9"},"outputs":[],"source":["# Import required packages and helper functions\n","import os\n","import core\n","import importlib\n","# importlib.reload(core)\n","\n","# Prepare TensorFlow\n","core.prepare_tensorflow()"]},{"cell_type":"markdown","metadata":{"id":"LCA0fNSWsAN-"},"source":["## Choose name of folder where all classification results will be stored\n","\n","This folder will be referred to as the \"mother directory\" going forward"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CcUWqXcKsAN_"},"outputs":[],"source":["# Create mother directory\n","mother_dir = \"Train\"\n","os.mkdir(mother_dir)"]},{"cell_type":"markdown","metadata":{"id":"Db5RGReisAN_"},"source":["## Place .gdv, .xyz, and vapor.npy files for all trajectories in unique folders\n","\n","An \".xyz\" file for each given trajectory should be processed according to the crayon package discussed/shown in the \"BGD_Example\" folder. These \".xyz\" files and corresponding \".gdv\" and \"vapor.npy\" files should all be placed in the same folder. For example, an \".xyz\" file named \"cry_x_ds.xyz\" should be placed in a folder labeled \"cry_x_ds\" along with its \".gdv\" and \"vapor.npy\" files. Please make sure that the .xyz files are the \"extended\" .xyz format and at a minimum contain data for species type, radius, and position coordinates. See \"Example_Data.zip\" within the \"Example\" folder for an example. \n","\n","Record the names of these folders once they are created."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9yqVppBgsAOA"},"outputs":[],"source":["# Create list of directories with \".gdv\", \".xyz\", and \"vapor.npy\" files for each trajectory of interest\n","traj_dirs = []\n","traj_dirs.append(\"Example_Data_1/1.0/Cry_0\")\n","traj_dirs.append(\"Example_Data_1/1.0/Cry_1\")\n","traj_dirs.append(\"Example_Data_1/1.0/Cry_2\")\n","traj_dirs.append(\"Example_Data_1/1.0/Cry_3\")\n","traj_dirs.append(\"Example_Data_1/1.0/Cry_4\")\n","traj_dirs.append(\"Example_Data_1/1.0/Cry_5\")\n","traj_dirs.append(\"Example_Data_1/1.0/Cry_6\")\n","traj_dirs.append(\"Example_Data_1/1.0/Cry_7\")\n","traj_dirs.append(\"Example_Data_1/1.0/Cry_8\")\n","traj_dirs.append(\"Example_Data_1/1.0/Cry_9\")\n","traj_dirs.append(\"Example_Data_1/1.0/Cry_10\")\n","traj_dirs.append(\"Example_Data_2/1.05/Cry_0\")\n","traj_dirs.append(\"Example_Data_2/1.05/Cry_1\")\n","traj_dirs.append(\"Example_Data_2/1.05/Cry_2\")\n","traj_dirs.append(\"Example_Data_2/1.05/Cry_3\")\n","traj_dirs.append(\"Example_Data_2/1.05/Cry_4\")\n","traj_dirs.append(\"Example_Data_2/1.05/Cry_5\")\n","traj_dirs.append(\"Example_Data_2/1.05/Cry_6\")\n","traj_dirs.append(\"Example_Data_2/1.05/Cry_7\")\n","traj_dirs.append(\"Example_Data_2/1.05/Cry_8\")\n","traj_dirs.append(\"Example_Data_2/1.05/Cry_9\")\n","traj_dirs.append(\"Example_Data_2/1.05/Cry_10\")"]},{"cell_type":"markdown","metadata":{"id":"ATJEfLE_sAOA"},"source":["## Extract unique structural and compositional neighborhood graphs.\n","\n","Note that neighborhood graphs of vapor particles are not recorded.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QWwsQzVlsAOA"},"outputs":[],"source":["# Note that \"st\" refers to \"structural\"\n","gdv_unique_st = core.process_gdvs_train_struct(traj_dirs, \n","                                               mother_dir,\n","                                               clean = True)"]},{"cell_type":"code","source":["# Note that \"st\" refers to \"structural\"\n","gdv_unique_co = core.process_gdvs_train_comp(traj_dirs, \n","                                             mother_dir,\n","                                             clean = True)"],"metadata":{"id":"hEYZoKwPE6xS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cm_8oahZsAOB"},"source":["## Split unique neighborhood graphs into training/validation/testing data sets\n","\n","This function first normalizes the unique neighborhood graphs (by weighing them to account for correlations between individual graphlet nodes) and then scales these weighted neighborhood graphs from -1 to 1. The unique, normalized neighborhood graphs are split into training/validation/testing data sets. that are used to train/validate/test the structural and compositional autoencoders. Note that the validation and testing data set sizes are constrained to be identical. Here, a 60%/20%/20% split is chosen as an example."]},{"cell_type":"code","source":["train_per = 60 # % of data points used in training data"],"metadata":{"id":"P0SVvPYOwTgO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["[x_train_st, \n"," x_val_st, \n"," x_test_st, \n"," min_st, \n"," max_st] = core.train_prep(gdv_unique_st, \n","                           train_per, \n","                           mother_dir,\n","                           model_type=\"struct\")"],"metadata":{"id":"ySJhtv5AFIqf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["[x_train_co, \n"," x_val_co, \n"," x_test_co, \n"," min_co, \n"," max_co] = core.train_prep(gdv_unique_co, \n","                           train_per, \n","                           mother_dir,\n","                           model_type=\"comp\")"],"metadata":{"id":"2WcoANbfFDWj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j6Kk-vKEsAOC"},"source":["## Explore architectural choices for structural and compositional autoencoders.\n","\n","Enter potential autoencoder architectural choices as a list. The code will train separate autoencoders for each of these combinations and output an \"elbow\" plot that compares their performance. Each model will be saved along with the training loss and validation loss at each epoch, testing loss, and total training time in the mother directory. Other architectural choices (e.g., dropout probability, learning rate) can be adjusted in core.py. "]},{"cell_type":"code","source":["# Make architectural choices\n","# The architecture choices below represent our suggestions -- but\n","# feel free to change these\n","h_nodes = [25, 50, 100, 200] # number of nodes per hidden layer\n","bn_nodes = [1, 2, 3, 4, 5, 6] # number of bottleneck layer nodes\n","h_layers = [2] # number of hidden layers"],"metadata":{"id":"UE9FGIudwjl1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train structural autoencoders\n","patience_st = 50 # patience for early stopping. We suggeset between 25-250,\n","# with smaller patiences being used for larger data sets\n","\n","core.train_autoencoders(x_train_st, \n","                        x_val_st, \n","                        x_test_st, \n","                        h_nodes, \n","                        bn_nodes, \n","                        h_layers, \n","                        patience_st, \n","                        mother_dir)\n","\n","# Create structrual elbow plots -- only options for model type are \"struct\" and \"comp\"\n","core.create_elbow(mother_dir, \n","                  model_type = \"struct\")"],"metadata":{"id":"u8cAm76XF8iI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train compositional autoencoders\n","patience_co = 100 # patience for early stopping. We suggeset between 25-250,\n","# with smaller patiences being used for larger data sets\n","\n","core.train_autoencoders(x_train_co, \n","                        x_val_co, \n","                        x_test_co, \n","                        h_nodes, \n","                        bn_nodes, \n","                        h_layers, \n","                        patience_co, \n","                        mother_dir)\n","\n","# Create compositional elbow plots -- only options for model type are \"struct\" and \"comp\"\n","core.create_elbow(mother_dir, \n","                  model_type = \"comp\")"],"metadata":{"id":"PRavSuO0GAM-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6KksVzAKsAOC"},"source":["## Make final autoencoder architectural choices\n","\n","After examining the elbow plots, choose the \"final\" architectural choices for both the structural and compositional autoencoders below. Note that the \"encoders\" are extracted from the \"autoencoders\" for dimensionality reduction."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vtaLu_QEsAOC"},"outputs":[],"source":["# Make final architectural choices for structrual autoencoder\n","hn_st = 'Write Integer Here' # number of nodes per hidden layer\n","# The example data chooses 50 hidden nodes\n","bn_st = 'Write Integer Here' # number of bottleneck layer nodes\n","# The example data chooses 3 bottleneck nodes\n","hl_st = 'Write Integer Here' # number of hidden layers\n","# The example data chooses 2 hidden layers\n","\n","# Load chosen structural encoder (and directory\n","# in which the encoders is saved)\n","[enc_st, \n"," enc_dir_st] = core.get_encoder(hn_st, \n","                                bn_st, \n","                                hl_st, \n","                                mother_dir, \n","                                model_type = \"struct\")"]},{"cell_type":"code","source":["# Make final architectural choices for compositional autoencoder\n","hn_co = 'Write Integer Here' # number of nodes per hidden layer\n","# The example data chooses 50 hidden nodes\n","bn_co = 'Write Integer Here' # number of bottleneck layer nodes\n","# The example data chooses 3 bottleneck nodes\n","hl_co = 'Write Integer Here' # number of hidden layers\n","# The example data chooses 2 hidden layers\n","\n","# Load chosen compositional encoder (and directory\n","# in which the encoders is saved)\n","[enc_co, \n"," enc_dir_co] = core.get_encoder(hn_co, \n","                                bn_co, \n","                                hl_co, \n","                                mother_dir, \n","                                model_type = \"comp\")"],"metadata":{"id":"aEz2_qawGoY9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F2A1HqNNsAOD"},"source":["## Reduce dimensionality of the neighborhood graphs using the  models\n","\n","Now that the encoder models are chosen, the dimensionality of the unique neighborhood graphs and the neighborhood graphs corresponding to each particle in each .xyz/.gdv file is reduced. \n","\n","**Note** All results are saved under the folder of the appropriate autoencoder architecture (i.e., mother_dir/Autoencoder_Struct/xx_HL_xx_Nodes/xx_OP or mother_dir/Autoencoder_Comp/xx_HL_xx_Nodes/xx_OP). This trend continues for the rest of the code blocks."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OwnjmJ8EsAOD"},"outputs":[],"source":["# Reduce dimensionality of unique structrual neighborhood graphs\n","lowd_st_unique = core.reduce_dim_uniquegdvs(enc_st, \n","                                            gdv_unique_st, \n","                                            min_st, \n","                                            max_st, \n","                                            enc_dir_st)\n","\n","# Reduce dimensionality of each structrual neighborhood graph of each particle \n","# in each .xyz file\n","lowd_all_st = {}\n","for traj_dir in traj_dirs:\n","    lowd_all_st[traj_dir] = core.reduce_dim_allgdvs(enc_st, \n","                                                    min_st, \n","                                                    max_st, \n","                                                    traj_dir, \n","                                                    enc_dir_st)"]},{"cell_type":"code","source":["# Reduce dimensionality of unique compositional neighborhood graphs\n","lowd_co_unique = core.reduce_dim_uniquegdvs(enc_co, \n","                                            gdv_unique_co, \n","                                            min_co, \n","                                            max_co, \n","                                            enc_dir_co)\n","\n","# Reduce dimensionality of each compositional neighborhood graph of each particle \n","# in each .xyz file\n","lowd_all_co = {}\n","for traj_dir in traj_dirs:\n","    lowd_all_co[traj_dir] = core.reduce_dim_allgdvs(enc_co, \n","                                                    min_co, \n","                                                    max_co,\n","                                                    traj_dir, \n","                                                    enc_dir_co)"],"metadata":{"id":"nHYNvknrG4sy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J9p-bW-GsAOD"},"source":["## Create cluster trees\n","Agglomerative hierarchical clustering (via Ward's linkage) is next implemented to cluster the low-dimensional representations of all unique neighborhood graphs. The first step here is to create a cluster tree, which is done below."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FxThKunusAOD"},"outputs":[],"source":["# Calculate structural cluster trees (i.e., linkage) based on low-dimensional \n","# representations of unique stuctural neighborhood graphs\n","Z_st = core.calc_linkage(lowd_st_unique)"]},{"cell_type":"code","source":["# Calculate compositional cluster trees based on low-dimensional \n","# representations of unique compositional neighborhood graphs\n","Z_co = core.calc_linkage(lowd_co_unique)"],"metadata":{"id":"uQ_mdxWoHxqj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6cxIanE9sAOE"},"source":["## Choose the \"best\" number of clusters for classification\n","Because agglomerative hierarchical clustering creates a \"cluster tree\", it is important to find the \"best\" number of clusters for classification.\n","\n","To choose the \"best\" number of clusters, the code below plots the number of low-dimensional points (i.e., neighborhood graphs) corresponding to \"target lattices\" against the number of clusters in each branch of the resulting cluster tree. The \"best' cluster number can be chosen as the point in which the target lattice cluster sizes (qualitatively) stabilize. \n","\n","Here, a \"target lattice\" cluster is defined as a cluster that contains a low-dimensional coordinate that corresponds to a theoretically perfect lattice. So, a \"BCC\" cluster contains the low-dimensional representation of the theoretically perfect BCC neighborhood graph.\n","\n","The attached works classifiy colloidal lattices that form FCC, HCP, BCC, DCsCl, and IrV-like structures. In this code, the target choices currently available are:\n","\n","Structural: \"FCC\", \"HCP\", \"BCC\", \"IrVA\", \"IrVB\", \"DCsClA\", \"DCsClB\", \"Weak\"\n","Compositional: \"FCC_HCP_IrVB\", \"BCC_DCsClB\", \"IrVA_DCsClA\"\n","\n","However, more structures can easily be added into core.py.\n","\n","**Note #1**: We recognize that the user's trajectory data may form BCC/FCC/HCP-like structures but not actually contain particles that have \"theoretically perfect\" lattice neighborhood graphs/low-dimensional coordinates. As a result, the target lattice cluster is defined as a cluster that contains the low-dimensional coordinate with the smallest distance to its theoretically perfect analog. For example, let's say the low-dimensional representation of the perfect BCC lattice is [1, 1, 1]<sup>T</sup>, but only [1 ,1, 1.01]<sup>T</sup> exists in the provided data. Then, [1, 1, 1.01]<sup>T</sup> will be treated as the \"perfect\" BCC coordinate.\n","\n","**Note #2**: We further recognize that the user may not want to choose the cluster number based on the use of target lattices. If this is the case, feel free to skip this step.\n","\n","**Note #3**: Notice that certain structures (e.g., FCC/HCP/IrVB) have identical compositional neighborhood graphs.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P5SdQYNDsAOE"},"outputs":[],"source":["# Choose target lattices for structural models\n","target_st = [\"FCC\", \"HCP\", \"BCC\"]\n","\n","# Plot populations of structural target clusters versus\n","# the total number of clusters in each branch of the cluster tree\n","# Note that the indices of the these target clusters are also returned.\n","# These indices are useful for tracking/book-keeping\n","[lowd_target_st, \n"," target_ind_st, \n"," clust_count_st] = core.choose_cluster_num(enc_st,\n","                                           target_st, \n","                                           min_st, \n","                                           max_st, \n","                                           lowd_st_unique, \n","                                           Z_st,\n","                                           enc_dir_st, \n","                                           model_type=\"struct\")"]},{"cell_type":"code","source":["# Choose target lattices for compositional models\n","target_co = [\"FCC_HCP_IrVB\", \"BCC_DCsClB\"]\n","\n","# Plot populations of compositional target clusters versus\n","# the total number of clusters in each branch of the cluster tree\n","# Note that the indices of the these target clusters are also returned.\n","# These indices are useful for tracking/book-keeping\n","[lowd_target_co, \n"," target_ind_co, \n"," clust_count_co] = core.choose_cluster_num(enc_co,\n","                                           target_co, \n","                                           min_co, \n","                                           max_co, \n","                                           lowd_co_unique, \n","                                           Z_co,\n","                                           enc_dir_co, \n","                                           model_type=\"comp\")\n","\n"],"metadata":{"id":"p8Tg8L_qIDgM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3YgAfvIosAOE"},"source":["## Cluster the low-dimensional spaces\n","\n","Based on the above plots (or not), choose the number of structural and compositonal clusters you would like to continue with. The code below then clusters these low-dimensional spaces according to this cluster number. The code even outputs associated dendograms that show the hierarchical structure of the resulting clusters."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QgJbFCrNsAOF"},"outputs":[],"source":["# Choose number of clusters for structural low-dimensional space\n","nc_st = 'Write Integer Here'\n","# The example data chooses 210 structural clusters\n","\n","# Cluster structural low-dimensional space. Note that these\n","# are the cluster ids of the unique neighborhood graphs\n","clust_ids_st = core.cluster(lowd_st_unique, \n","                            Z_st, \n","                            target_ind_st, \n","                            nc_st, \n","                            enc_dir_st, \n","                            model_type=\"struct\")\n","\n","# Assign structrual clusters to all particles in all .xyz files\n","clust_ids_all_st = {}\n","for traj_dir in traj_dirs:\n","    clust_ids_all_st[traj_dir] = core.assign_clusters(lowd_st_unique, \n","                                                     clust_ids_st, \n","                                                     lowd_all_st[traj_dir],\n","                                                     traj_dir, \n","                                                     enc_dir_st,\n","                                                     clean = True)\n","    \n","# Get cluster labels of target lattices for structural models\n","target_clust_st = core.get_target_clusters(clust_ids_st, \n","                                           target_ind_st)"]},{"cell_type":"code","source":["# Choose number of clusters for compositional low-dimensional space\n","nc_co = 'Write Integer Here'\n","# The example data chooses 180 compositional clusters\n","\n","# Cluster compositional low-dimensional space. Note that these\n","# are the cluster ids of the unique neighborhood graphs\n","clust_ids_co = core.cluster(lowd_co_unique, \n","                            Z_co, target_ind_co, \n","                            nc_co, \n","                            enc_dir_co, \n","                            model_type=\"comp\")\n","\n","# Assign compositional clusters to all particles in all .xyz files\n","clust_ids_all_co = {}\n","for traj_dir in traj_dirs:\n","    clust_ids_all_co[traj_dir] = core.assign_clusters(lowd_co_unique,\n","                                                     clust_ids_co, \n","                                                     lowd_all_co[traj_dir],\n","                                                     traj_dir, \n","                                                     enc_dir_co,\n","                                                     clean = True)\n","\n","# Get cluster labels of target lattices for compositional models \n","target_clust_co = core.get_target_clusters(clust_ids_co, \n","                                           target_ind_co)"],"metadata":{"id":"_FfLf9J1L9Qr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-6ih1XWUsAOF"},"source":["## Combined Classification and OVITO Visualization\n","\n","Now that the structural and compositional low-dimensional spaces have been clustered, it is time to classify the particles in the XYZ files. We determine this classification based on the chosen target lattices, and structural and compositional clusters. For example, if a given particle’s structural and compositional low-dimensional representations fall under “FCC” identified clusters, the particle will be labeled as a “structurally and compositionally ordered FCC particle” (i.e., “CO-FCC”). If only the particle’s structural low-dimensional representation falls under an FCC cluster, the particle will be labeled as “structurally ordered, yet compositionally disordered FCC” (i.e., “CD-FCC”). If the particle’s low dimensional representation does not fall under any target lattice cluster, the particle is left unlabeled. These “unlabeled” particles often correspond to vapor particles, structurally defective particles, surface particles, etc.\n","\n","After classification, the original .xyz files are re-written such that each particle is colored according to its classification. These .xyz files can be visualized in OVITO. Use the qualitative analyses from these visualizations along with the cluster tree to assign physical meaning(s) to each class.\n","\n","**Note #1** The re-written  are saved under the folder of the appropriate structural autoencoder architecture (i.e., mother_dir/Autoencoder_Struct/xx_HL_xx_Nodes/xx_OP/traj_dir)\n","\n","**Note #2**: Only run this cell if you ARE interested in compositional classification!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"coGa98ULsAOF"},"outputs":[],"source":["# Based on target lattices from before, we create and assign clusters for \"CO\" and \"CD\"\n","# target lattices.\n","target_comb = core.get_combined_cluster_ids(target_clust_st, target_clust_co)\n","\n","# Classify all particles in all provided trajectories\n","clust_ids_all_comb = {}\n","for traj_dir in traj_dirs:\n","    clust_ids_all_comb[traj_dir] = core.assign_clusters_comb(target_comb,\n","                                                             clust_ids_all_st[traj_dir], \n","                                                             clust_ids_all_co[traj_dir], \n","                                                             traj_dir, \n","                                                             enc_dir_st)\n","    \n","# First assign colors to combined cluster IDs. Note that this function assigns \"true\"\n","# colors to \"CO\" particles, light colors to \"CD\" particles, and white to unabeled particles.\n","# Feel free to modify this in the core.py file. For example, CO-FCC could be red, while CD-\n","# CD-FCC would be light red. The function outputs a list of used colors (and their RGB\n","# values) and their corresponding classifications.\n","colors_list, colors_dict = core.assign_colors_comb(target_comb,\n","                                                   mother_dir)\n","\n","# Print color/classification assignments for user clarity. Dictionary is also saved as\n","# text file\n","print (colors_dict)\n","\n","# Re-write XYZ files \n","for traj_dir in traj_dirs:\n","    core.create_XYZ(clust_ids_all_comb[traj_dir], \n","                    colors_list, \n","                    traj_dir, \n","                    enc_dir_st)"]},{"cell_type":"markdown","metadata":{"id":"pJL0sJhWQp6N"},"source":["## Structural Classification and OVITO Visualization\n","\n","Now that the structural low-dimensional space has been clustered, it is time to classify the particles in the XYZ files. We determine this classification based on the chosen target lattices and structural clusters. For example, if a given particle’s structural low-dimensional representation falls under an “FCC” identified cluster, the particle will be labeled as a “structurally ordered FCC particle” (i.e., “SO-FCC”). If the particle’s low dimensional representation does not fall under any target lattice cluster, the particle is left unlabeled. These “unlabeled” particles often correspond to vapor particles, structurally defective particles, surface particles, etc.\n","\n","After classification, the original .xyz files are re-written such that each particle is colored according to its classification. These .xyz files can be visualized in OVITO. Use the qualitative analyses from these visualizations along with the cluster tree to assign physical meaning(s) to each class.\n","\n","**Note #1** The re-written  are saved under the folder of the appropriate structural autoencoder architecture (i.e., mother_dir/Autoencoder_Struct/xx_HL_xx_Nodes/xx_OP/traj_dir)\n","\n","**Note #2**: Only run this cell if you are NOT interested in compositional classification!"]},{"cell_type":"code","source":["# Based on target lattices from before, we create and assign clusters for \"SO\"\n","# target lattices.\n","target_st = core.get_st_class_cluster_ids(target_clust_st)\n","\n","# Classify all particles in all provided trajectories\n","clust_ids_all_st_class = {}\n","for traj_dir in traj_dirs:\n","    clust_ids_all_st_class[traj_dir] = core.assign_clusters_st_class(target_st,\n","                                                                     clust_ids_all_st[traj_dir], \n","                                                                     traj_dir, \n","                                                                     enc_dir_st)\n","\n","# First assign colors to final cluster IDs. Note that this function assigns \"true\"\n","# colors to \"SO\" particles and white to unabeled particles. Feel free to modify \n","# this in the core.py file. The function outputs a list of used colors (and \n","# their RGB values) and their corresponding classifications.\n","colors_list_st, colors_dict_st = core.assign_colors_st(target_clust_st,\n","                                                       mother_dir)\n","\n","# Print color/classification assignments for user clarity. Dictionary is also saved as\n","# text file\n","print (colors_dict_st)\n","\n","# Re-write XYZ files \n","for traj_dir in traj_dirs:\n","    core.create_XYZ(clust_ids_all_st_class[traj_dir], \n","                    colors_list_st, \n","                    traj_dir, \n","                    enc_dir_st)"],"metadata":{"id":"MunrvN9dRD3P"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"provenance":[],"machine_shape":"hm","collapsed_sections":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}