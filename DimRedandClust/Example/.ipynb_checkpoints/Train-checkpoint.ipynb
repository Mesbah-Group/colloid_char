{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Summary\n",
    "\n",
    "The following code reduces the dimensionality of structural and compositional neighborhood graphs and uses agglomerative hierarchical clustering to partition the low-dimensional spaces and assign classifications to the resulting partitions\n",
    "\n",
    "Specifically, this code:\n",
    "\n",
    "**(1)** Takes as input \".gdv\" files and \"vapor.npy\" files that (i) contain structural and compositional neighborhood graphs and (ii) identify vapor particles. These files can describe multiple trajectories with particles that have different interaction potentials, sizes, etc. Note that the corresponding \".xyz\" files should be in the same folder.\n",
    "\n",
    "**(2)** Trains a deep neural network called an \"autoencoder\" (using only the unique neighborhood graphs). An \"encoder\" is extracted from the \"autoencoder\" and is then used for dimensionality reduction. Note that both \"structural\" and \"compositional\" autoencoders/encoders are created.\n",
    "\n",
    "**(3)** Uses agglomerative hierarchical clustering (via Ward's linkage) to partition the structural and compositional low-dimensional spaces and assign classifications to the resulting partitions.\n",
    "\n",
    "**(4)** Modifies the \".xyz\" files such that individual particles are colored according to their discrete classifications. These \".xyz\" files can be visualized in OVITO. Qualitative analyses of these images can provide a general idea of what each class physically represents.\n",
    "\n",
    "**Note**: Example data and results of this entire framework can be found in \"Example.zip\". This section contains a \"filled out\" example of this code (with outputs) that we recommend reading through. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU computing is available\n",
      "TensorFlow version: 2.3.0\n",
      "Eager execution: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'core' from '/home/mesbahlab/Documents/Jared/colloid_char/core.py'>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do not write bytecode to maintain clean directories\n",
    "import sys\n",
    "sys.dont_write_bytecode = True\n",
    "\n",
    "# Import required packages and helper functions\n",
    "import os\n",
    "import core\n",
    "import importlib\n",
    "# importlib.reload(core)\n",
    "\n",
    "# Prepare TensorFlow\n",
    "core.prepare_tensorflow()\n",
    "\n",
    "import importlib\n",
    "importlib.reload(core)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose name of folder where all classification results will be stored\n",
    "\n",
    "This folder will be referred to as the \"mother directory\" going forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mother directory\n",
    "mother_dir = \"Train\"\n",
    "os.mkdir(mother_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place .gdv, .xyz, and vapor.npy files for all trajectories in unique folders\n",
    "\n",
    "An \".xyz\" file for each given trajectory should be processed according to the crayon package discussed/shown in the \"BGD_Example\" folder. These \".xyz\" files and corresponding \".gdv\" and \"vapor.npy\" files should all be placed in the same folder. For example, an \".xyz\" file named \"cry_x_ds.xyz\" should be placed in a folder labeled \"cry_x_ds\" along with its \".gdv\" and \"vapor.npy\" files. Please make sure that the .xyz files are the \"extended\" .xyz format and at a minimum contain data for species type, radius, and position coordinates. See \"Example_Data\" within \"Example.zip\" for an example. \n",
    "\n",
    "Record the names of these folders once they are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of directories with \".gdv\", \".xyz\", and \"vapor.npy\" files for each trajectory of interest\n",
    "traj_dirs = []\n",
    "traj_dirs.append(\"Example_Data/1.0/Cry_0\")\n",
    "traj_dirs.append(\"Example_Data/1.0/Cry_1\")\n",
    "traj_dirs.append(\"Example_Data/1.0/Cry_2\")\n",
    "traj_dirs.append(\"Example_Data/1.0/Cry_3\")\n",
    "traj_dirs.append(\"Example_Data/1.0/Cry_4\")\n",
    "traj_dirs.append(\"Example_Data/1.0/Cry_5\")\n",
    "traj_dirs.append(\"Example_Data/1.0/Cry_6\")\n",
    "traj_dirs.append(\"Example_Data/1.0/Cry_7\")\n",
    "traj_dirs.append(\"Example_Data/1.0/Cry_8\")\n",
    "traj_dirs.append(\"Example_Data/1.0/Cry_9\")\n",
    "traj_dirs.append(\"Example_Data/1.0/Cry_10\")\n",
    "traj_dirs.append(\"Example_Data/1.05/Cry_0\")\n",
    "traj_dirs.append(\"Example_Data/1.05/Cry_1\")\n",
    "traj_dirs.append(\"Example_Data/1.05/Cry_2\")\n",
    "traj_dirs.append(\"Example_Data/1.05/Cry_3\")\n",
    "traj_dirs.append(\"Example_Data/1.05/Cry_4\")\n",
    "traj_dirs.append(\"Example_Data/1.05/Cry_5\")\n",
    "traj_dirs.append(\"Example_Data/1.05/Cry_6\")\n",
    "traj_dirs.append(\"Example_Data/1.05/Cry_7\")\n",
    "traj_dirs.append(\"Example_Data/1.05/Cry_8\")\n",
    "traj_dirs.append(\"Example_Data/1.05/Cry_9\")\n",
    "traj_dirs.append(\"Example_Data/1.05/Cry_10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract unique structural and compositional neighborhood graphs.\n",
    "\n",
    "Note that neighborhood graphs of vapor particles are not recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that \"st\" refers to \"structural\" and \"co\" refers to \"compositional\n",
    "[gdv_unique_st, \n",
    " gdv_unique_co]= core.process_gdvs_train(traj_dirs,\n",
    "                                         mother_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split unique neighborhood graphs into training/validation/testing data sets\n",
    "\n",
    "This function first normalizes the unique neighborhood graphs (by weighing them to account for correlations between individual graphlet nodes) and then scales these weighted neighborhood graphs from -1 to 1. The unique, normalized neighborhood graphs are split into training/validation/testing data sets. that are used to train/validate/test the structural and compositional autoencoders. Note that the validation and testing data set sizes are constrained to be identical. Here, a 60%/20%/20% split is chosen as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_per = 60 # % of data points used in training data\n",
    "[x_train_st, \n",
    " x_val_st, \n",
    " x_test_st, \n",
    " min_st, \n",
    " max_st] = core.train_prep(gdv_unique_st, \n",
    "                           train_per, \n",
    "                           mother_dir,\n",
    "                           model_type=\"struct\")\n",
    "\n",
    "[x_train_co, \n",
    " x_val_co, \n",
    " x_test_co, \n",
    " min_co, \n",
    " max_co] = core.train_prep(gdv_unique_co, \n",
    "                           train_per, \n",
    "                           mother_dir,\n",
    "                           model_type=\"comp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore architectural choices for structural and compositional autoencoders.\n",
    "\n",
    "Enter potential autoencoder architectural choices as a list. The code will train separate autoencoders for each of these combinations and output an \"elbow\" plot that compares their performance. Each model will be saved along with the training loss and validation loss at each epoch, testing loss, and total training time in the mother directory. Other architectural choices (e.g., dropout probability, learning rate) can be adjusted in core.py. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.2146 - val_loss: 0.0324\n",
      "Epoch 2/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0261\n",
      "Epoch 3/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0168\n",
      "Epoch 4/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0332 - val_loss: 0.0155\n",
      "Epoch 5/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0300 - val_loss: 0.0173\n",
      "Epoch 6/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0280 - val_loss: 0.0155\n",
      "Epoch 7/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0262 - val_loss: 0.0151\n",
      "Epoch 8/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0254 - val_loss: 0.0156\n",
      "Epoch 9/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.0153\n",
      "Epoch 10/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0233 - val_loss: 0.0152\n",
      "Epoch 11/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0228 - val_loss: 0.0150\n",
      "Epoch 12/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0221 - val_loss: 0.0154\n",
      "Epoch 13/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0218 - val_loss: 0.0149\n",
      "Epoch 14/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0214 - val_loss: 0.0149\n",
      "Epoch 15/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0213 - val_loss: 0.0148\n",
      "Epoch 16/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0207 - val_loss: 0.0146\n",
      "Epoch 17/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0205 - val_loss: 0.0148\n",
      "Epoch 18/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0202 - val_loss: 0.0149\n",
      "Epoch 19/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0202 - val_loss: 0.0151\n",
      "Epoch 20/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0196 - val_loss: 0.0147\n",
      "Epoch 21/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0194 - val_loss: 0.0146\n",
      "Epoch 22/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0193 - val_loss: 0.0149\n",
      "Epoch 23/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0189 - val_loss: 0.0151\n",
      "Epoch 24/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0188 - val_loss: 0.0149\n",
      "Epoch 25/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0189 - val_loss: 0.0160\n",
      "Epoch 26/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0185 - val_loss: 0.0149\n",
      "Epoch 27/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0183 - val_loss: 0.0146\n",
      "Epoch 28/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0185 - val_loss: 0.0156\n",
      "Epoch 29/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0181 - val_loss: 0.0150\n",
      "Epoch 30/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0180 - val_loss: 0.0147\n",
      "Epoch 31/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.0146\n",
      "Epoch 32/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0177 - val_loss: 0.0147\n",
      "Epoch 33/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0177 - val_loss: 0.0147\n",
      "Epoch 34/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0175 - val_loss: 0.0150\n",
      "Epoch 35/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0174 - val_loss: 0.0146\n",
      "Epoch 36/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0175 - val_loss: 0.0146\n",
      "Epoch 37/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0173 - val_loss: 0.0146\n",
      "Epoch 38/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0173 - val_loss: 0.0145\n",
      "Epoch 39/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.0146\n",
      "Epoch 40/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.0145\n",
      "Epoch 41/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0171 - val_loss: 0.0146\n",
      "Epoch 42/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0171 - val_loss: 0.0148\n",
      "Epoch 43/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0170 - val_loss: 0.0146\n",
      "Epoch 44/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0170 - val_loss: 0.0147\n",
      "Epoch 45/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0170 - val_loss: 0.0146\n",
      "Epoch 46/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0170 - val_loss: 0.0145\n",
      "Epoch 47/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0170 - val_loss: 0.0145\n",
      "Epoch 48/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0148\n",
      "Epoch 49/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0147\n",
      "Epoch 50/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0170 - val_loss: 0.0148\n",
      "Epoch 51/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0148\n",
      "Epoch 52/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0149\n",
      "Epoch 53/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0146\n",
      "Epoch 54/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0147\n",
      "Epoch 55/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0145\n",
      "Epoch 56/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0145\n",
      "Epoch 57/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0145\n",
      "Epoch 58/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0170 - val_loss: 0.0145\n",
      "Epoch 59/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0148\n",
      "Epoch 60/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0146\n",
      "Epoch 61/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0145\n",
      "Epoch 62/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0146\n",
      "Epoch 63/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0147\n",
      "Epoch 64/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0146\n",
      "Epoch 65/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0147\n",
      "Epoch 66/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0148\n",
      "Epoch 67/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0146\n",
      "Epoch 68/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0145\n",
      "Epoch 69/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0144\n",
      "Epoch 70/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0146\n",
      "Epoch 71/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0149\n",
      "Epoch 72/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0145\n",
      "Epoch 73/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0144\n",
      "Epoch 74/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0145\n",
      "Epoch 75/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0146\n",
      "Epoch 76/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0145\n",
      "Epoch 77/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0149\n",
      "Epoch 78/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0144\n",
      "Epoch 79/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0145\n",
      "Epoch 81/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0145\n",
      "Epoch 82/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0145\n",
      "Epoch 83/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0155\n",
      "Epoch 84/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0149\n",
      "Epoch 85/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0144\n",
      "Epoch 86/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0146\n",
      "Epoch 87/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0146\n",
      "Epoch 88/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0151\n",
      "Epoch 89/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0144\n",
      "Epoch 90/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0148\n",
      "Epoch 91/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0152\n",
      "Epoch 92/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0146\n",
      "Epoch 93/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0152\n",
      "Epoch 94/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0145\n",
      "Epoch 95/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0146\n",
      "Epoch 96/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0152\n",
      "Epoch 97/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0150\n",
      "Epoch 98/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0146\n",
      "Epoch 99/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0145\n",
      "Epoch 100/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0155\n",
      "Epoch 101/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0146\n",
      "Epoch 102/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0147\n",
      "Epoch 103/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0144\n",
      "Epoch 104/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0151\n",
      "Epoch 105/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0144\n",
      "Epoch 106/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0143\n",
      "Epoch 107/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0145\n",
      "Epoch 108/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0148\n",
      "Epoch 109/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0151\n",
      "Epoch 110/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0144\n",
      "Epoch 111/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0146\n",
      "Epoch 112/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0145\n",
      "Epoch 113/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0144\n",
      "Epoch 114/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0145\n",
      "Epoch 115/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0146\n",
      "Epoch 116/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0146\n",
      "Epoch 117/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0143\n",
      "Epoch 118/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0143\n",
      "Epoch 119/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0144\n",
      "Epoch 120/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0144\n",
      "Epoch 121/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0143\n",
      "Epoch 122/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0145\n",
      "Epoch 123/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0142\n",
      "Epoch 124/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0151\n",
      "Epoch 125/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0144\n",
      "Epoch 126/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0142\n",
      "Epoch 127/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0142\n",
      "Epoch 128/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0145\n",
      "Epoch 129/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0142\n",
      "Epoch 130/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0142\n",
      "Epoch 131/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0144\n",
      "Epoch 132/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0143\n",
      "Epoch 133/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0142\n",
      "Epoch 134/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0143\n",
      "Epoch 135/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0142\n",
      "Epoch 136/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0144\n",
      "Epoch 137/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0149\n",
      "Epoch 138/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0148\n",
      "Epoch 139/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0145\n",
      "Epoch 140/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0144\n",
      "Epoch 141/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0144\n",
      "Epoch 142/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0142\n",
      "Epoch 143/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0146\n",
      "Epoch 144/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0143\n",
      "Epoch 145/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0144\n",
      "Epoch 146/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0152\n",
      "Epoch 147/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0143\n",
      "Epoch 148/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0144\n",
      "Epoch 149/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0146\n",
      "Epoch 150/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0142\n",
      "Epoch 151/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0144\n",
      "Epoch 152/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0145\n",
      "Epoch 153/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0148\n",
      "Epoch 154/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0143\n",
      "Epoch 155/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0145\n",
      "Epoch 156/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0144\n",
      "Epoch 157/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0143\n",
      "Epoch 158/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0144\n",
      "Epoch 159/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0142\n",
      "Epoch 160/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0143\n",
      "Epoch 161/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0150\n",
      "Epoch 162/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0146\n",
      "Epoch 163/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0143\n",
      "Epoch 164/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0143\n",
      "Epoch 165/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0142\n",
      "Epoch 166/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0144\n",
      "Epoch 167/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0144\n",
      "Epoch 168/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0145\n",
      "Epoch 169/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0145\n",
      "Epoch 170/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0144\n",
      "Epoch 171/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0144\n",
      "Epoch 172/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0142\n",
      "Epoch 173/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0142\n",
      "Epoch 174/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0142\n",
      "Epoch 175/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0148\n",
      "Epoch 176/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0144\n",
      "Epoch 177/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0142\n",
      "Epoch 178/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0143\n",
      "Epoch 179/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0144\n",
      "Epoch 180/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0144\n",
      "Epoch 181/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0143\n",
      "Epoch 182/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0142\n",
      "Epoch 183/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0142\n",
      "Epoch 184/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0142\n",
      "Epoch 185/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0145\n",
      "Epoch 186/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0153\n",
      "Epoch 187/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0142\n",
      "Epoch 188/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0143\n",
      "Epoch 189/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0144\n",
      "Epoch 190/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0142\n",
      "Epoch 191/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0143\n",
      "Epoch 192/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0143\n",
      "Epoch 193/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0143\n",
      "Epoch 194/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0145\n",
      "Epoch 195/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0144\n",
      "Epoch 196/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0143\n",
      "Epoch 197/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0143\n",
      "Epoch 198/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0143\n",
      "Epoch 199/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0142\n",
      "Epoch 200/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0142\n",
      "Epoch 201/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0147\n",
      "Epoch 202/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0144\n",
      "Epoch 203/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0142\n",
      "Epoch 204/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0142\n",
      "Epoch 205/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0146\n",
      "Epoch 206/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0143\n",
      "Epoch 207/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0142\n",
      "Epoch 208/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0151\n",
      "Epoch 209/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0142\n",
      "Epoch 210/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0142\n",
      "Epoch 211/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0143\n",
      "Epoch 212/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0144\n",
      "Epoch 213/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0146\n",
      "Epoch 214/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0143\n",
      "Epoch 215/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0151\n",
      "Epoch 216/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0143\n",
      "Epoch 217/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0142\n",
      "Epoch 218/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0142\n",
      "Epoch 219/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0146\n",
      "Epoch 220/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0142\n",
      "Epoch 221/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0142\n",
      "Epoch 222/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0143\n",
      "Epoch 00222: early stopping\n",
      "Epoch 1/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.1612 - val_loss: 0.0308\n",
      "Epoch 2/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0525 - val_loss: 0.0187\n",
      "Epoch 3/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0354 - val_loss: 0.0155\n",
      "Epoch 4/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0299 - val_loss: 0.0146\n",
      "Epoch 5/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0270 - val_loss: 0.0134\n",
      "Epoch 6/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0240 - val_loss: 0.0113\n",
      "Epoch 7/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0213 - val_loss: 0.0094\n",
      "Epoch 8/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0201 - val_loss: 0.0104\n",
      "Epoch 9/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0193 - val_loss: 0.0093\n",
      "Epoch 10/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0188 - val_loss: 0.0092\n",
      "Epoch 11/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.0088\n",
      "Epoch 12/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0173 - val_loss: 0.0098\n",
      "Epoch 13/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0171 - val_loss: 0.0089\n",
      "Epoch 14/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0089\n",
      "Epoch 15/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0094\n",
      "Epoch 16/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0088\n",
      "Epoch 17/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0087\n",
      "Epoch 18/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0096\n",
      "Epoch 19/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0145 - val_loss: 0.0089\n",
      "Epoch 20/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.0086\n",
      "Epoch 21/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0143 - val_loss: 0.0087\n",
      "Epoch 22/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0088\n",
      "Epoch 23/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.0084\n",
      "Epoch 24/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.0085\n",
      "Epoch 25/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.0087\n",
      "Epoch 26/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.0089\n",
      "Epoch 27/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.0089\n",
      "Epoch 28/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.0085\n",
      "Epoch 29/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.0097\n",
      "Epoch 30/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0088\n",
      "Epoch 31/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.0084\n",
      "Epoch 32/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.0087\n",
      "Epoch 33/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0085\n",
      "Epoch 34/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.0084\n",
      "Epoch 35/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.0087\n",
      "Epoch 36/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.0083\n",
      "Epoch 37/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0087\n",
      "Epoch 38/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0085\n",
      "Epoch 39/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.0093\n",
      "Epoch 40/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.0086\n",
      "Epoch 41/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.0088\n",
      "Epoch 42/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.0086\n",
      "Epoch 43/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.0087\n",
      "Epoch 44/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.0084\n",
      "Epoch 45/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.0091\n",
      "Epoch 46/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0084\n",
      "Epoch 47/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.0085\n",
      "Epoch 48/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.0095\n",
      "Epoch 49/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.0085\n",
      "Epoch 50/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0087\n",
      "Epoch 51/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.0084\n",
      "Epoch 52/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0086\n",
      "Epoch 53/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.0087\n",
      "Epoch 54/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.0085\n",
      "Epoch 55/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0090\n",
      "Epoch 56/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.0085\n",
      "Epoch 57/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0085\n",
      "Epoch 58/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.0085\n",
      "Epoch 59/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0089\n",
      "Epoch 60/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.0087\n",
      "Epoch 61/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.0087\n",
      "Epoch 62/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.0085\n",
      "Epoch 63/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.0086\n",
      "Epoch 64/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0084\n",
      "Epoch 65/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.0084\n",
      "Epoch 66/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0091\n",
      "Epoch 67/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.0091\n",
      "Epoch 68/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0084\n",
      "Epoch 69/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0084\n",
      "Epoch 70/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0090\n",
      "Epoch 71/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.0084\n",
      "Epoch 72/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0087\n",
      "Epoch 73/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.0086\n",
      "Epoch 74/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0085\n",
      "Epoch 75/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0084\n",
      "Epoch 76/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0088\n",
      "Epoch 77/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0086\n",
      "Epoch 78/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0091\n",
      "Epoch 79/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0082\n",
      "Epoch 80/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.0084\n",
      "Epoch 81/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0082\n",
      "Epoch 82/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0084\n",
      "Epoch 83/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0083\n",
      "Epoch 84/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0083\n",
      "Epoch 85/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0086\n",
      "Epoch 86/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0084\n",
      "Epoch 87/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0087\n",
      "Epoch 88/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0084\n",
      "Epoch 89/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0088\n",
      "Epoch 90/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0086\n",
      "Epoch 91/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0089\n",
      "Epoch 92/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0084\n",
      "Epoch 94/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0087\n",
      "Epoch 95/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0094\n",
      "Epoch 96/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0084\n",
      "Epoch 97/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0093\n",
      "Epoch 98/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0086\n",
      "Epoch 99/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0085\n",
      "Epoch 100/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0090\n",
      "Epoch 101/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0092\n",
      "Epoch 102/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0086\n",
      "Epoch 103/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0086\n",
      "Epoch 104/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0083\n",
      "Epoch 105/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0084\n",
      "Epoch 106/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0084\n",
      "Epoch 107/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0082\n",
      "Epoch 108/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0085\n",
      "Epoch 109/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0085\n",
      "Epoch 110/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0085\n",
      "Epoch 111/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0082\n",
      "Epoch 112/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0083\n",
      "Epoch 113/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0082\n",
      "Epoch 114/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0083\n",
      "Epoch 115/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0083\n",
      "Epoch 116/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0088\n",
      "Epoch 117/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0088\n",
      "Epoch 118/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0089\n",
      "Epoch 119/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0090\n",
      "Epoch 120/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0084\n",
      "Epoch 121/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0086\n",
      "Epoch 122/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0085\n",
      "Epoch 123/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0085\n",
      "Epoch 124/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0087\n",
      "Epoch 125/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0093\n",
      "Epoch 126/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0085\n",
      "Epoch 127/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0082\n",
      "Epoch 128/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0085\n",
      "Epoch 129/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0084\n",
      "Epoch 130/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0086\n",
      "Epoch 131/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0081\n",
      "Epoch 132/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0084\n",
      "Epoch 133/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0082\n",
      "Epoch 134/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0086\n",
      "Epoch 135/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0081\n",
      "Epoch 136/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0082\n",
      "Epoch 137/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0083\n",
      "Epoch 138/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0084\n",
      "Epoch 139/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0091\n",
      "Epoch 140/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0083\n",
      "Epoch 141/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0087\n",
      "Epoch 142/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0089\n",
      "Epoch 143/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0082\n",
      "Epoch 144/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0086\n",
      "Epoch 145/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0081\n",
      "Epoch 146/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0086\n",
      "Epoch 147/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0086\n",
      "Epoch 148/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0083\n",
      "Epoch 149/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0081\n",
      "Epoch 150/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0082\n",
      "Epoch 151/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0084\n",
      "Epoch 152/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0090\n",
      "Epoch 153/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0088\n",
      "Epoch 154/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0088\n",
      "Epoch 155/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0084\n",
      "Epoch 156/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0083\n",
      "Epoch 157/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0081\n",
      "Epoch 158/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0082\n",
      "Epoch 159/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0082\n",
      "Epoch 160/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0082\n",
      "Epoch 161/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0089\n",
      "Epoch 162/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0083\n",
      "Epoch 163/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0083\n",
      "Epoch 164/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0084\n",
      "Epoch 165/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0082\n",
      "Epoch 166/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0081\n",
      "Epoch 167/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0084\n",
      "Epoch 168/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0082\n",
      "Epoch 169/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0081\n",
      "Epoch 170/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0082\n",
      "Epoch 171/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0087\n",
      "Epoch 172/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0087\n",
      "Epoch 173/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0084\n",
      "Epoch 174/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0083\n",
      "Epoch 175/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0083\n",
      "Epoch 176/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0082\n",
      "Epoch 177/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0082\n",
      "Epoch 178/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0082\n",
      "Epoch 179/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0094\n",
      "Epoch 180/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0083\n",
      "Epoch 181/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0083\n",
      "Epoch 182/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0082\n",
      "Epoch 183/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0084\n",
      "Epoch 184/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0082\n",
      "Epoch 185/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0082\n",
      "Epoch 186/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0084\n",
      "Epoch 187/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0083\n",
      "Epoch 188/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0085\n",
      "Epoch 189/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0084\n",
      "Epoch 190/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0085\n",
      "Epoch 191/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0083\n",
      "Epoch 192/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0084\n",
      "Epoch 193/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0088\n",
      "Epoch 194/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0086\n",
      "Epoch 195/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0083\n",
      "Epoch 196/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0082\n",
      "Epoch 197/10000\n",
      "151/151 [==============================] - ETA: 0s - loss: 0.011 - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0082\n",
      "Epoch 198/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0083\n",
      "Epoch 199/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0084\n",
      "Epoch 200/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0082\n",
      "Epoch 201/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0083\n",
      "Epoch 202/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0090\n",
      "Epoch 203/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0089\n",
      "Epoch 204/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0083\n",
      "Epoch 205/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0086\n",
      "Epoch 206/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0082\n",
      "Epoch 207/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0083\n",
      "Epoch 208/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0088\n",
      "Epoch 209/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0083\n",
      "Epoch 210/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0082\n",
      "Epoch 211/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0082\n",
      "Epoch 212/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0082\n",
      "Epoch 213/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0082\n",
      "Epoch 214/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0086\n",
      "Epoch 215/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0082\n",
      "Epoch 216/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0088\n",
      "Epoch 00216: early stopping\n",
      "Epoch 1/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.2035 - val_loss: 0.0312\n",
      "Epoch 2/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0567 - val_loss: 0.0210\n",
      "Epoch 3/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0383 - val_loss: 0.0155\n",
      "Epoch 4/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0309 - val_loss: 0.0131\n",
      "Epoch 5/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0273 - val_loss: 0.0109\n",
      "Epoch 6/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0237 - val_loss: 0.0101\n",
      "Epoch 7/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0219 - val_loss: 0.0098\n",
      "Epoch 8/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0205 - val_loss: 0.0090\n",
      "Epoch 9/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0197 - val_loss: 0.0092\n",
      "Epoch 10/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0188 - val_loss: 0.0097\n",
      "Epoch 11/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0181 - val_loss: 0.0109\n",
      "Epoch 12/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0175 - val_loss: 0.0085\n",
      "Epoch 13/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0084\n",
      "Epoch 14/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0072\n",
      "Epoch 15/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0064\n",
      "Epoch 16/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.0058\n",
      "Epoch 17/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.0061\n",
      "Epoch 18/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.0056\n",
      "Epoch 19/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.0059\n",
      "Epoch 20/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0130 - val_loss: 0.0056\n",
      "Epoch 21/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.0054\n",
      "Epoch 22/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.0056\n",
      "Epoch 23/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.0054\n",
      "Epoch 24/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.0056\n",
      "Epoch 25/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0053\n",
      "Epoch 26/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0063\n",
      "Epoch 27/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0053\n",
      "Epoch 28/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.0057\n",
      "Epoch 29/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0056\n",
      "Epoch 30/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0054\n",
      "Epoch 31/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0052\n",
      "Epoch 32/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0053\n",
      "Epoch 33/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0052\n",
      "Epoch 34/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0060\n",
      "Epoch 35/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0053\n",
      "Epoch 36/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0053\n",
      "Epoch 37/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0054\n",
      "Epoch 38/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0059\n",
      "Epoch 39/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0055\n",
      "Epoch 40/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0053\n",
      "Epoch 41/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0061\n",
      "Epoch 42/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0056\n",
      "Epoch 43/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0052\n",
      "Epoch 44/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0054\n",
      "Epoch 45/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0051\n",
      "Epoch 46/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0051\n",
      "Epoch 47/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0054\n",
      "Epoch 48/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0054\n",
      "Epoch 49/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0056\n",
      "Epoch 50/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0054\n",
      "Epoch 51/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0051\n",
      "Epoch 52/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0055\n",
      "Epoch 53/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0055\n",
      "Epoch 54/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0052\n",
      "Epoch 55/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0054\n",
      "Epoch 56/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0066\n",
      "Epoch 57/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0053\n",
      "Epoch 58/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0053\n",
      "Epoch 59/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0052\n",
      "Epoch 60/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0054\n",
      "Epoch 61/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0056\n",
      "Epoch 62/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0053\n",
      "Epoch 63/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0054\n",
      "Epoch 64/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0051\n",
      "Epoch 65/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0054\n",
      "Epoch 66/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0051\n",
      "Epoch 67/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0053\n",
      "Epoch 68/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0055\n",
      "Epoch 69/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0057\n",
      "Epoch 70/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0055\n",
      "Epoch 71/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0052\n",
      "Epoch 72/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0051\n",
      "Epoch 73/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0052\n",
      "Epoch 74/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0055\n",
      "Epoch 75/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0051\n",
      "Epoch 76/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0065\n",
      "Epoch 77/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0053\n",
      "Epoch 78/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0052\n",
      "Epoch 79/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0053\n",
      "Epoch 80/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0064\n",
      "Epoch 81/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0053\n",
      "Epoch 82/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0051\n",
      "Epoch 83/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0050\n",
      "Epoch 84/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0050\n",
      "Epoch 85/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0050\n",
      "Epoch 86/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0051\n",
      "Epoch 87/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0050\n",
      "Epoch 88/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0050\n",
      "Epoch 89/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0051\n",
      "Epoch 90/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0051\n",
      "Epoch 91/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0061\n",
      "Epoch 92/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0049\n",
      "Epoch 93/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0051\n",
      "Epoch 94/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0050\n",
      "Epoch 95/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0057\n",
      "Epoch 96/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0050\n",
      "Epoch 97/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0057\n",
      "Epoch 98/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0051\n",
      "Epoch 99/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0051\n",
      "Epoch 100/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0050\n",
      "Epoch 101/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0051\n",
      "Epoch 102/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0061\n",
      "Epoch 103/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0051\n",
      "Epoch 104/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0052\n",
      "Epoch 105/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0053\n",
      "Epoch 106/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0049\n",
      "Epoch 107/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0054\n",
      "Epoch 108/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0055\n",
      "Epoch 109/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0049\n",
      "Epoch 110/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0052\n",
      "Epoch 111/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0051\n",
      "Epoch 113/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0051\n",
      "Epoch 114/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0052\n",
      "Epoch 115/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0055\n",
      "Epoch 116/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0051\n",
      "Epoch 117/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0051\n",
      "Epoch 118/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0050\n",
      "Epoch 119/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0052\n",
      "Epoch 120/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0051\n",
      "Epoch 121/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0051\n",
      "Epoch 122/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0052\n",
      "Epoch 123/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0054\n",
      "Epoch 124/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0053\n",
      "Epoch 125/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0054\n",
      "Epoch 126/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0054\n",
      "Epoch 127/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0055\n",
      "Epoch 128/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0049\n",
      "Epoch 129/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0051\n",
      "Epoch 130/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0050\n",
      "Epoch 131/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0048\n",
      "Epoch 132/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0049\n",
      "Epoch 133/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0049\n",
      "Epoch 134/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0049\n",
      "Epoch 135/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0059\n",
      "Epoch 136/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0050\n",
      "Epoch 137/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0050\n",
      "Epoch 138/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0060\n",
      "Epoch 139/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0050\n",
      "Epoch 140/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0051\n",
      "Epoch 141/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0058\n",
      "Epoch 142/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0054\n",
      "Epoch 143/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0050\n",
      "Epoch 144/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0049\n",
      "Epoch 145/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0053\n",
      "Epoch 146/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0054\n",
      "Epoch 147/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0052\n",
      "Epoch 148/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0050\n",
      "Epoch 149/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0050\n",
      "Epoch 150/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0056\n",
      "Epoch 151/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0058\n",
      "Epoch 152/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0051\n",
      "Epoch 153/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0051\n",
      "Epoch 154/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0051\n",
      "Epoch 155/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0050\n",
      "Epoch 156/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0050\n",
      "Epoch 157/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0051\n",
      "Epoch 158/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0052\n",
      "Epoch 159/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0050\n",
      "Epoch 160/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0050\n",
      "Epoch 161/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0051\n",
      "Epoch 162/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0050\n",
      "Epoch 163/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0050\n",
      "Epoch 164/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0050\n",
      "Epoch 165/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0052\n",
      "Epoch 166/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0052\n",
      "Epoch 167/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0052\n",
      "Epoch 168/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0050\n",
      "Epoch 169/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0051\n",
      "Epoch 170/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0051\n",
      "Epoch 171/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0049\n",
      "Epoch 172/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0051\n",
      "Epoch 173/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0050\n",
      "Epoch 174/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0051\n",
      "Epoch 175/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0052\n",
      "Epoch 176/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 177/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0050\n",
      "Epoch 178/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0053\n",
      "Epoch 179/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0050\n",
      "Epoch 180/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0050\n",
      "Epoch 181/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0056\n",
      "Epoch 00181: early stopping\n",
      "Epoch 1/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.1724 - val_loss: 0.0267\n",
      "Epoch 2/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0163\n",
      "Epoch 3/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0366 - val_loss: 0.0140\n",
      "Epoch 4/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0303 - val_loss: 0.0119\n",
      "Epoch 5/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0258 - val_loss: 0.0098\n",
      "Epoch 6/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0219 - val_loss: 0.0075\n",
      "Epoch 7/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0199 - val_loss: 0.0065\n",
      "Epoch 8/10000\n",
      "151/151 [==============================] - ETA: 0s - loss: 0.018 - 0s 1ms/step - loss: 0.0184 - val_loss: 0.0062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.0063\n",
      "Epoch 10/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0060\n",
      "Epoch 11/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0063\n",
      "Epoch 12/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0055\n",
      "Epoch 13/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0058\n",
      "Epoch 14/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0143 - val_loss: 0.0062\n",
      "Epoch 15/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0055\n",
      "Epoch 16/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.0053\n",
      "Epoch 17/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.0066\n",
      "Epoch 18/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0130 - val_loss: 0.0052\n",
      "Epoch 19/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.0053\n",
      "Epoch 20/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.0056\n",
      "Epoch 21/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.0056\n",
      "Epoch 22/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0061\n",
      "Epoch 23/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0051\n",
      "Epoch 24/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0058\n",
      "Epoch 25/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.0052\n",
      "Epoch 26/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.0050\n",
      "Epoch 27/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0048\n",
      "Epoch 28/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0051\n",
      "Epoch 29/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0046\n",
      "Epoch 30/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0043\n",
      "Epoch 31/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0047\n",
      "Epoch 32/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0044\n",
      "Epoch 33/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0044\n",
      "Epoch 34/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0045\n",
      "Epoch 35/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0042\n",
      "Epoch 36/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0045\n",
      "Epoch 37/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0045\n",
      "Epoch 38/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0048\n",
      "Epoch 39/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0042\n",
      "Epoch 40/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 41/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0044\n",
      "Epoch 42/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0048\n",
      "Epoch 43/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0043\n",
      "Epoch 44/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0042\n",
      "Epoch 45/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 46/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0044\n",
      "Epoch 47/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0044\n",
      "Epoch 48/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0043\n",
      "Epoch 49/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0045\n",
      "Epoch 50/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 51/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0044\n",
      "Epoch 52/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0044\n",
      "Epoch 53/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 54/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0046\n",
      "Epoch 55/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0049\n",
      "Epoch 56/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0054\n",
      "Epoch 57/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0042\n",
      "Epoch 58/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0043\n",
      "Epoch 59/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0044\n",
      "Epoch 60/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0043\n",
      "Epoch 61/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0044\n",
      "Epoch 62/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0044\n",
      "Epoch 63/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0042\n",
      "Epoch 64/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0043\n",
      "Epoch 65/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0042\n",
      "Epoch 66/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0041\n",
      "Epoch 67/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0041\n",
      "Epoch 68/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0042\n",
      "Epoch 69/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0043\n",
      "Epoch 70/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0041\n",
      "Epoch 71/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0043\n",
      "Epoch 72/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0044\n",
      "Epoch 73/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0045\n",
      "Epoch 74/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0047\n",
      "Epoch 75/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0045\n",
      "Epoch 76/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0043\n",
      "Epoch 77/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0042\n",
      "Epoch 78/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0043\n",
      "Epoch 79/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0042\n",
      "Epoch 80/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0040\n",
      "Epoch 81/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0040\n",
      "Epoch 82/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0040\n",
      "Epoch 83/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0043\n",
      "Epoch 84/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0047\n",
      "Epoch 85/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0045\n",
      "Epoch 86/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0045\n",
      "Epoch 87/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0042\n",
      "Epoch 89/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0045\n",
      "Epoch 90/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0042\n",
      "Epoch 91/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0043\n",
      "Epoch 92/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0043\n",
      "Epoch 93/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0041\n",
      "Epoch 94/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0040\n",
      "Epoch 95/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0049\n",
      "Epoch 96/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0045\n",
      "Epoch 97/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 98/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0043\n",
      "Epoch 99/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0042\n",
      "Epoch 100/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0043\n",
      "Epoch 101/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0042\n",
      "Epoch 102/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0046\n",
      "Epoch 103/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0041\n",
      "Epoch 104/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0046\n",
      "Epoch 105/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0042\n",
      "Epoch 106/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0041\n",
      "Epoch 107/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0047\n",
      "Epoch 108/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0041\n",
      "Epoch 109/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0041\n",
      "Epoch 110/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0041\n",
      "Epoch 111/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0049\n",
      "Epoch 112/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0041\n",
      "Epoch 113/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0042\n",
      "Epoch 114/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0041\n",
      "Epoch 115/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0042\n",
      "Epoch 116/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0043\n",
      "Epoch 117/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0041\n",
      "Epoch 118/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0047\n",
      "Epoch 119/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0046\n",
      "Epoch 120/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0044\n",
      "Epoch 121/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0040\n",
      "Epoch 122/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0039\n",
      "Epoch 123/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0041\n",
      "Epoch 124/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0044\n",
      "Epoch 125/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0040\n",
      "Epoch 126/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0045\n",
      "Epoch 127/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0041\n",
      "Epoch 128/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0042\n",
      "Epoch 129/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0040\n",
      "Epoch 130/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0042\n",
      "Epoch 131/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0042\n",
      "Epoch 132/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0040\n",
      "Epoch 133/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0039\n",
      "Epoch 134/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0043\n",
      "Epoch 135/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0042\n",
      "Epoch 136/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0039\n",
      "Epoch 137/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0043\n",
      "Epoch 138/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0042\n",
      "Epoch 139/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0043\n",
      "Epoch 140/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0042\n",
      "Epoch 141/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0047\n",
      "Epoch 142/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0040\n",
      "Epoch 143/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0049\n",
      "Epoch 144/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0047\n",
      "Epoch 145/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0040\n",
      "Epoch 146/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0039\n",
      "Epoch 147/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0042\n",
      "Epoch 148/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0044\n",
      "Epoch 149/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0042\n",
      "Epoch 150/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0042\n",
      "Epoch 151/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0046\n",
      "Epoch 152/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0044\n",
      "Epoch 153/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0042\n",
      "Epoch 154/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0051\n",
      "Epoch 155/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0043\n",
      "Epoch 156/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0041\n",
      "Epoch 157/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0044\n",
      "Epoch 158/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0042\n",
      "Epoch 159/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0044\n",
      "Epoch 160/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0040\n",
      "Epoch 161/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0042\n",
      "Epoch 162/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0041\n",
      "Epoch 163/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0043\n",
      "Epoch 164/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0042\n",
      "Epoch 165/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0043\n",
      "Epoch 166/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0040\n",
      "Epoch 167/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0044\n",
      "Epoch 168/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0043\n",
      "Epoch 169/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0043\n",
      "Epoch 170/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0040\n",
      "Epoch 171/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0039\n",
      "Epoch 172/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0042\n",
      "Epoch 173/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0042\n",
      "Epoch 174/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0043\n",
      "Epoch 175/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0044\n",
      "Epoch 176/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0043\n",
      "Epoch 177/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0043\n",
      "Epoch 178/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0041\n",
      "Epoch 179/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0046\n",
      "Epoch 180/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0040\n",
      "Epoch 181/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0041\n",
      "Epoch 182/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0042\n",
      "Epoch 183/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0040\n",
      "Epoch 184/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0040\n",
      "Epoch 185/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0041\n",
      "Epoch 186/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0040\n",
      "Epoch 187/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0042\n",
      "Epoch 188/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0040\n",
      "Epoch 189/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0040\n",
      "Epoch 190/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0041\n",
      "Epoch 191/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0041\n",
      "Epoch 192/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0040\n",
      "Epoch 193/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0040\n",
      "Epoch 194/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0044\n",
      "Epoch 195/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0041\n",
      "Epoch 196/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0039\n",
      "Epoch 197/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0040\n",
      "Epoch 198/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0045\n",
      "Epoch 199/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0044\n",
      "Epoch 200/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0040\n",
      "Epoch 201/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0044\n",
      "Epoch 202/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0040\n",
      "Epoch 203/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0043\n",
      "Epoch 204/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0043\n",
      "Epoch 205/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0043\n",
      "Epoch 206/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0046\n",
      "Epoch 207/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0048\n",
      "Epoch 208/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0043\n",
      "Epoch 209/10000\n",
      "151/151 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0040\n",
      "Epoch 210/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0041\n",
      "Epoch 211/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0043\n",
      "Epoch 212/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0042\n",
      "Epoch 213/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0039\n",
      "Epoch 214/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0060\n",
      "Epoch 215/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0041\n",
      "Epoch 216/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0041\n",
      "Epoch 217/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0039\n",
      "Epoch 218/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0043\n",
      "Epoch 219/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0041\n",
      "Epoch 220/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0040\n",
      "Epoch 221/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0041\n",
      "Epoch 222/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0044\n",
      "Epoch 223/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0040\n",
      "Epoch 224/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0043\n",
      "Epoch 225/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0043\n",
      "Epoch 226/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0042\n",
      "Epoch 227/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0039\n",
      "Epoch 228/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0041\n",
      "Epoch 229/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0045\n",
      "Epoch 230/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0046\n",
      "Epoch 231/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0041\n",
      "Epoch 232/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0048\n",
      "Epoch 233/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0040\n",
      "Epoch 234/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0041\n",
      "Epoch 235/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0040\n",
      "Epoch 236/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0045\n",
      "Epoch 237/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0041\n",
      "Epoch 238/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0040\n",
      "Epoch 239/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0043\n",
      "Epoch 240/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0041\n",
      "Epoch 241/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0039\n",
      "Epoch 242/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0046\n",
      "Epoch 243/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0047\n",
      "Epoch 244/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0042\n",
      "Epoch 245/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0045\n",
      "Epoch 246/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0039\n",
      "Epoch 247/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0042\n",
      "Epoch 248/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0045\n",
      "Epoch 249/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0039\n",
      "Epoch 250/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0042\n",
      "Epoch 251/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0044\n",
      "Epoch 252/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0045\n",
      "Epoch 253/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0043\n",
      "Epoch 254/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0042\n",
      "Epoch 255/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0042\n",
      "Epoch 256/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0042\n",
      "Epoch 257/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0048\n",
      "Epoch 258/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0039\n",
      "Epoch 259/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0042\n",
      "Epoch 260/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0041\n",
      "Epoch 261/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0053\n",
      "Epoch 262/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0041\n",
      "Epoch 263/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0042\n",
      "Epoch 264/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0050\n",
      "Epoch 265/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0041\n",
      "Epoch 266/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0040\n",
      "Epoch 267/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0046\n",
      "Epoch 268/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0040\n",
      "Epoch 269/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0039\n",
      "Epoch 270/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0044\n",
      "Epoch 271/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0044\n",
      "Epoch 272/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0045\n",
      "Epoch 273/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0042\n",
      "Epoch 274/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0049\n",
      "Epoch 275/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0040\n",
      "Epoch 276/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0041\n",
      "Epoch 277/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0043\n",
      "Epoch 278/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0042\n",
      "Epoch 279/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0043\n",
      "Epoch 280/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0038\n",
      "Epoch 281/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0042\n",
      "Epoch 282/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0038\n",
      "Epoch 283/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0056\n",
      "Epoch 284/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0042\n",
      "Epoch 285/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0040\n",
      "Epoch 286/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0041\n",
      "Epoch 287/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0042\n",
      "Epoch 288/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0044\n",
      "Epoch 289/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0039\n",
      "Epoch 290/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0041\n",
      "Epoch 291/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0038\n",
      "Epoch 292/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0043\n",
      "Epoch 293/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0040\n",
      "Epoch 294/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0043\n",
      "Epoch 295/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0040\n",
      "Epoch 296/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0040\n",
      "Epoch 297/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0041\n",
      "Epoch 298/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0044\n",
      "Epoch 299/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0039\n",
      "Epoch 300/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0041\n",
      "Epoch 301/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0042\n",
      "Epoch 302/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0041\n",
      "Epoch 303/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0041\n",
      "Epoch 304/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0040\n",
      "Epoch 305/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0042\n",
      "Epoch 306/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0041\n",
      "Epoch 307/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0046\n",
      "Epoch 308/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0040\n",
      "Epoch 309/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0045\n",
      "Epoch 310/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0042\n",
      "Epoch 311/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0043\n",
      "Epoch 312/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0044\n",
      "Epoch 313/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0044\n",
      "Epoch 314/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0042\n",
      "Epoch 315/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0039\n",
      "Epoch 316/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0040\n",
      "Epoch 317/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0044\n",
      "Epoch 318/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0041\n",
      "Epoch 319/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0041\n",
      "Epoch 320/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0043\n",
      "Epoch 321/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0041\n",
      "Epoch 322/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0040\n",
      "Epoch 323/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0040\n",
      "Epoch 324/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0040\n",
      "Epoch 325/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0039\n",
      "Epoch 326/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0041\n",
      "Epoch 327/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0041\n",
      "Epoch 328/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0044\n",
      "Epoch 329/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0043\n",
      "Epoch 330/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0041\n",
      "Epoch 00330: early stopping\n",
      "Epoch 1/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.1721 - val_loss: 0.0256\n",
      "Epoch 2/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0511 - val_loss: 0.0172\n",
      "Epoch 3/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0159\n",
      "Epoch 4/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0304 - val_loss: 0.0128\n",
      "Epoch 5/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0264 - val_loss: 0.0107\n",
      "Epoch 6/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0229 - val_loss: 0.0088\n",
      "Epoch 7/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0203 - val_loss: 0.0080\n",
      "Epoch 8/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0189 - val_loss: 0.0064\n",
      "Epoch 9/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0176 - val_loss: 0.0069\n",
      "Epoch 10/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0060\n",
      "Epoch 11/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0059\n",
      "Epoch 12/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0060\n",
      "Epoch 13/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0058\n",
      "Epoch 14/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0055\n",
      "Epoch 15/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.0059\n",
      "Epoch 16/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.0054\n",
      "Epoch 17/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.0061\n",
      "Epoch 18/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.0056\n",
      "Epoch 19/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.0055\n",
      "Epoch 20/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0055\n",
      "Epoch 21/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.0054\n",
      "Epoch 22/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0056\n",
      "Epoch 23/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0051\n",
      "Epoch 24/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0056\n",
      "Epoch 25/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0055\n",
      "Epoch 26/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0056\n",
      "Epoch 27/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.0052\n",
      "Epoch 28/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0052\n",
      "Epoch 29/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0053\n",
      "Epoch 30/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0049\n",
      "Epoch 31/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0048\n",
      "Epoch 32/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0048\n",
      "Epoch 33/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0047\n",
      "Epoch 34/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0045\n",
      "Epoch 35/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0046\n",
      "Epoch 36/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0043\n",
      "Epoch 37/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0045\n",
      "Epoch 38/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0041\n",
      "Epoch 39/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0043\n",
      "Epoch 40/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0047\n",
      "Epoch 41/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0042\n",
      "Epoch 42/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0044\n",
      "Epoch 43/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0042\n",
      "Epoch 44/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0044\n",
      "Epoch 45/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0042\n",
      "Epoch 46/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0045\n",
      "Epoch 47/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0048\n",
      "Epoch 48/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0051\n",
      "Epoch 49/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0043\n",
      "Epoch 50/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0043\n",
      "Epoch 51/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0043\n",
      "Epoch 52/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0042\n",
      "Epoch 53/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0041\n",
      "Epoch 54/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 55/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0050\n",
      "Epoch 56/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0041\n",
      "Epoch 57/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 58/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0051\n",
      "Epoch 59/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 60/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0042\n",
      "Epoch 61/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0046\n",
      "Epoch 62/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0042\n",
      "Epoch 63/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0042\n",
      "Epoch 64/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0042\n",
      "Epoch 65/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0042\n",
      "Epoch 66/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0042\n",
      "Epoch 67/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0050\n",
      "Epoch 68/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0043\n",
      "Epoch 69/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0043\n",
      "Epoch 70/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0044\n",
      "Epoch 71/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0045\n",
      "Epoch 72/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0044\n",
      "Epoch 73/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0045\n",
      "Epoch 74/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0042\n",
      "Epoch 75/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0044\n",
      "Epoch 76/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0045\n",
      "Epoch 77/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 78/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0044\n",
      "Epoch 79/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0044\n",
      "Epoch 80/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0041\n",
      "Epoch 81/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0041\n",
      "Epoch 82/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 83/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0043\n",
      "Epoch 84/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0049\n",
      "Epoch 85/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0041\n",
      "Epoch 86/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0048\n",
      "Epoch 87/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0044\n",
      "Epoch 88/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0045\n",
      "Epoch 89/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0042\n",
      "Epoch 90/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0041\n",
      "Epoch 91/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 92/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0054\n",
      "Epoch 93/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0043\n",
      "Epoch 94/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0043\n",
      "Epoch 95/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0047\n",
      "Epoch 96/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0043\n",
      "Epoch 97/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0043\n",
      "Epoch 98/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0049\n",
      "Epoch 99/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0049\n",
      "Epoch 100/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0043\n",
      "Epoch 101/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 102/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0044\n",
      "Epoch 103/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0045\n",
      "Epoch 104/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0049\n",
      "Epoch 105/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0048\n",
      "Epoch 106/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0043\n",
      "Epoch 107/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0049\n",
      "Epoch 108/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0046\n",
      "Epoch 109/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0040\n",
      "Epoch 110/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0041\n",
      "Epoch 111/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0045\n",
      "Epoch 112/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0044\n",
      "Epoch 113/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0041\n",
      "Epoch 114/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0042\n",
      "Epoch 115/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0042\n",
      "Epoch 116/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0041\n",
      "Epoch 117/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 118/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0041\n",
      "Epoch 119/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0043\n",
      "Epoch 120/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0045\n",
      "Epoch 121/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0047\n",
      "Epoch 122/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0041\n",
      "Epoch 123/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0043\n",
      "Epoch 124/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0041\n",
      "Epoch 125/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0044\n",
      "Epoch 126/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0045\n",
      "Epoch 127/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0043\n",
      "Epoch 128/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0041\n",
      "Epoch 129/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0054\n",
      "Epoch 130/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0044\n",
      "Epoch 131/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0041\n",
      "Epoch 132/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0043\n",
      "Epoch 133/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0046\n",
      "Epoch 134/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0042\n",
      "Epoch 135/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0040\n",
      "Epoch 136/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0045\n",
      "Epoch 137/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0042\n",
      "Epoch 138/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0044\n",
      "Epoch 139/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0053\n",
      "Epoch 140/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0041\n",
      "Epoch 141/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0046\n",
      "Epoch 142/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0042\n",
      "Epoch 143/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0049\n",
      "Epoch 144/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0040\n",
      "Epoch 145/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0044\n",
      "Epoch 146/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0046\n",
      "Epoch 147/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0043\n",
      "Epoch 148/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0043\n",
      "Epoch 149/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0042\n",
      "Epoch 150/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0044\n",
      "Epoch 151/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0042\n",
      "Epoch 152/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0040\n",
      "Epoch 153/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0051\n",
      "Epoch 154/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0043\n",
      "Epoch 155/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0046\n",
      "Epoch 156/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0045\n",
      "Epoch 157/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0040\n",
      "Epoch 158/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0043\n",
      "Epoch 159/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0040\n",
      "Epoch 160/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0042\n",
      "Epoch 161/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0044\n",
      "Epoch 162/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0040\n",
      "Epoch 163/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0043\n",
      "Epoch 164/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0040\n",
      "Epoch 165/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0042\n",
      "Epoch 166/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0041\n",
      "Epoch 167/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0043\n",
      "Epoch 168/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0040\n",
      "Epoch 169/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0042\n",
      "Epoch 170/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0045\n",
      "Epoch 171/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0044\n",
      "Epoch 172/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0045\n",
      "Epoch 173/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0043\n",
      "Epoch 174/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0044\n",
      "Epoch 175/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0042\n",
      "Epoch 176/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0041\n",
      "Epoch 177/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0046\n",
      "Epoch 178/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0043\n",
      "Epoch 179/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0043\n",
      "Epoch 180/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0042\n",
      "Epoch 181/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0042\n",
      "Epoch 182/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0044\n",
      "Epoch 183/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0043\n",
      "Epoch 184/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0039\n",
      "Epoch 185/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0042\n",
      "Epoch 186/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0040\n",
      "Epoch 187/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0039\n",
      "Epoch 188/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0041\n",
      "Epoch 189/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0044\n",
      "Epoch 190/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0041\n",
      "Epoch 191/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0042\n",
      "Epoch 192/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0040\n",
      "Epoch 193/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0039\n",
      "Epoch 194/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0042\n",
      "Epoch 195/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0042\n",
      "Epoch 196/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0041\n",
      "Epoch 197/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0041\n",
      "Epoch 198/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0043\n",
      "Epoch 199/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0041\n",
      "Epoch 200/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0047\n",
      "Epoch 201/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0041\n",
      "Epoch 202/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0041\n",
      "Epoch 203/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0042\n",
      "Epoch 204/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0041\n",
      "Epoch 205/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0043\n",
      "Epoch 206/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0046\n",
      "Epoch 207/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0048\n",
      "Epoch 208/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0041\n",
      "Epoch 209/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0043\n",
      "Epoch 210/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0040\n",
      "Epoch 211/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0044\n",
      "Epoch 212/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0040\n",
      "Epoch 213/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0042\n",
      "Epoch 214/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0045\n",
      "Epoch 215/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0042\n",
      "Epoch 216/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0043\n",
      "Epoch 217/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0040\n",
      "Epoch 218/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0041\n",
      "Epoch 219/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0044\n",
      "Epoch 220/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0052\n",
      "Epoch 221/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0041\n",
      "Epoch 222/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0044\n",
      "Epoch 223/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0041\n",
      "Epoch 224/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0040\n",
      "Epoch 225/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0052\n",
      "Epoch 226/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0040\n",
      "Epoch 227/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0045\n",
      "Epoch 228/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0040\n",
      "Epoch 229/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0040\n",
      "Epoch 230/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0045\n",
      "Epoch 231/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0038\n",
      "Epoch 232/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0044\n",
      "Epoch 233/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0040\n",
      "Epoch 234/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0042\n",
      "Epoch 235/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0042\n",
      "Epoch 236/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0040\n",
      "Epoch 237/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0048\n",
      "Epoch 238/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0041\n",
      "Epoch 239/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0039\n",
      "Epoch 240/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0041\n",
      "Epoch 241/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0042\n",
      "Epoch 242/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0043\n",
      "Epoch 243/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0044\n",
      "Epoch 244/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0043\n",
      "Epoch 245/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0042\n",
      "Epoch 246/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0048\n",
      "Epoch 247/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0042\n",
      "Epoch 248/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0040\n",
      "Epoch 249/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0045\n",
      "Epoch 250/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0040\n",
      "Epoch 251/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0042\n",
      "Epoch 252/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0043\n",
      "Epoch 253/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0040\n",
      "Epoch 254/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0042\n",
      "Epoch 255/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0045\n",
      "Epoch 256/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0044\n",
      "Epoch 257/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0040\n",
      "Epoch 258/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0044\n",
      "Epoch 259/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0045\n",
      "Epoch 260/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0040\n",
      "Epoch 261/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0041\n",
      "Epoch 262/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0040\n",
      "Epoch 263/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0041\n",
      "Epoch 264/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0043\n",
      "Epoch 265/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0043\n",
      "Epoch 266/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0041\n",
      "Epoch 267/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0042\n",
      "Epoch 268/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0041\n",
      "Epoch 269/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0044\n",
      "Epoch 270/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0044\n",
      "Epoch 271/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0040\n",
      "Epoch 272/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0048\n",
      "Epoch 273/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0044\n",
      "Epoch 274/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0043\n",
      "Epoch 275/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0040\n",
      "Epoch 276/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0046\n",
      "Epoch 277/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0044\n",
      "Epoch 278/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0039\n",
      "Epoch 279/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0043\n",
      "Epoch 280/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0039\n",
      "Epoch 281/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0041\n",
      "Epoch 00281: early stopping\n",
      "Epoch 1/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.1891 - val_loss: 0.0286\n",
      "Epoch 2/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0552 - val_loss: 0.0193\n",
      "Epoch 3/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0384 - val_loss: 0.0140\n",
      "Epoch 4/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0312 - val_loss: 0.0124\n",
      "Epoch 5/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0265 - val_loss: 0.0100\n",
      "Epoch 6/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0231 - val_loss: 0.0078\n",
      "Epoch 7/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0204 - val_loss: 0.0067\n",
      "Epoch 8/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0190 - val_loss: 0.0064\n",
      "Epoch 9/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0177 - val_loss: 0.0060\n",
      "Epoch 10/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0060\n",
      "Epoch 11/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0058\n",
      "Epoch 12/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0057\n",
      "Epoch 13/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0058\n",
      "Epoch 14/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0058\n",
      "Epoch 15/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.0058\n",
      "Epoch 16/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0054\n",
      "Epoch 17/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.0058\n",
      "Epoch 18/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.0059\n",
      "Epoch 19/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.0057\n",
      "Epoch 20/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.0055\n",
      "Epoch 21/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.0063\n",
      "Epoch 22/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.0062\n",
      "Epoch 23/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0055\n",
      "Epoch 24/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0056\n",
      "Epoch 25/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0051\n",
      "Epoch 26/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.0053\n",
      "Epoch 27/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0053\n",
      "Epoch 28/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.0051\n",
      "Epoch 29/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0055\n",
      "Epoch 30/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0051\n",
      "Epoch 31/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0049\n",
      "Epoch 32/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0048\n",
      "Epoch 33/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0046\n",
      "Epoch 34/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0044\n",
      "Epoch 35/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0043\n",
      "Epoch 36/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0044\n",
      "Epoch 37/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0046\n",
      "Epoch 38/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0046\n",
      "Epoch 39/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0051\n",
      "Epoch 40/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0053\n",
      "Epoch 41/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0048\n",
      "Epoch 42/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0043\n",
      "Epoch 43/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0048\n",
      "Epoch 44/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0050\n",
      "Epoch 45/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0044\n",
      "Epoch 46/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0045\n",
      "Epoch 47/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0044\n",
      "Epoch 48/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0048\n",
      "Epoch 49/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0045\n",
      "Epoch 50/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 51/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0042\n",
      "Epoch 52/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0042\n",
      "Epoch 53/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0047\n",
      "Epoch 54/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0053\n",
      "Epoch 55/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0043\n",
      "Epoch 56/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0043\n",
      "Epoch 57/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0043\n",
      "Epoch 58/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0045\n",
      "Epoch 59/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0042\n",
      "Epoch 60/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0046\n",
      "Epoch 61/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0049\n",
      "Epoch 62/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0052\n",
      "Epoch 63/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0045\n",
      "Epoch 64/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0048\n",
      "Epoch 65/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0044\n",
      "Epoch 66/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0042\n",
      "Epoch 67/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0064\n",
      "Epoch 68/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0042\n",
      "Epoch 69/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0050\n",
      "Epoch 70/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0044\n",
      "Epoch 71/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0044\n",
      "Epoch 72/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0042\n",
      "Epoch 73/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0043\n",
      "Epoch 74/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0043\n",
      "Epoch 75/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0046\n",
      "Epoch 76/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0041\n",
      "Epoch 77/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0047\n",
      "Epoch 78/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0046\n",
      "Epoch 79/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0051\n",
      "Epoch 80/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0048\n",
      "Epoch 81/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0042\n",
      "Epoch 82/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0048\n",
      "Epoch 83/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0054\n",
      "Epoch 84/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0042\n",
      "Epoch 85/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0043\n",
      "Epoch 86/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0044\n",
      "Epoch 87/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0047\n",
      "Epoch 88/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0048\n",
      "Epoch 89/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 90/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0040\n",
      "Epoch 91/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0042\n",
      "Epoch 92/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0041\n",
      "Epoch 93/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 94/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0045\n",
      "Epoch 95/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0042\n",
      "Epoch 96/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0042\n",
      "Epoch 97/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0047\n",
      "Epoch 98/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0043\n",
      "Epoch 99/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0057\n",
      "Epoch 100/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0042\n",
      "Epoch 101/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0047\n",
      "Epoch 103/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0041\n",
      "Epoch 104/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0045\n",
      "Epoch 105/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0041\n",
      "Epoch 106/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0055\n",
      "Epoch 107/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 108/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0043\n",
      "Epoch 109/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0041\n",
      "Epoch 110/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0041\n",
      "Epoch 111/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0042\n",
      "Epoch 112/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0043\n",
      "Epoch 113/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0043\n",
      "Epoch 114/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0043\n",
      "Epoch 115/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0049\n",
      "Epoch 116/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0043\n",
      "Epoch 117/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0052\n",
      "Epoch 118/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0043\n",
      "Epoch 119/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0042\n",
      "Epoch 120/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0042\n",
      "Epoch 121/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0042\n",
      "Epoch 122/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0042\n",
      "Epoch 123/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0041\n",
      "Epoch 124/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0046\n",
      "Epoch 125/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0047\n",
      "Epoch 126/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0042\n",
      "Epoch 127/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0041\n",
      "Epoch 128/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0042\n",
      "Epoch 129/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0044\n",
      "Epoch 130/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0047\n",
      "Epoch 131/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0043\n",
      "Epoch 132/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0044\n",
      "Epoch 133/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0043\n",
      "Epoch 134/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0046\n",
      "Epoch 135/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0041\n",
      "Epoch 136/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0044\n",
      "Epoch 137/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0044\n",
      "Epoch 138/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0040\n",
      "Epoch 139/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0041\n",
      "Epoch 140/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0050\n",
      "Epoch 141/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0044\n",
      "Epoch 142/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0047\n",
      "Epoch 143/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0040\n",
      "Epoch 144/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0043\n",
      "Epoch 145/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0047\n",
      "Epoch 146/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0041\n",
      "Epoch 147/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0041\n",
      "Epoch 148/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0045\n",
      "Epoch 149/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0041\n",
      "Epoch 150/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0042\n",
      "Epoch 151/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0042\n",
      "Epoch 152/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0042\n",
      "Epoch 153/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0041\n",
      "Epoch 154/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0041\n",
      "Epoch 155/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0042\n",
      "Epoch 156/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0042\n",
      "Epoch 157/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 158/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0043\n",
      "Epoch 159/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0039\n",
      "Epoch 160/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0047\n",
      "Epoch 161/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0044\n",
      "Epoch 162/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0053\n",
      "Epoch 163/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0045\n",
      "Epoch 164/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0040\n",
      "Epoch 165/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0043\n",
      "Epoch 166/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0043\n",
      "Epoch 167/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0061\n",
      "Epoch 168/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0040\n",
      "Epoch 169/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0041\n",
      "Epoch 170/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0043\n",
      "Epoch 171/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0046\n",
      "Epoch 172/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0043\n",
      "Epoch 173/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0041\n",
      "Epoch 174/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0041\n",
      "Epoch 175/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0040\n",
      "Epoch 176/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0040\n",
      "Epoch 177/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0042\n",
      "Epoch 178/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0040\n",
      "Epoch 179/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0041\n",
      "Epoch 180/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0043\n",
      "Epoch 181/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0039\n",
      "Epoch 182/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0041\n",
      "Epoch 183/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0041\n",
      "Epoch 184/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0040\n",
      "Epoch 185/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0041\n",
      "Epoch 186/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0049\n",
      "Epoch 187/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0041\n",
      "Epoch 188/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0044\n",
      "Epoch 189/10000\n",
      "151/151 [==============================] - 0s 3ms/step - loss: 0.0087 - val_loss: 0.0043\n",
      "Epoch 190/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0041\n",
      "Epoch 191/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0045\n",
      "Epoch 192/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0040\n",
      "Epoch 193/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0042\n",
      "Epoch 194/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0040\n",
      "Epoch 195/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0042\n",
      "Epoch 196/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0044\n",
      "Epoch 197/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0063\n",
      "Epoch 198/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0041\n",
      "Epoch 199/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0041\n",
      "Epoch 200/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0040\n",
      "Epoch 201/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0041\n",
      "Epoch 202/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0041\n",
      "Epoch 203/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0041\n",
      "Epoch 204/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0040\n",
      "Epoch 205/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0045\n",
      "Epoch 206/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0040\n",
      "Epoch 207/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0045\n",
      "Epoch 208/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0043\n",
      "Epoch 209/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0040\n",
      "Epoch 210/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0039\n",
      "Epoch 211/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0041\n",
      "Epoch 212/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0044\n",
      "Epoch 213/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0046\n",
      "Epoch 214/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0044\n",
      "Epoch 215/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0047\n",
      "Epoch 216/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0049\n",
      "Epoch 217/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0043\n",
      "Epoch 218/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0041\n",
      "Epoch 219/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0043\n",
      "Epoch 220/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0041\n",
      "Epoch 221/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0040\n",
      "Epoch 222/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0040\n",
      "Epoch 223/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0043\n",
      "Epoch 224/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0042\n",
      "Epoch 225/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0048\n",
      "Epoch 226/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0040\n",
      "Epoch 227/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0041\n",
      "Epoch 228/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0047\n",
      "Epoch 229/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0041\n",
      "Epoch 230/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0039\n",
      "Epoch 231/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0046\n",
      "Epoch 00231: early stopping\n",
      "Epoch 1/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.1298 - val_loss: 0.0284\n",
      "Epoch 2/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0418 - val_loss: 0.0161\n",
      "Epoch 3/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0294 - val_loss: 0.0151\n",
      "Epoch 4/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0259 - val_loss: 0.0154\n",
      "Epoch 5/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0239 - val_loss: 0.0147\n",
      "Epoch 6/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0225 - val_loss: 0.0148\n",
      "Epoch 7/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0217 - val_loss: 0.0148\n",
      "Epoch 8/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0206 - val_loss: 0.0147\n",
      "Epoch 9/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0204 - val_loss: 0.0148\n",
      "Epoch 10/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0200 - val_loss: 0.0146\n",
      "Epoch 11/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0195 - val_loss: 0.0146\n",
      "Epoch 12/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0191 - val_loss: 0.0150\n",
      "Epoch 13/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0191 - val_loss: 0.0149\n",
      "Epoch 14/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0186 - val_loss: 0.0150\n",
      "Epoch 15/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.0146\n",
      "Epoch 16/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0183 - val_loss: 0.0150\n",
      "Epoch 17/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0182 - val_loss: 0.0147\n",
      "Epoch 18/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0179 - val_loss: 0.0147\n",
      "Epoch 19/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0180 - val_loss: 0.0146\n",
      "Epoch 20/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.0145\n",
      "Epoch 21/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0146\n",
      "Epoch 22/10000\n",
      "151/151 [==============================] - 0s 3ms/step - loss: 0.0176 - val_loss: 0.0155\n",
      "Epoch 23/10000\n",
      "151/151 [==============================] - 0s 3ms/step - loss: 0.0174 - val_loss: 0.0145\n",
      "Epoch 24/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0147\n",
      "Epoch 25/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0171 - val_loss: 0.0146\n",
      "Epoch 26/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.0144\n",
      "Epoch 27/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0170 - val_loss: 0.0145\n",
      "Epoch 28/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0144\n",
      "Epoch 29/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0148\n",
      "Epoch 30/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0146\n",
      "Epoch 31/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0145\n",
      "Epoch 32/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0146\n",
      "Epoch 33/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0145\n",
      "Epoch 34/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0146\n",
      "Epoch 35/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0147\n",
      "Epoch 36/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0145\n",
      "Epoch 37/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0145\n",
      "Epoch 38/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0147\n",
      "Epoch 39/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0150\n",
      "Epoch 40/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0147\n",
      "Epoch 41/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0148\n",
      "Epoch 42/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0147\n",
      "Epoch 43/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0148\n",
      "Epoch 44/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0150\n",
      "Epoch 45/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0150\n",
      "Epoch 46/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0146\n",
      "Epoch 47/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0144\n",
      "Epoch 48/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0146\n",
      "Epoch 49/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0146\n",
      "Epoch 50/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0144\n",
      "Epoch 51/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0146\n",
      "Epoch 52/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0144\n",
      "Epoch 53/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0147\n",
      "Epoch 54/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0148\n",
      "Epoch 55/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0145\n",
      "Epoch 56/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0144\n",
      "Epoch 57/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0144\n",
      "Epoch 58/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0144\n",
      "Epoch 59/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0156\n",
      "Epoch 60/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0144\n",
      "Epoch 61/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0145\n",
      "Epoch 62/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0146\n",
      "Epoch 63/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0148\n",
      "Epoch 64/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0148\n",
      "Epoch 65/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0145\n",
      "Epoch 66/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0144\n",
      "Epoch 67/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0144\n",
      "Epoch 68/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0147\n",
      "Epoch 69/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0144\n",
      "Epoch 70/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0146\n",
      "Epoch 71/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0144\n",
      "Epoch 72/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0145\n",
      "Epoch 73/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0145\n",
      "Epoch 74/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0144\n",
      "Epoch 75/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0144\n",
      "Epoch 76/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0144\n",
      "Epoch 77/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0145\n",
      "Epoch 78/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0144\n",
      "Epoch 79/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0145\n",
      "Epoch 80/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0145\n",
      "Epoch 81/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0150\n",
      "Epoch 82/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0146\n",
      "Epoch 83/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0145\n",
      "Epoch 84/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0146\n",
      "Epoch 85/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0150\n",
      "Epoch 86/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0144\n",
      "Epoch 87/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0144\n",
      "Epoch 88/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0148\n",
      "Epoch 89/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0144\n",
      "Epoch 90/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0145\n",
      "Epoch 91/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0144\n",
      "Epoch 92/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0145\n",
      "Epoch 93/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0144\n",
      "Epoch 94/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0144\n",
      "Epoch 95/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0146\n",
      "Epoch 96/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0145\n",
      "Epoch 97/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0144\n",
      "Epoch 98/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0149\n",
      "Epoch 99/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0145\n",
      "Epoch 100/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0144\n",
      "Epoch 101/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0145\n",
      "Epoch 102/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0144\n",
      "Epoch 103/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0145\n",
      "Epoch 104/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0145\n",
      "Epoch 105/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0145\n",
      "Epoch 107/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0143\n",
      "Epoch 108/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0144\n",
      "Epoch 109/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0147\n",
      "Epoch 110/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0147\n",
      "Epoch 111/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0144\n",
      "Epoch 112/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0146\n",
      "Epoch 113/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0145\n",
      "Epoch 114/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0147\n",
      "Epoch 115/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0145\n",
      "Epoch 116/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0143\n",
      "Epoch 117/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0147\n",
      "Epoch 118/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0146\n",
      "Epoch 119/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0146\n",
      "Epoch 120/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0145\n",
      "Epoch 121/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0149\n",
      "Epoch 122/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0145\n",
      "Epoch 123/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0145\n",
      "Epoch 124/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0147\n",
      "Epoch 125/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0144\n",
      "Epoch 126/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0149\n",
      "Epoch 127/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0144\n",
      "Epoch 128/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0144\n",
      "Epoch 129/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0145\n",
      "Epoch 130/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0143\n",
      "Epoch 131/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0147\n",
      "Epoch 132/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0147\n",
      "Epoch 133/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0144\n",
      "Epoch 134/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0144\n",
      "Epoch 135/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0147\n",
      "Epoch 136/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0145\n",
      "Epoch 137/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0144\n",
      "Epoch 138/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0146\n",
      "Epoch 139/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0146\n",
      "Epoch 140/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0147\n",
      "Epoch 141/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0144\n",
      "Epoch 142/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0146\n",
      "Epoch 143/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0144\n",
      "Epoch 144/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0143\n",
      "Epoch 145/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0144\n",
      "Epoch 146/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0144\n",
      "Epoch 147/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0145\n",
      "Epoch 148/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0143\n",
      "Epoch 149/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0144\n",
      "Epoch 150/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0144\n",
      "Epoch 151/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0146\n",
      "Epoch 152/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0146\n",
      "Epoch 153/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0145\n",
      "Epoch 154/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0145\n",
      "Epoch 155/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0146\n",
      "Epoch 156/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0144\n",
      "Epoch 157/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0148\n",
      "Epoch 00157: early stopping\n",
      "Epoch 1/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.1260 - val_loss: 0.0200\n",
      "Epoch 2/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0150\n",
      "Epoch 3/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0256 - val_loss: 0.0097\n",
      "Epoch 4/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0210 - val_loss: 0.0095\n",
      "Epoch 5/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0186 - val_loss: 0.0086\n",
      "Epoch 6/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.0085\n",
      "Epoch 7/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0089\n",
      "Epoch 8/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0085\n",
      "Epoch 9/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0085\n",
      "Epoch 10/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0092\n",
      "Epoch 11/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.0083\n",
      "Epoch 12/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0090\n",
      "Epoch 13/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.0086\n",
      "Epoch 14/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.0086\n",
      "Epoch 15/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0130 - val_loss: 0.0083\n",
      "Epoch 16/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0130 - val_loss: 0.0084\n",
      "Epoch 17/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.0082\n",
      "Epoch 18/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0085\n",
      "Epoch 19/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.0089\n",
      "Epoch 20/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.0085\n",
      "Epoch 21/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.0083\n",
      "Epoch 22/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.0084\n",
      "Epoch 23/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.0085\n",
      "Epoch 24/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0085\n",
      "Epoch 25/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0081\n",
      "Epoch 26/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0082\n",
      "Epoch 27/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0085\n",
      "Epoch 28/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0083\n",
      "Epoch 29/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0084\n",
      "Epoch 30/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0090\n",
      "Epoch 31/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.0089\n",
      "Epoch 32/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0083\n",
      "Epoch 33/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0081\n",
      "Epoch 34/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.0081\n",
      "Epoch 35/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0082\n",
      "Epoch 36/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0084\n",
      "Epoch 37/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0085\n",
      "Epoch 38/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0085\n",
      "Epoch 39/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0081\n",
      "Epoch 40/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0081\n",
      "Epoch 41/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0082\n",
      "Epoch 42/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0082\n",
      "Epoch 43/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0082\n",
      "Epoch 44/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0083\n",
      "Epoch 45/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0085\n",
      "Epoch 46/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0082\n",
      "Epoch 47/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0081\n",
      "Epoch 48/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0085\n",
      "Epoch 49/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0083\n",
      "Epoch 50/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0083\n",
      "Epoch 51/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0081\n",
      "Epoch 52/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0082\n",
      "Epoch 53/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0082\n",
      "Epoch 54/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0084\n",
      "Epoch 55/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0084\n",
      "Epoch 56/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0080\n",
      "Epoch 57/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0081\n",
      "Epoch 58/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0081\n",
      "Epoch 59/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0083\n",
      "Epoch 60/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0083\n",
      "Epoch 61/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0084\n",
      "Epoch 62/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0081\n",
      "Epoch 63/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0081\n",
      "Epoch 64/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0081\n",
      "Epoch 65/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0083\n",
      "Epoch 66/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0091\n",
      "Epoch 67/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0081\n",
      "Epoch 68/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0081\n",
      "Epoch 69/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0081\n",
      "Epoch 70/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0081\n",
      "Epoch 71/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0083\n",
      "Epoch 72/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0080\n",
      "Epoch 73/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0082\n",
      "Epoch 74/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0082\n",
      "Epoch 75/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0085\n",
      "Epoch 76/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0082\n",
      "Epoch 77/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0084\n",
      "Epoch 78/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0082\n",
      "Epoch 79/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0082\n",
      "Epoch 80/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0082\n",
      "Epoch 81/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0089\n",
      "Epoch 82/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0082\n",
      "Epoch 83/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0083\n",
      "Epoch 84/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0084\n",
      "Epoch 85/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0081\n",
      "Epoch 86/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0087\n",
      "Epoch 87/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0081\n",
      "Epoch 88/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0081\n",
      "Epoch 89/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0083\n",
      "Epoch 90/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0081\n",
      "Epoch 91/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0084\n",
      "Epoch 92/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0082\n",
      "Epoch 93/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0082\n",
      "Epoch 94/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0084\n",
      "Epoch 95/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0085\n",
      "Epoch 96/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0085\n",
      "Epoch 97/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0084\n",
      "Epoch 98/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0083\n",
      "Epoch 99/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0081\n",
      "Epoch 100/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0095\n",
      "Epoch 101/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0081\n",
      "Epoch 102/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0081\n",
      "Epoch 103/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0080\n",
      "Epoch 104/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0082\n",
      "Epoch 105/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0081\n",
      "Epoch 00106: early stopping\n",
      "Epoch 1/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.1277 - val_loss: 0.0148\n",
      "Epoch 2/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0369 - val_loss: 0.0106\n",
      "Epoch 3/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0258 - val_loss: 0.0097\n",
      "Epoch 4/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0213 - val_loss: 0.0087\n",
      "Epoch 5/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0189 - val_loss: 0.0088\n",
      "Epoch 6/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0171 - val_loss: 0.0076\n",
      "Epoch 7/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0060\n",
      "Epoch 8/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.0052\n",
      "Epoch 9/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.0052\n",
      "Epoch 10/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.0049\n",
      "Epoch 11/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0049\n",
      "Epoch 12/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0052\n",
      "Epoch 13/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0053\n",
      "Epoch 14/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.0050\n",
      "Epoch 15/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0050\n",
      "Epoch 16/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0053\n",
      "Epoch 17/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0047\n",
      "Epoch 18/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0055\n",
      "Epoch 19/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0050\n",
      "Epoch 20/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0048\n",
      "Epoch 21/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0052\n",
      "Epoch 22/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0048\n",
      "Epoch 23/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0048\n",
      "Epoch 24/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0047\n",
      "Epoch 25/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0046\n",
      "Epoch 26/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0046\n",
      "Epoch 27/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0050\n",
      "Epoch 28/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0050\n",
      "Epoch 29/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0050\n",
      "Epoch 30/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0046\n",
      "Epoch 31/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0053\n",
      "Epoch 32/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0047\n",
      "Epoch 33/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0046\n",
      "Epoch 34/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0048\n",
      "Epoch 35/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0048\n",
      "Epoch 36/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0047\n",
      "Epoch 37/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0047\n",
      "Epoch 38/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0046\n",
      "Epoch 39/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0049\n",
      "Epoch 40/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0047\n",
      "Epoch 41/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0048\n",
      "Epoch 42/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0051\n",
      "Epoch 43/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0046\n",
      "Epoch 44/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0047\n",
      "Epoch 45/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0046\n",
      "Epoch 46/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0051\n",
      "Epoch 47/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0047\n",
      "Epoch 48/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0051\n",
      "Epoch 49/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0053\n",
      "Epoch 50/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0047\n",
      "Epoch 51/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0049\n",
      "Epoch 52/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0049\n",
      "Epoch 53/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0047\n",
      "Epoch 54/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0048\n",
      "Epoch 55/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0049\n",
      "Epoch 56/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0050\n",
      "Epoch 57/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0046\n",
      "Epoch 58/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0046\n",
      "Epoch 59/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0047\n",
      "Epoch 60/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0046\n",
      "Epoch 61/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0045\n",
      "Epoch 62/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0049\n",
      "Epoch 63/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0046\n",
      "Epoch 64/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0045\n",
      "Epoch 65/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0047\n",
      "Epoch 66/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0048\n",
      "Epoch 67/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0058\n",
      "Epoch 68/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0044\n",
      "Epoch 69/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0046\n",
      "Epoch 70/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0047\n",
      "Epoch 71/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0045\n",
      "Epoch 72/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0047\n",
      "Epoch 73/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0046\n",
      "Epoch 74/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0044\n",
      "Epoch 75/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0046\n",
      "Epoch 76/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0046\n",
      "Epoch 77/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0048\n",
      "Epoch 78/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0045\n",
      "Epoch 79/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0045\n",
      "Epoch 80/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0048\n",
      "Epoch 81/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0044\n",
      "Epoch 82/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0050\n",
      "Epoch 83/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0045\n",
      "Epoch 84/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0045\n",
      "Epoch 85/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0044\n",
      "Epoch 86/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0044\n",
      "Epoch 87/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 88/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0049\n",
      "Epoch 89/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0048\n",
      "Epoch 90/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0046\n",
      "Epoch 91/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0048\n",
      "Epoch 92/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0045\n",
      "Epoch 93/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0044\n",
      "Epoch 94/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0053\n",
      "Epoch 95/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0047\n",
      "Epoch 96/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0044\n",
      "Epoch 97/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0045\n",
      "Epoch 98/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0045\n",
      "Epoch 99/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0047\n",
      "Epoch 100/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0046\n",
      "Epoch 101/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0046\n",
      "Epoch 102/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0046\n",
      "Epoch 103/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0049\n",
      "Epoch 104/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0046\n",
      "Epoch 105/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0056\n",
      "Epoch 106/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0046\n",
      "Epoch 107/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0047\n",
      "Epoch 108/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0047\n",
      "Epoch 109/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0048\n",
      "Epoch 110/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0047\n",
      "Epoch 111/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0048\n",
      "Epoch 112/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0045\n",
      "Epoch 113/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0045\n",
      "Epoch 114/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0044\n",
      "Epoch 115/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0044\n",
      "Epoch 116/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0051\n",
      "Epoch 117/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0043\n",
      "Epoch 118/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0045\n",
      "Epoch 119/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0044\n",
      "Epoch 120/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0045\n",
      "Epoch 121/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0048\n",
      "Epoch 122/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0046\n",
      "Epoch 123/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0049\n",
      "Epoch 124/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0047\n",
      "Epoch 125/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0045\n",
      "Epoch 126/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0044\n",
      "Epoch 127/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0044\n",
      "Epoch 128/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0044\n",
      "Epoch 129/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0049\n",
      "Epoch 130/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0045\n",
      "Epoch 131/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0045\n",
      "Epoch 132/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0047\n",
      "Epoch 133/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0045\n",
      "Epoch 134/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0045\n",
      "Epoch 135/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0045\n",
      "Epoch 136/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0045\n",
      "Epoch 137/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0044\n",
      "Epoch 138/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0044\n",
      "Epoch 139/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0048\n",
      "Epoch 140/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0044\n",
      "Epoch 141/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0045\n",
      "Epoch 142/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0044\n",
      "Epoch 143/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0044\n",
      "Epoch 144/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 145/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0043\n",
      "Epoch 146/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0044\n",
      "Epoch 147/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0044\n",
      "Epoch 148/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0045\n",
      "Epoch 149/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0045\n",
      "Epoch 150/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0044\n",
      "Epoch 151/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0048\n",
      "Epoch 152/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0044\n",
      "Epoch 153/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0044\n",
      "Epoch 154/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0044\n",
      "Epoch 155/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0048\n",
      "Epoch 156/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0047\n",
      "Epoch 157/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0055\n",
      "Epoch 158/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0045\n",
      "Epoch 159/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0053\n",
      "Epoch 160/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0043\n",
      "Epoch 161/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0047\n",
      "Epoch 162/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0045\n",
      "Epoch 163/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0043\n",
      "Epoch 164/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0042\n",
      "Epoch 165/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0044\n",
      "Epoch 166/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0052\n",
      "Epoch 167/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0048\n",
      "Epoch 168/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0045\n",
      "Epoch 169/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0045\n",
      "Epoch 170/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0044\n",
      "Epoch 171/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0045\n",
      "Epoch 172/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0045\n",
      "Epoch 173/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0044\n",
      "Epoch 174/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0051\n",
      "Epoch 175/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 176/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0047\n",
      "Epoch 177/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0046\n",
      "Epoch 178/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0046\n",
      "Epoch 179/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0047\n",
      "Epoch 180/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0051\n",
      "Epoch 181/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0049\n",
      "Epoch 182/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0043\n",
      "Epoch 183/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0047\n",
      "Epoch 184/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0045\n",
      "Epoch 185/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0043\n",
      "Epoch 186/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0046\n",
      "Epoch 187/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0043\n",
      "Epoch 188/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0044\n",
      "Epoch 189/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0042\n",
      "Epoch 190/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0048\n",
      "Epoch 191/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0044\n",
      "Epoch 192/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 193/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0046\n",
      "Epoch 194/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0044\n",
      "Epoch 195/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0043\n",
      "Epoch 196/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0051\n",
      "Epoch 197/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0045\n",
      "Epoch 198/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0044\n",
      "Epoch 199/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0048\n",
      "Epoch 200/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0044\n",
      "Epoch 201/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0049\n",
      "Epoch 202/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0044\n",
      "Epoch 203/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0047\n",
      "Epoch 204/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0044\n",
      "Epoch 205/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0045\n",
      "Epoch 206/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0044\n",
      "Epoch 207/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0043\n",
      "Epoch 208/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0043\n",
      "Epoch 209/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0044\n",
      "Epoch 210/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0045\n",
      "Epoch 211/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 212/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0043\n",
      "Epoch 213/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0042\n",
      "Epoch 214/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0057\n",
      "Epoch 215/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0046\n",
      "Epoch 216/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0048\n",
      "Epoch 217/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0042\n",
      "Epoch 218/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0043\n",
      "Epoch 219/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 220/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0044\n",
      "Epoch 221/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 222/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0042\n",
      "Epoch 223/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0048\n",
      "Epoch 224/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0045\n",
      "Epoch 225/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0042\n",
      "Epoch 226/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0043\n",
      "Epoch 227/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0044\n",
      "Epoch 228/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0045\n",
      "Epoch 229/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0044\n",
      "Epoch 230/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0042\n",
      "Epoch 231/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0044\n",
      "Epoch 232/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0041\n",
      "Epoch 233/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0043\n",
      "Epoch 234/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0053\n",
      "Epoch 235/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0043\n",
      "Epoch 236/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0046\n",
      "Epoch 237/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0045\n",
      "Epoch 238/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 239/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0042\n",
      "Epoch 240/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 241/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 242/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 243/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 244/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0043\n",
      "Epoch 245/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0045\n",
      "Epoch 246/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0044\n",
      "Epoch 247/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 248/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0051\n",
      "Epoch 249/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0042\n",
      "Epoch 250/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0042\n",
      "Epoch 251/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 252/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0046\n",
      "Epoch 253/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0042\n",
      "Epoch 254/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0053\n",
      "Epoch 255/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 256/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 257/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0046\n",
      "Epoch 258/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0042\n",
      "Epoch 259/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0042\n",
      "Epoch 260/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0044\n",
      "Epoch 261/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0043\n",
      "Epoch 262/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 263/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0046\n",
      "Epoch 264/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0042\n",
      "Epoch 265/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0042\n",
      "Epoch 266/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 267/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0042\n",
      "Epoch 268/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0042\n",
      "Epoch 269/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0044\n",
      "Epoch 270/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0044\n",
      "Epoch 271/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0042\n",
      "Epoch 272/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0045\n",
      "Epoch 273/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0043\n",
      "Epoch 274/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0044\n",
      "Epoch 275/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0044\n",
      "Epoch 276/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0042\n",
      "Epoch 277/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0044\n",
      "Epoch 278/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 279/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0042\n",
      "Epoch 280/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0044\n",
      "Epoch 281/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 282/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 00282: early stopping\n",
      "Epoch 1/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.1370 - val_loss: 0.0172\n",
      "Epoch 2/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0374 - val_loss: 0.0106\n",
      "Epoch 3/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0257 - val_loss: 0.0081\n",
      "Epoch 4/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0202 - val_loss: 0.0084\n",
      "Epoch 5/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0171 - val_loss: 0.0053\n",
      "Epoch 6/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0051\n",
      "Epoch 7/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.0053\n",
      "Epoch 8/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.0064\n",
      "Epoch 9/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.0049\n",
      "Epoch 10/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.0045\n",
      "Epoch 11/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0044\n",
      "Epoch 12/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.0042\n",
      "Epoch 13/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.0045\n",
      "Epoch 14/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0044\n",
      "Epoch 15/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0044\n",
      "Epoch 16/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0037\n",
      "Epoch 17/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0042\n",
      "Epoch 18/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0043\n",
      "Epoch 19/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0038\n",
      "Epoch 20/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0038\n",
      "Epoch 21/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0045\n",
      "Epoch 22/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0040\n",
      "Epoch 23/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0039\n",
      "Epoch 24/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0038\n",
      "Epoch 25/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0036\n",
      "Epoch 26/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0041\n",
      "Epoch 27/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0048\n",
      "Epoch 28/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0036\n",
      "Epoch 29/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0036\n",
      "Epoch 30/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0037\n",
      "Epoch 31/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0038\n",
      "Epoch 32/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0038\n",
      "Epoch 33/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0036\n",
      "Epoch 34/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0039\n",
      "Epoch 35/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0035\n",
      "Epoch 36/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0036\n",
      "Epoch 37/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0042\n",
      "Epoch 38/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0035\n",
      "Epoch 39/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0040\n",
      "Epoch 40/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0040\n",
      "Epoch 41/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0038\n",
      "Epoch 42/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0038\n",
      "Epoch 43/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0038\n",
      "Epoch 44/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0035\n",
      "Epoch 45/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0035\n",
      "Epoch 46/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0035\n",
      "Epoch 47/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0035\n",
      "Epoch 48/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0037\n",
      "Epoch 49/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0036\n",
      "Epoch 50/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0036\n",
      "Epoch 51/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0037\n",
      "Epoch 52/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0037\n",
      "Epoch 53/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0036\n",
      "Epoch 54/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0035\n",
      "Epoch 55/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0037\n",
      "Epoch 56/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0035\n",
      "Epoch 57/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0035\n",
      "Epoch 58/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0036\n",
      "Epoch 59/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0039\n",
      "Epoch 60/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0037\n",
      "Epoch 61/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0038\n",
      "Epoch 62/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0038\n",
      "Epoch 63/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0038\n",
      "Epoch 64/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0036\n",
      "Epoch 65/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0036\n",
      "Epoch 66/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0040\n",
      "Epoch 67/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0035\n",
      "Epoch 68/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0042\n",
      "Epoch 69/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0040\n",
      "Epoch 70/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0036\n",
      "Epoch 71/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0034\n",
      "Epoch 72/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0038\n",
      "Epoch 73/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0035\n",
      "Epoch 74/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 75/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0036\n",
      "Epoch 76/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0038\n",
      "Epoch 77/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0037\n",
      "Epoch 78/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0037\n",
      "Epoch 79/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0038\n",
      "Epoch 80/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0036\n",
      "Epoch 81/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0034\n",
      "Epoch 82/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0035\n",
      "Epoch 83/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0036\n",
      "Epoch 84/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0039\n",
      "Epoch 85/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0035\n",
      "Epoch 86/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0044\n",
      "Epoch 87/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0035\n",
      "Epoch 88/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0037\n",
      "Epoch 89/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0034\n",
      "Epoch 90/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0035\n",
      "Epoch 91/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0037\n",
      "Epoch 92/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0035\n",
      "Epoch 93/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0036\n",
      "Epoch 94/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0034\n",
      "Epoch 95/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0034\n",
      "Epoch 96/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0034\n",
      "Epoch 97/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0037\n",
      "Epoch 98/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0035\n",
      "Epoch 99/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0036\n",
      "Epoch 100/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0036\n",
      "Epoch 101/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0035\n",
      "Epoch 102/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0035\n",
      "Epoch 103/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0037\n",
      "Epoch 104/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0035\n",
      "Epoch 105/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0036\n",
      "Epoch 106/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0034\n",
      "Epoch 107/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0035\n",
      "Epoch 108/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0034\n",
      "Epoch 110/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0034\n",
      "Epoch 111/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0035\n",
      "Epoch 112/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0034\n",
      "Epoch 113/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0033\n",
      "Epoch 114/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0034\n",
      "Epoch 115/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 116/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0036\n",
      "Epoch 117/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0035\n",
      "Epoch 118/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0034\n",
      "Epoch 119/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0035\n",
      "Epoch 120/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0035\n",
      "Epoch 121/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0034\n",
      "Epoch 122/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0041\n",
      "Epoch 123/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0047\n",
      "Epoch 124/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0035\n",
      "Epoch 125/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0037\n",
      "Epoch 126/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0034\n",
      "Epoch 127/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0033\n",
      "Epoch 128/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0035\n",
      "Epoch 129/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0034\n",
      "Epoch 130/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0036\n",
      "Epoch 131/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0035\n",
      "Epoch 132/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0033\n",
      "Epoch 133/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0034\n",
      "Epoch 134/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0040\n",
      "Epoch 135/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0036\n",
      "Epoch 136/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0036\n",
      "Epoch 137/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0035\n",
      "Epoch 138/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0033\n",
      "Epoch 139/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0034\n",
      "Epoch 140/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0037\n",
      "Epoch 141/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0037\n",
      "Epoch 142/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0036\n",
      "Epoch 143/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0037\n",
      "Epoch 144/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0037\n",
      "Epoch 145/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0038\n",
      "Epoch 146/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0038\n",
      "Epoch 147/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0035\n",
      "Epoch 148/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0034\n",
      "Epoch 149/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0035\n",
      "Epoch 150/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0033\n",
      "Epoch 151/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0038\n",
      "Epoch 152/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0035\n",
      "Epoch 153/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0035\n",
      "Epoch 154/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 155/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0036\n",
      "Epoch 156/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0035\n",
      "Epoch 157/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0037\n",
      "Epoch 158/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0042\n",
      "Epoch 159/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0034\n",
      "Epoch 160/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0035\n",
      "Epoch 161/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0037\n",
      "Epoch 162/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0034\n",
      "Epoch 163/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0037\n",
      "Epoch 164/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0035\n",
      "Epoch 165/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0035\n",
      "Epoch 166/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0036\n",
      "Epoch 167/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0035\n",
      "Epoch 168/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0034\n",
      "Epoch 169/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0034\n",
      "Epoch 170/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0036\n",
      "Epoch 171/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0038\n",
      "Epoch 172/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0033\n",
      "Epoch 173/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0035\n",
      "Epoch 174/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0037\n",
      "Epoch 175/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0036\n",
      "Epoch 176/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0036\n",
      "Epoch 177/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0033\n",
      "Epoch 178/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0035\n",
      "Epoch 179/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0033\n",
      "Epoch 180/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0036\n",
      "Epoch 181/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0035\n",
      "Epoch 182/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0035\n",
      "Epoch 00182: early stopping\n",
      "Epoch 1/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.1396 - val_loss: 0.0165\n",
      "Epoch 2/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0368 - val_loss: 0.0107\n",
      "Epoch 3/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0249 - val_loss: 0.0069\n",
      "Epoch 4/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0194 - val_loss: 0.0073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0060\n",
      "Epoch 6/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0053\n",
      "Epoch 7/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.0062\n",
      "Epoch 8/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0130 - val_loss: 0.0049\n",
      "Epoch 9/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.0048\n",
      "Epoch 10/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0043\n",
      "Epoch 11/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0043\n",
      "Epoch 12/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0040\n",
      "Epoch 13/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0052\n",
      "Epoch 14/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0038\n",
      "Epoch 15/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0038\n",
      "Epoch 16/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0035\n",
      "Epoch 17/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0037\n",
      "Epoch 18/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0032\n",
      "Epoch 19/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0033\n",
      "Epoch 20/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0031\n",
      "Epoch 21/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0035\n",
      "Epoch 22/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0029\n",
      "Epoch 23/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0030\n",
      "Epoch 24/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0033\n",
      "Epoch 25/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0030\n",
      "Epoch 26/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0029\n",
      "Epoch 27/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0032\n",
      "Epoch 28/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0029\n",
      "Epoch 29/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0031\n",
      "Epoch 30/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0029\n",
      "Epoch 31/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0030\n",
      "Epoch 32/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0030\n",
      "Epoch 33/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0030\n",
      "Epoch 34/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0032\n",
      "Epoch 35/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0029\n",
      "Epoch 36/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0030\n",
      "Epoch 37/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0029\n",
      "Epoch 38/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0028\n",
      "Epoch 39/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0033\n",
      "Epoch 40/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0031\n",
      "Epoch 41/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0034\n",
      "Epoch 42/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0031\n",
      "Epoch 43/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0030\n",
      "Epoch 44/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0028\n",
      "Epoch 45/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0032\n",
      "Epoch 46/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0032\n",
      "Epoch 47/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0027\n",
      "Epoch 48/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0036\n",
      "Epoch 49/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0029\n",
      "Epoch 50/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0030\n",
      "Epoch 51/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0032\n",
      "Epoch 52/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0030\n",
      "Epoch 53/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0030\n",
      "Epoch 54/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0032\n",
      "Epoch 55/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0029\n",
      "Epoch 56/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0029\n",
      "Epoch 57/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0034\n",
      "Epoch 58/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0033\n",
      "Epoch 59/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0028\n",
      "Epoch 60/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0029\n",
      "Epoch 61/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0030\n",
      "Epoch 62/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0029\n",
      "Epoch 63/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0030\n",
      "Epoch 64/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0031\n",
      "Epoch 65/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0031\n",
      "Epoch 66/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0031\n",
      "Epoch 67/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0032\n",
      "Epoch 68/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0031\n",
      "Epoch 69/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0031\n",
      "Epoch 70/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0029\n",
      "Epoch 71/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0032\n",
      "Epoch 72/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0029\n",
      "Epoch 73/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0030\n",
      "Epoch 74/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0029\n",
      "Epoch 75/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0040\n",
      "Epoch 76/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0029\n",
      "Epoch 77/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0029\n",
      "Epoch 78/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0029\n",
      "Epoch 79/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0032\n",
      "Epoch 80/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0032\n",
      "Epoch 81/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0030\n",
      "Epoch 82/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0028\n",
      "Epoch 83/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0028\n",
      "Epoch 85/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0029\n",
      "Epoch 86/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0034\n",
      "Epoch 87/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0031\n",
      "Epoch 88/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0028\n",
      "Epoch 89/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0030\n",
      "Epoch 90/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0030\n",
      "Epoch 91/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0031\n",
      "Epoch 92/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0030\n",
      "Epoch 93/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0028\n",
      "Epoch 94/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0035\n",
      "Epoch 95/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0028\n",
      "Epoch 96/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0030\n",
      "Epoch 97/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0027\n",
      "Epoch 98/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0029\n",
      "Epoch 99/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0030\n",
      "Epoch 100/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0029\n",
      "Epoch 101/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0029\n",
      "Epoch 102/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0029\n",
      "Epoch 103/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0030\n",
      "Epoch 104/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0030\n",
      "Epoch 105/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0029\n",
      "Epoch 106/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0029\n",
      "Epoch 107/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0030\n",
      "Epoch 108/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0029\n",
      "Epoch 109/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0034\n",
      "Epoch 110/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0032\n",
      "Epoch 111/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0033\n",
      "Epoch 112/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0035\n",
      "Epoch 113/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0029\n",
      "Epoch 114/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0027\n",
      "Epoch 115/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0028\n",
      "Epoch 116/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0029\n",
      "Epoch 117/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0030\n",
      "Epoch 118/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0029\n",
      "Epoch 119/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0028\n",
      "Epoch 120/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0031\n",
      "Epoch 121/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0029\n",
      "Epoch 122/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0028\n",
      "Epoch 123/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0028\n",
      "Epoch 124/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0030\n",
      "Epoch 125/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0028\n",
      "Epoch 126/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0028\n",
      "Epoch 127/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0027\n",
      "Epoch 128/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0029\n",
      "Epoch 129/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0029\n",
      "Epoch 130/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0028\n",
      "Epoch 131/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0027\n",
      "Epoch 132/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0029\n",
      "Epoch 133/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0026\n",
      "Epoch 134/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0025\n",
      "Epoch 135/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0032\n",
      "Epoch 136/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0029\n",
      "Epoch 137/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0027\n",
      "Epoch 138/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0027\n",
      "Epoch 139/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0026\n",
      "Epoch 140/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0033\n",
      "Epoch 141/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0030\n",
      "Epoch 142/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0027\n",
      "Epoch 143/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0036\n",
      "Epoch 144/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0027\n",
      "Epoch 145/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0029\n",
      "Epoch 146/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0027\n",
      "Epoch 147/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0027\n",
      "Epoch 148/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0032\n",
      "Epoch 149/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0026\n",
      "Epoch 150/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0026\n",
      "Epoch 151/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0026\n",
      "Epoch 152/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0029\n",
      "Epoch 153/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0029\n",
      "Epoch 154/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0028\n",
      "Epoch 155/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0038\n",
      "Epoch 156/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0028\n",
      "Epoch 157/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0034\n",
      "Epoch 158/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0029\n",
      "Epoch 159/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0027\n",
      "Epoch 160/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0027\n",
      "Epoch 161/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0027\n",
      "Epoch 162/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0031\n",
      "Epoch 163/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0027\n",
      "Epoch 164/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0026\n",
      "Epoch 165/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0027\n",
      "Epoch 166/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0028\n",
      "Epoch 167/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0029\n",
      "Epoch 168/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0029\n",
      "Epoch 169/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0029\n",
      "Epoch 170/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0027\n",
      "Epoch 171/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0030\n",
      "Epoch 172/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0025\n",
      "Epoch 173/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0027\n",
      "Epoch 174/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0029\n",
      "Epoch 175/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0028\n",
      "Epoch 176/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0028\n",
      "Epoch 177/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0029\n",
      "Epoch 178/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0028\n",
      "Epoch 179/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0027\n",
      "Epoch 180/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0026\n",
      "Epoch 181/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0034\n",
      "Epoch 182/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0029\n",
      "Epoch 183/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0027\n",
      "Epoch 184/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0026\n",
      "Epoch 00184: early stopping\n",
      "Epoch 1/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.1348 - val_loss: 0.0174\n",
      "Epoch 2/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0394 - val_loss: 0.0112\n",
      "Epoch 3/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0259 - val_loss: 0.0069\n",
      "Epoch 4/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0204 - val_loss: 0.0058\n",
      "Epoch 5/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0173 - val_loss: 0.0054\n",
      "Epoch 6/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0055\n",
      "Epoch 7/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.0056\n",
      "Epoch 8/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.0048\n",
      "Epoch 9/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.0046\n",
      "Epoch 10/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0048\n",
      "Epoch 11/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0042\n",
      "Epoch 12/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.0039\n",
      "Epoch 13/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0040\n",
      "Epoch 14/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0037\n",
      "Epoch 15/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0041\n",
      "Epoch 16/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0037\n",
      "Epoch 17/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0035\n",
      "Epoch 18/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0032\n",
      "Epoch 19/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0042\n",
      "Epoch 20/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0037\n",
      "Epoch 21/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0034\n",
      "Epoch 22/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0037\n",
      "Epoch 23/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0031\n",
      "Epoch 24/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0031\n",
      "Epoch 25/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0029\n",
      "Epoch 26/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0029\n",
      "Epoch 27/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0034\n",
      "Epoch 28/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0027\n",
      "Epoch 29/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0028\n",
      "Epoch 30/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0028\n",
      "Epoch 31/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0025\n",
      "Epoch 32/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0028\n",
      "Epoch 33/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0024\n",
      "Epoch 34/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0027\n",
      "Epoch 35/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0024\n",
      "Epoch 36/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0025\n",
      "Epoch 37/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0023\n",
      "Epoch 38/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0027\n",
      "Epoch 39/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0032\n",
      "Epoch 40/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0024\n",
      "Epoch 41/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0023\n",
      "Epoch 42/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0026\n",
      "Epoch 43/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0027\n",
      "Epoch 44/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0030\n",
      "Epoch 45/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0024\n",
      "Epoch 46/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0029\n",
      "Epoch 47/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0032\n",
      "Epoch 48/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0023\n",
      "Epoch 49/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0025\n",
      "Epoch 50/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0025\n",
      "Epoch 51/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0029\n",
      "Epoch 52/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0024\n",
      "Epoch 53/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0024\n",
      "Epoch 54/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0026\n",
      "Epoch 55/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0024\n",
      "Epoch 56/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0028\n",
      "Epoch 57/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0032\n",
      "Epoch 58/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0023\n",
      "Epoch 59/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0025\n",
      "Epoch 60/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0026\n",
      "Epoch 61/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0024\n",
      "Epoch 62/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0023\n",
      "Epoch 63/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0026\n",
      "Epoch 64/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0028\n",
      "Epoch 65/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0023\n",
      "Epoch 66/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0024\n",
      "Epoch 67/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0023\n",
      "Epoch 68/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0022\n",
      "Epoch 69/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0030\n",
      "Epoch 70/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0026\n",
      "Epoch 71/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0024\n",
      "Epoch 72/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0026\n",
      "Epoch 73/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0022\n",
      "Epoch 74/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0022\n",
      "Epoch 75/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0024\n",
      "Epoch 76/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0023\n",
      "Epoch 77/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0024\n",
      "Epoch 78/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0024\n",
      "Epoch 79/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0028\n",
      "Epoch 80/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0024\n",
      "Epoch 81/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0027\n",
      "Epoch 82/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0024\n",
      "Epoch 83/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0025\n",
      "Epoch 84/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0025\n",
      "Epoch 85/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0023\n",
      "Epoch 86/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0028\n",
      "Epoch 87/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0026\n",
      "Epoch 88/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0026\n",
      "Epoch 89/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0027\n",
      "Epoch 90/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0024\n",
      "Epoch 91/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0030\n",
      "Epoch 92/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0031\n",
      "Epoch 93/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0025\n",
      "Epoch 94/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0022\n",
      "Epoch 95/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0028\n",
      "Epoch 96/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0022\n",
      "Epoch 97/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0023\n",
      "Epoch 98/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0025\n",
      "Epoch 99/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0023\n",
      "Epoch 100/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0025\n",
      "Epoch 101/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0023\n",
      "Epoch 102/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0022\n",
      "Epoch 103/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0025\n",
      "Epoch 104/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0022\n",
      "Epoch 105/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0027\n",
      "Epoch 106/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0028\n",
      "Epoch 107/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0023\n",
      "Epoch 108/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0024\n",
      "Epoch 109/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0022\n",
      "Epoch 110/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0023\n",
      "Epoch 111/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0024\n",
      "Epoch 112/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0023\n",
      "Epoch 113/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0035\n",
      "Epoch 114/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0023\n",
      "Epoch 115/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0025\n",
      "Epoch 116/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0021\n",
      "Epoch 117/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0023\n",
      "Epoch 118/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0026\n",
      "Epoch 119/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0027\n",
      "Epoch 120/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0023\n",
      "Epoch 121/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0023\n",
      "Epoch 122/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0022\n",
      "Epoch 123/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0021\n",
      "Epoch 124/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0025\n",
      "Epoch 125/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0023\n",
      "Epoch 126/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0023\n",
      "Epoch 127/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0027\n",
      "Epoch 128/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0022\n",
      "Epoch 129/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0022\n",
      "Epoch 130/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0024\n",
      "Epoch 131/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0029\n",
      "Epoch 132/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0028\n",
      "Epoch 133/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0023\n",
      "Epoch 134/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0025\n",
      "Epoch 135/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0025\n",
      "Epoch 136/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0023\n",
      "Epoch 137/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0024\n",
      "Epoch 138/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0023\n",
      "Epoch 139/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0023\n",
      "Epoch 140/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0023\n",
      "Epoch 141/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0024\n",
      "Epoch 142/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0023\n",
      "Epoch 143/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0021\n",
      "Epoch 144/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0022\n",
      "Epoch 145/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0023\n",
      "Epoch 146/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0023\n",
      "Epoch 147/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0030\n",
      "Epoch 148/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0024\n",
      "Epoch 149/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0029\n",
      "Epoch 150/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0026\n",
      "Epoch 151/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0026\n",
      "Epoch 152/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0022\n",
      "Epoch 153/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0022\n",
      "Epoch 154/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0025\n",
      "Epoch 155/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0026\n",
      "Epoch 156/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0024\n",
      "Epoch 157/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0024\n",
      "Epoch 158/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0027\n",
      "Epoch 159/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0023\n",
      "Epoch 160/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0022\n",
      "Epoch 161/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0026\n",
      "Epoch 162/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0024\n",
      "Epoch 163/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0024\n",
      "Epoch 164/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0026\n",
      "Epoch 165/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0023\n",
      "Epoch 166/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0023\n",
      "Epoch 167/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0023\n",
      "Epoch 168/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0025\n",
      "Epoch 169/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0022\n",
      "Epoch 170/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0024\n",
      "Epoch 171/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0026\n",
      "Epoch 172/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0025\n",
      "Epoch 173/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0023\n",
      "Epoch 00173: early stopping\n",
      "Epoch 1/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0187\n",
      "Epoch 2/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0298 - val_loss: 0.0154\n",
      "Epoch 3/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0244 - val_loss: 0.0152\n",
      "Epoch 4/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0220 - val_loss: 0.0152\n",
      "Epoch 5/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0208 - val_loss: 0.0147\n",
      "Epoch 6/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0197 - val_loss: 0.0146\n",
      "Epoch 7/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0191 - val_loss: 0.0150\n",
      "Epoch 8/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0187 - val_loss: 0.0145\n",
      "Epoch 9/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.0145\n",
      "Epoch 10/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0181 - val_loss: 0.0145\n",
      "Epoch 11/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0177 - val_loss: 0.0144\n",
      "Epoch 12/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0175 - val_loss: 0.0146\n",
      "Epoch 13/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0175 - val_loss: 0.0146\n",
      "Epoch 14/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0173 - val_loss: 0.0148\n",
      "Epoch 15/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0171 - val_loss: 0.0145\n",
      "Epoch 16/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0170 - val_loss: 0.0144\n",
      "Epoch 17/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0144\n",
      "Epoch 18/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0145\n",
      "Epoch 19/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0145\n",
      "Epoch 20/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0149\n",
      "Epoch 21/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0148\n",
      "Epoch 22/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0152\n",
      "Epoch 23/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0156\n",
      "Epoch 24/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0145\n",
      "Epoch 25/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0145\n",
      "Epoch 26/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0147\n",
      "Epoch 27/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0148\n",
      "Epoch 28/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0144\n",
      "Epoch 29/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0144\n",
      "Epoch 30/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0150\n",
      "Epoch 31/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0151\n",
      "Epoch 32/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0144\n",
      "Epoch 33/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0145\n",
      "Epoch 34/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0144\n",
      "Epoch 35/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0145\n",
      "Epoch 36/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0146\n",
      "Epoch 37/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0144\n",
      "Epoch 38/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0147\n",
      "Epoch 39/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0145\n",
      "Epoch 40/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0144\n",
      "Epoch 41/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0145\n",
      "Epoch 42/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0144\n",
      "Epoch 43/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0147\n",
      "Epoch 44/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0146\n",
      "Epoch 45/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0149\n",
      "Epoch 46/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0144\n",
      "Epoch 47/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0150\n",
      "Epoch 48/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0144\n",
      "Epoch 49/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0148\n",
      "Epoch 50/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0145\n",
      "Epoch 51/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0146\n",
      "Epoch 52/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0145\n",
      "Epoch 53/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0143\n",
      "Epoch 54/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0147\n",
      "Epoch 55/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0147\n",
      "Epoch 56/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0143\n",
      "Epoch 57/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0145\n",
      "Epoch 58/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0145\n",
      "Epoch 59/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0144\n",
      "Epoch 60/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0151\n",
      "Epoch 61/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0143\n",
      "Epoch 62/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0145\n",
      "Epoch 63/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0146\n",
      "Epoch 64/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0146\n",
      "Epoch 65/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0145\n",
      "Epoch 66/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0145\n",
      "Epoch 67/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0144\n",
      "Epoch 68/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0143\n",
      "Epoch 69/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0144\n",
      "Epoch 70/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0147\n",
      "Epoch 71/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0147\n",
      "Epoch 72/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0146\n",
      "Epoch 73/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0145\n",
      "Epoch 74/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0144\n",
      "Epoch 75/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0145\n",
      "Epoch 76/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0143\n",
      "Epoch 77/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0147\n",
      "Epoch 78/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0145\n",
      "Epoch 79/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0145\n",
      "Epoch 80/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0143\n",
      "Epoch 81/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0144\n",
      "Epoch 82/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0144\n",
      "Epoch 83/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0144\n",
      "Epoch 84/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0144\n",
      "Epoch 85/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0143\n",
      "Epoch 86/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0148\n",
      "Epoch 87/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0144\n",
      "Epoch 88/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0145\n",
      "Epoch 89/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0143\n",
      "Epoch 90/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0148\n",
      "Epoch 91/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0144\n",
      "Epoch 92/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0145\n",
      "Epoch 93/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0144\n",
      "Epoch 94/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0144\n",
      "Epoch 95/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0144\n",
      "Epoch 96/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0146\n",
      "Epoch 97/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0146\n",
      "Epoch 98/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0144\n",
      "Epoch 99/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0144\n",
      "Epoch 100/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0145\n",
      "Epoch 101/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0145\n",
      "Epoch 102/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0146\n",
      "Epoch 103/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0147\n",
      "Epoch 104/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0145\n",
      "Epoch 105/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0146\n",
      "Epoch 106/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0144\n",
      "Epoch 107/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0147\n",
      "Epoch 108/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0143\n",
      "Epoch 109/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0147\n",
      "Epoch 110/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0147\n",
      "Epoch 111/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0144\n",
      "Epoch 112/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0143\n",
      "Epoch 113/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0145\n",
      "Epoch 114/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0144\n",
      "Epoch 115/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0143\n",
      "Epoch 116/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0143\n",
      "Epoch 117/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0144\n",
      "Epoch 118/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0143\n",
      "Epoch 119/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0144\n",
      "Epoch 120/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0145\n",
      "Epoch 121/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0145\n",
      "Epoch 122/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0143\n",
      "Epoch 123/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0145\n",
      "Epoch 124/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0144\n",
      "Epoch 125/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0144\n",
      "Epoch 126/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0143\n",
      "Epoch 127/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0143\n",
      "Epoch 128/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0143\n",
      "Epoch 129/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0143\n",
      "Epoch 130/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0143\n",
      "Epoch 131/10000\n",
      "151/151 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.0146\n",
      "Epoch 132/10000\n",
      "151/151 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.0147\n",
      "Epoch 133/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0144\n",
      "Epoch 134/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0145\n",
      "Epoch 135/10000\n",
      "151/151 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.0145\n",
      "Epoch 136/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0146\n",
      "Epoch 137/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0144\n",
      "Epoch 138/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0146\n",
      "Epoch 139/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0143\n",
      "Epoch 140/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0143\n",
      "Epoch 141/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0146\n",
      "Epoch 142/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0149\n",
      "Epoch 143/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0144\n",
      "Epoch 144/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0143\n",
      "Epoch 145/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0145\n",
      "Epoch 146/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0143\n",
      "Epoch 147/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0146\n",
      "Epoch 148/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0144\n",
      "Epoch 149/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0146\n",
      "Epoch 150/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0148\n",
      "Epoch 151/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0146\n",
      "Epoch 152/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0144\n",
      "Epoch 153/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0146\n",
      "Epoch 154/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0146\n",
      "Epoch 155/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0145\n",
      "Epoch 156/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0146\n",
      "Epoch 157/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0145\n",
      "Epoch 158/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0146\n",
      "Epoch 00158: early stopping\n",
      "Epoch 1/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0943 - val_loss: 0.0150\n",
      "Epoch 2/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0281 - val_loss: 0.0116\n",
      "Epoch 3/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0194 - val_loss: 0.0088\n",
      "Epoch 4/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0090\n",
      "Epoch 5/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0088\n",
      "Epoch 6/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0142 - val_loss: 0.0082\n",
      "Epoch 7/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.0082\n",
      "Epoch 8/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.0086\n",
      "Epoch 9/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.0081\n",
      "Epoch 10/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.0082\n",
      "Epoch 11/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.0084\n",
      "Epoch 12/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0082\n",
      "Epoch 13/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0081\n",
      "Epoch 14/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0084\n",
      "Epoch 15/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0082\n",
      "Epoch 16/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0089\n",
      "Epoch 17/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0080\n",
      "Epoch 18/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.0080\n",
      "Epoch 19/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.0081\n",
      "Epoch 20/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.0082\n",
      "Epoch 21/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0084\n",
      "Epoch 22/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0081\n",
      "Epoch 23/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0082\n",
      "Epoch 24/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0082\n",
      "Epoch 25/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0088\n",
      "Epoch 26/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0081\n",
      "Epoch 27/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0082\n",
      "Epoch 28/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0081\n",
      "Epoch 29/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0081\n",
      "Epoch 30/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0085\n",
      "Epoch 31/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0081\n",
      "Epoch 32/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0082\n",
      "Epoch 33/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0080\n",
      "Epoch 34/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0084\n",
      "Epoch 35/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0082\n",
      "Epoch 36/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0084\n",
      "Epoch 37/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0081\n",
      "Epoch 38/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0080\n",
      "Epoch 39/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0084\n",
      "Epoch 40/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0081\n",
      "Epoch 41/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0083\n",
      "Epoch 42/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0081\n",
      "Epoch 43/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0080\n",
      "Epoch 44/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0082\n",
      "Epoch 45/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0085\n",
      "Epoch 46/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0080\n",
      "Epoch 47/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0081\n",
      "Epoch 48/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 49/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0085\n",
      "Epoch 50/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0081\n",
      "Epoch 51/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0080\n",
      "Epoch 52/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0080\n",
      "Epoch 53/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 54/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0082\n",
      "Epoch 55/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0080\n",
      "Epoch 56/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0081\n",
      "Epoch 57/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0082\n",
      "Epoch 58/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 59/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0082\n",
      "Epoch 60/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0080\n",
      "Epoch 61/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 62/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0082\n",
      "Epoch 63/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0080\n",
      "Epoch 64/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0083\n",
      "Epoch 65/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 66/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0081\n",
      "Epoch 67/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0082\n",
      "Epoch 00067: early stopping\n",
      "Epoch 1/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0996 - val_loss: 0.0165\n",
      "Epoch 2/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0269 - val_loss: 0.0091\n",
      "Epoch 3/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0189 - val_loss: 0.0070\n",
      "Epoch 4/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.0049\n",
      "Epoch 5/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.0057\n",
      "Epoch 6/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0047\n",
      "Epoch 7/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0047\n",
      "Epoch 8/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0051\n",
      "Epoch 9/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0052\n",
      "Epoch 10/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0045\n",
      "Epoch 11/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0046\n",
      "Epoch 12/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0045\n",
      "Epoch 13/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0046\n",
      "Epoch 14/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0045\n",
      "Epoch 15/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0048\n",
      "Epoch 16/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 17/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0048\n",
      "Epoch 18/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0045\n",
      "Epoch 19/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0049\n",
      "Epoch 20/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0046\n",
      "Epoch 21/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0044\n",
      "Epoch 22/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0047\n",
      "Epoch 23/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0047\n",
      "Epoch 24/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0061\n",
      "Epoch 25/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0047\n",
      "Epoch 26/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0044\n",
      "Epoch 27/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0050\n",
      "Epoch 28/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0046\n",
      "Epoch 29/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0051\n",
      "Epoch 30/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0048\n",
      "Epoch 31/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0045\n",
      "Epoch 32/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0046\n",
      "Epoch 33/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0048\n",
      "Epoch 34/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0050\n",
      "Epoch 35/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0046\n",
      "Epoch 36/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0048\n",
      "Epoch 37/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0044\n",
      "Epoch 38/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0044\n",
      "Epoch 39/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0050\n",
      "Epoch 40/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0044\n",
      "Epoch 41/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0049\n",
      "Epoch 42/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0044\n",
      "Epoch 43/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 44/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0046\n",
      "Epoch 45/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0045\n",
      "Epoch 46/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 47/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 48/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 49/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0048\n",
      "Epoch 50/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 51/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 52/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 53/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0044\n",
      "Epoch 54/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 55/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0044\n",
      "Epoch 56/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 57/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0049\n",
      "Epoch 58/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 59/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 60/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 61/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 62/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 63/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 64/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 65/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 66/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 67/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 68/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 69/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0051\n",
      "Epoch 70/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0050\n",
      "Epoch 71/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 72/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 73/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 74/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 75/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 76/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 77/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 78/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 79/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 80/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 81/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 82/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 83/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 84/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 85/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 86/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 87/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 88/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 89/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 90/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 91/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 92/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 93/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 94/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 95/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 96/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 97/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 98/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 99/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 100/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 101/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 102/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 103/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 104/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 105/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 106/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 107/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 108/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 109/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 110/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 111/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 112/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 113/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 114/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 115/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 116/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 117/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 118/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 119/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 120/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 121/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 122/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 123/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 124/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 125/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 126/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 127/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 128/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 129/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 130/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 131/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 132/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 133/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 134/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 135/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 136/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 137/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 138/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 139/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 140/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 141/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 142/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 143/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 144/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 145/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 146/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 147/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 148/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 149/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 150/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 151/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 152/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 153/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 154/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0042\n",
      "Epoch 155/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 156/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 157/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 158/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 159/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 160/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 161/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 00161: early stopping\n",
      "Epoch 1/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0909 - val_loss: 0.0110\n",
      "Epoch 2/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0252 - val_loss: 0.0070\n",
      "Epoch 3/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0170 - val_loss: 0.0047\n",
      "Epoch 4/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0046\n",
      "Epoch 5/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.0045\n",
      "Epoch 6/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0042\n",
      "Epoch 7/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0044\n",
      "Epoch 8/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0035\n",
      "Epoch 9/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0040\n",
      "Epoch 10/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0037\n",
      "Epoch 11/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0038\n",
      "Epoch 12/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0037\n",
      "Epoch 13/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0036\n",
      "Epoch 14/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0034\n",
      "Epoch 15/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0034\n",
      "Epoch 16/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0037\n",
      "Epoch 17/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0037\n",
      "Epoch 18/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0034\n",
      "Epoch 19/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0033\n",
      "Epoch 20/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0034\n",
      "Epoch 21/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0033\n",
      "Epoch 22/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0031\n",
      "Epoch 23/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0034\n",
      "Epoch 24/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0035\n",
      "Epoch 25/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0037\n",
      "Epoch 26/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0033\n",
      "Epoch 27/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0034\n",
      "Epoch 28/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0034\n",
      "Epoch 29/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0038\n",
      "Epoch 30/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0038\n",
      "Epoch 31/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0038\n",
      "Epoch 32/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0035\n",
      "Epoch 33/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0037\n",
      "Epoch 34/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0037\n",
      "Epoch 35/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0035\n",
      "Epoch 36/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0034\n",
      "Epoch 37/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0035\n",
      "Epoch 38/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0036\n",
      "Epoch 39/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0038\n",
      "Epoch 40/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0033\n",
      "Epoch 41/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0033\n",
      "Epoch 42/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0033\n",
      "Epoch 43/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0033\n",
      "Epoch 44/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0034\n",
      "Epoch 45/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0037\n",
      "Epoch 46/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0035\n",
      "Epoch 47/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0034\n",
      "Epoch 48/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0035\n",
      "Epoch 49/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0034\n",
      "Epoch 50/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0038\n",
      "Epoch 51/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0033\n",
      "Epoch 52/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0033\n",
      "Epoch 53/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0035\n",
      "Epoch 54/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 55/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0032\n",
      "Epoch 56/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 57/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0037\n",
      "Epoch 58/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0034\n",
      "Epoch 59/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0032\n",
      "Epoch 60/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 61/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 62/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0034\n",
      "Epoch 63/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 64/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0033\n",
      "Epoch 65/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0033\n",
      "Epoch 66/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 67/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 68/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0033\n",
      "Epoch 69/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 70/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0034\n",
      "Epoch 71/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0032\n",
      "Epoch 72/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0036\n",
      "Epoch 73/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0033\n",
      "Epoch 74/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 75/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0033\n",
      "Epoch 76/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0032\n",
      "Epoch 77/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 78/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 79/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 80/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 81/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 82/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0034\n",
      "Epoch 83/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0032\n",
      "Epoch 84/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 85/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 86/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0032\n",
      "Epoch 87/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0035\n",
      "Epoch 88/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 89/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0036\n",
      "Epoch 90/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0032\n",
      "Epoch 91/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0032\n",
      "Epoch 92/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 93/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 94/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 95/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 96/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 97/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0032\n",
      "Epoch 98/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 99/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 100/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 101/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0032\n",
      "Epoch 102/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0036\n",
      "Epoch 103/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0032\n",
      "Epoch 104/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0032\n",
      "Epoch 105/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 106/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 107/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0036\n",
      "Epoch 108/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 109/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 110/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 111/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0032\n",
      "Epoch 112/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 113/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 114/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 115/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0032\n",
      "Epoch 116/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0032\n",
      "Epoch 117/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 00117: early stopping\n",
      "Epoch 1/10000\n",
      "151/151 [==============================] - 0s 3ms/step - loss: 0.0923 - val_loss: 0.0105\n",
      "Epoch 2/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0251 - val_loss: 0.0060\n",
      "Epoch 3/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0171 - val_loss: 0.0051\n",
      "Epoch 4/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0044\n",
      "Epoch 5/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.0043\n",
      "Epoch 6/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0034\n",
      "Epoch 7/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0034\n",
      "Epoch 8/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0044\n",
      "Epoch 9/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0031\n",
      "Epoch 10/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0035\n",
      "Epoch 11/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0028\n",
      "Epoch 12/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0030\n",
      "Epoch 13/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0034\n",
      "Epoch 14/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0031\n",
      "Epoch 15/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0026\n",
      "Epoch 16/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0030\n",
      "Epoch 17/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0028\n",
      "Epoch 18/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0026\n",
      "Epoch 19/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0030\n",
      "Epoch 20/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0027\n",
      "Epoch 21/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0029\n",
      "Epoch 22/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0027\n",
      "Epoch 23/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0027\n",
      "Epoch 24/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0029\n",
      "Epoch 25/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0031\n",
      "Epoch 26/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0035\n",
      "Epoch 27/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0034\n",
      "Epoch 28/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0026\n",
      "Epoch 29/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0031\n",
      "Epoch 30/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0027\n",
      "Epoch 31/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0026\n",
      "Epoch 32/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0029\n",
      "Epoch 33/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0030\n",
      "Epoch 34/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0026\n",
      "Epoch 35/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 36/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0026\n",
      "Epoch 37/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0027\n",
      "Epoch 38/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0025\n",
      "Epoch 39/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0026\n",
      "Epoch 40/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0025\n",
      "Epoch 41/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0026\n",
      "Epoch 42/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0027\n",
      "Epoch 43/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0026\n",
      "Epoch 44/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0025\n",
      "Epoch 45/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0028\n",
      "Epoch 46/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0029\n",
      "Epoch 47/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0026\n",
      "Epoch 48/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 49/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 50/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 51/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0027\n",
      "Epoch 52/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0025\n",
      "Epoch 53/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0023\n",
      "Epoch 54/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 55/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 56/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 57/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0025\n",
      "Epoch 58/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0022\n",
      "Epoch 59/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 60/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 61/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0023\n",
      "Epoch 62/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 63/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 64/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 65/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0022\n",
      "Epoch 66/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 67/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 68/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 69/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 70/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 71/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 72/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 73/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 74/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 75/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0022\n",
      "Epoch 76/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 77/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 78/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 79/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0021\n",
      "Epoch 80/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0025\n",
      "Epoch 81/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 82/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 84/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 85/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 86/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 87/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 88/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0021\n",
      "Epoch 89/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 90/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 91/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 92/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 93/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 94/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 95/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0025\n",
      "Epoch 96/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 97/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 98/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 99/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 100/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 101/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 102/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 103/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 104/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 105/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 106/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 107/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 108/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 109/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 110/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 111/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 112/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 113/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0033\n",
      "Epoch 114/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 115/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0021\n",
      "Epoch 116/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 117/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 118/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 119/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 120/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0021\n",
      "Epoch 121/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 122/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 123/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 124/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 125/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 126/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 127/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 128/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 129/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 130/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 131/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 132/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 133/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 134/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 135/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 136/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 137/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 138/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 139/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 140/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 141/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 142/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0021\n",
      "Epoch 143/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 144/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 145/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 146/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 147/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 148/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 149/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 150/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 151/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 152/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 153/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 154/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 155/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 156/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 157/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 158/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 159/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 160/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 161/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 162/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 163/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 164/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 165/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 166/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 167/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 168/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 169/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 170/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 171/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 172/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 173/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 174/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 175/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 176/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 177/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 178/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0021\n",
      "Epoch 179/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 180/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 181/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 182/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 183/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 184/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0020\n",
      "Epoch 185/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 186/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 187/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 188/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 189/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 190/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 191/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 192/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 193/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 194/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 195/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 196/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 197/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 198/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 199/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 200/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 201/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 202/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 203/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 204/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 205/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 206/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 207/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 208/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 209/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 210/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 211/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 212/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 213/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 214/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 215/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 216/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0020\n",
      "Epoch 217/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 218/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 219/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 220/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 221/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 222/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 223/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 224/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 225/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 226/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 227/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 228/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 229/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 230/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0021\n",
      "Epoch 231/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 232/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 233/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 234/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 235/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 236/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 237/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 238/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 239/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 240/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 241/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0020\n",
      "Epoch 242/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 243/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 244/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 245/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 246/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 247/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 248/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 249/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 250/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 00250: early stopping\n",
      "Epoch 1/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0937 - val_loss: 0.0098\n",
      "Epoch 2/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0245 - val_loss: 0.0061\n",
      "Epoch 3/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0052\n",
      "Epoch 4/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.0039\n",
      "Epoch 5/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0033\n",
      "Epoch 6/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0030\n",
      "Epoch 7/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0034\n",
      "Epoch 8/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0027\n",
      "Epoch 9/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0030\n",
      "Epoch 10/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0022\n",
      "Epoch 11/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0024\n",
      "Epoch 12/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0027\n",
      "Epoch 13/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0026\n",
      "Epoch 14/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0023\n",
      "Epoch 15/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0029\n",
      "Epoch 16/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0028\n",
      "Epoch 17/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0021\n",
      "Epoch 18/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0022\n",
      "Epoch 19/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0021\n",
      "Epoch 20/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0025\n",
      "Epoch 21/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0023\n",
      "Epoch 22/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0022\n",
      "Epoch 23/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0026\n",
      "Epoch 24/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0020\n",
      "Epoch 25/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0030\n",
      "Epoch 26/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0021\n",
      "Epoch 27/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0020\n",
      "Epoch 28/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0020\n",
      "Epoch 29/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0026\n",
      "Epoch 30/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0021\n",
      "Epoch 31/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0025\n",
      "Epoch 32/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0020\n",
      "Epoch 33/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0019\n",
      "Epoch 34/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0021\n",
      "Epoch 35/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0023\n",
      "Epoch 36/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 37/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0024\n",
      "Epoch 38/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0020\n",
      "Epoch 39/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0020\n",
      "Epoch 40/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0019\n",
      "Epoch 41/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 42/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0022\n",
      "Epoch 43/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0019\n",
      "Epoch 44/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0025\n",
      "Epoch 45/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 46/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0022\n",
      "Epoch 47/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 48/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0019\n",
      "Epoch 49/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0023\n",
      "Epoch 50/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 51/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0019\n",
      "Epoch 52/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 53/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 54/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0019\n",
      "Epoch 55/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0020\n",
      "Epoch 56/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 57/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0019\n",
      "Epoch 58/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 59/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 60/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0020\n",
      "Epoch 61/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 62/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0019\n",
      "Epoch 63/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 64/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 65/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0019\n",
      "Epoch 66/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0019\n",
      "Epoch 67/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0020\n",
      "Epoch 68/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 69/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0019\n",
      "Epoch 70/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0019\n",
      "Epoch 71/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 72/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0020\n",
      "Epoch 73/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0018\n",
      "Epoch 74/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0018\n",
      "Epoch 75/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0019\n",
      "Epoch 76/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0020\n",
      "Epoch 77/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0020\n",
      "Epoch 78/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 79/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0019\n",
      "Epoch 80/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 81/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 82/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 83/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0020\n",
      "Epoch 84/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 85/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0019\n",
      "Epoch 86/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0019\n",
      "Epoch 87/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0019\n",
      "Epoch 88/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 89/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0019\n",
      "Epoch 90/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 91/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 92/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0018\n",
      "Epoch 93/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 94/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0019\n",
      "Epoch 95/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 96/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 97/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0018\n",
      "Epoch 98/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 99/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0019\n",
      "Epoch 100/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 101/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 102/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0018\n",
      "Epoch 103/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 104/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 105/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 106/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0020\n",
      "Epoch 107/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0018\n",
      "Epoch 108/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0018\n",
      "Epoch 109/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0018\n",
      "Epoch 110/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 111/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0019\n",
      "Epoch 112/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0019\n",
      "Epoch 113/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 114/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 115/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 116/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0017\n",
      "Epoch 117/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0019\n",
      "Epoch 118/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 119/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0019\n",
      "Epoch 120/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 121/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 122/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0019\n",
      "Epoch 123/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 124/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0018\n",
      "Epoch 125/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0018\n",
      "Epoch 126/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 127/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0019\n",
      "Epoch 128/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 129/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0019\n",
      "Epoch 130/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 131/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 132/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 133/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 134/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 135/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0018\n",
      "Epoch 136/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 137/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0018\n",
      "Epoch 138/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 139/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0019\n",
      "Epoch 140/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 141/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 142/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 143/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 144/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0018\n",
      "Epoch 145/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0019\n",
      "Epoch 146/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 147/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 148/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0018\n",
      "Epoch 149/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 150/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0018\n",
      "Epoch 151/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0018\n",
      "Epoch 152/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 153/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0019\n",
      "Epoch 154/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0018\n",
      "Epoch 155/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 156/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0017\n",
      "Epoch 157/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 158/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0018\n",
      "Epoch 159/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 160/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0019\n",
      "Epoch 161/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 162/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0017\n",
      "Epoch 163/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0019\n",
      "Epoch 164/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0018\n",
      "Epoch 165/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0018\n",
      "Epoch 166/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0018\n",
      "Epoch 00166: early stopping\n",
      "Epoch 1/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0890 - val_loss: 0.0155\n",
      "Epoch 2/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0246 - val_loss: 0.0146\n",
      "Epoch 3/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0216 - val_loss: 0.0146\n",
      "Epoch 4/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0200 - val_loss: 0.0150\n",
      "Epoch 5/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0191 - val_loss: 0.0150\n",
      "Epoch 6/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0185 - val_loss: 0.0147\n",
      "Epoch 7/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0179 - val_loss: 0.0145\n",
      "Epoch 8/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0175 - val_loss: 0.0145\n",
      "Epoch 9/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0173 - val_loss: 0.0151\n",
      "Epoch 10/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0171 - val_loss: 0.0145\n",
      "Epoch 11/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0146\n",
      "Epoch 12/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0144\n",
      "Epoch 13/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0144\n",
      "Epoch 14/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0144\n",
      "Epoch 15/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0149\n",
      "Epoch 16/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0144\n",
      "Epoch 17/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0146\n",
      "Epoch 18/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0144\n",
      "Epoch 19/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0144\n",
      "Epoch 20/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0145\n",
      "Epoch 21/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0145\n",
      "Epoch 22/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0148\n",
      "Epoch 23/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0144\n",
      "Epoch 24/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0144\n",
      "Epoch 25/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0146\n",
      "Epoch 26/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0145\n",
      "Epoch 27/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0144\n",
      "Epoch 28/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0146\n",
      "Epoch 29/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0147\n",
      "Epoch 30/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0144\n",
      "Epoch 31/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0149\n",
      "Epoch 32/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0144\n",
      "Epoch 33/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0152\n",
      "Epoch 34/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0147\n",
      "Epoch 35/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0145\n",
      "Epoch 36/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0145\n",
      "Epoch 37/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0144\n",
      "Epoch 38/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0146\n",
      "Epoch 39/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0144\n",
      "Epoch 40/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0146\n",
      "Epoch 41/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0144\n",
      "Epoch 42/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0144\n",
      "Epoch 43/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0148\n",
      "Epoch 44/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0145\n",
      "Epoch 45/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0145\n",
      "Epoch 46/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0145\n",
      "Epoch 47/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0148\n",
      "Epoch 48/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0147\n",
      "Epoch 49/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0145\n",
      "Epoch 50/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0144\n",
      "Epoch 51/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0144\n",
      "Epoch 52/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0144\n",
      "Epoch 53/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0144\n",
      "Epoch 54/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0146\n",
      "Epoch 55/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0145\n",
      "Epoch 56/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0148\n",
      "Epoch 57/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0144\n",
      "Epoch 58/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0144\n",
      "Epoch 59/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0143\n",
      "Epoch 60/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0145\n",
      "Epoch 61/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0146\n",
      "Epoch 62/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0147\n",
      "Epoch 63/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0144\n",
      "Epoch 64/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0144\n",
      "Epoch 65/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0147\n",
      "Epoch 66/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0144\n",
      "Epoch 67/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0143\n",
      "Epoch 68/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0143\n",
      "Epoch 69/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0144\n",
      "Epoch 70/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0144\n",
      "Epoch 71/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0146\n",
      "Epoch 72/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0144\n",
      "Epoch 73/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0146\n",
      "Epoch 74/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0145\n",
      "Epoch 75/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0147\n",
      "Epoch 76/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0145\n",
      "Epoch 77/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0144\n",
      "Epoch 78/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0146\n",
      "Epoch 79/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0145\n",
      "Epoch 80/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0144\n",
      "Epoch 81/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0152\n",
      "Epoch 82/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0144\n",
      "Epoch 83/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0149\n",
      "Epoch 84/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0150\n",
      "Epoch 85/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0151\n",
      "Epoch 86/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0144\n",
      "Epoch 87/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0146\n",
      "Epoch 88/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0144\n",
      "Epoch 89/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0144\n",
      "Epoch 90/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0147\n",
      "Epoch 91/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0144\n",
      "Epoch 92/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0144\n",
      "Epoch 93/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0144\n",
      "Epoch 94/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0147\n",
      "Epoch 95/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0143\n",
      "Epoch 96/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0144\n",
      "Epoch 97/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0145\n",
      "Epoch 98/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0147\n",
      "Epoch 99/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0149\n",
      "Epoch 100/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0144\n",
      "Epoch 101/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0147\n",
      "Epoch 102/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0144\n",
      "Epoch 103/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0157\n",
      "Epoch 104/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0144\n",
      "Epoch 105/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0144\n",
      "Epoch 106/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0149\n",
      "Epoch 107/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0145\n",
      "Epoch 108/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0145\n",
      "Epoch 109/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0144\n",
      "Epoch 110/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0143\n",
      "Epoch 111/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0146\n",
      "Epoch 112/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0147\n",
      "Epoch 113/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0145\n",
      "Epoch 114/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0144\n",
      "Epoch 115/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0145\n",
      "Epoch 116/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0145\n",
      "Epoch 117/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0148\n",
      "Epoch 118/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0143\n",
      "Epoch 00118: early stopping\n",
      "Epoch 1/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0601 - val_loss: 0.0134\n",
      "Epoch 2/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0209 - val_loss: 0.0087\n",
      "Epoch 3/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0084\n",
      "Epoch 4/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.0082\n",
      "Epoch 5/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.0090\n",
      "Epoch 6/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.0081\n",
      "Epoch 7/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0081\n",
      "Epoch 8/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0081\n",
      "Epoch 9/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.0082\n",
      "Epoch 10/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0084\n",
      "Epoch 11/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0080\n",
      "Epoch 12/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0080\n",
      "Epoch 13/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0080\n",
      "Epoch 14/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0080\n",
      "Epoch 15/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0084\n",
      "Epoch 16/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0081\n",
      "Epoch 17/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0083\n",
      "Epoch 18/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0094\n",
      "Epoch 19/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0084\n",
      "Epoch 20/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0082\n",
      "Epoch 21/10000\n",
      "151/151 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.0082\n",
      "Epoch 22/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0084\n",
      "Epoch 23/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0080\n",
      "Epoch 24/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0080\n",
      "Epoch 25/10000\n",
      "151/151 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.0091\n",
      "Epoch 26/10000\n",
      "151/151 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.0085\n",
      "Epoch 27/10000\n",
      "151/151 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0080\n",
      "Epoch 28/10000\n",
      "151/151 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 29/10000\n",
      "151/151 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0081\n",
      "Epoch 30/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0080\n",
      "Epoch 31/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0083\n",
      "Epoch 32/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0083\n",
      "Epoch 33/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0080\n",
      "Epoch 34/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0081\n",
      "Epoch 35/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0085\n",
      "Epoch 36/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0080\n",
      "Epoch 37/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0079\n",
      "Epoch 38/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0086\n",
      "Epoch 39/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0084\n",
      "Epoch 40/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0087\n",
      "Epoch 41/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0086\n",
      "Epoch 42/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0080\n",
      "Epoch 43/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0082\n",
      "Epoch 44/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0081\n",
      "Epoch 45/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0081\n",
      "Epoch 46/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0080\n",
      "Epoch 47/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0080\n",
      "Epoch 48/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0081\n",
      "Epoch 49/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0091\n",
      "Epoch 50/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0080\n",
      "Epoch 51/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0081\n",
      "Epoch 52/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0080\n",
      "Epoch 53/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0087\n",
      "Epoch 54/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0082\n",
      "Epoch 55/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0080\n",
      "Epoch 56/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0080\n",
      "Epoch 57/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0080\n",
      "Epoch 58/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0080\n",
      "Epoch 59/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0081\n",
      "Epoch 60/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0081\n",
      "Epoch 61/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0080\n",
      "Epoch 62/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0080\n",
      "Epoch 63/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0081\n",
      "Epoch 64/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0080\n",
      "Epoch 65/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0080\n",
      "Epoch 66/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0085\n",
      "Epoch 67/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0087\n",
      "Epoch 68/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0080\n",
      "Epoch 69/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0081\n",
      "Epoch 70/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0083\n",
      "Epoch 71/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0079\n",
      "Epoch 72/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0080\n",
      "Epoch 73/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0084\n",
      "Epoch 74/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0080\n",
      "Epoch 75/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0081\n",
      "Epoch 76/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0082\n",
      "Epoch 77/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0084\n",
      "Epoch 78/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0083\n",
      "Epoch 79/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0081\n",
      "Epoch 80/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0080\n",
      "Epoch 81/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0082\n",
      "Epoch 82/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0083\n",
      "Epoch 83/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0080\n",
      "Epoch 84/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0082\n",
      "Epoch 85/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0080\n",
      "Epoch 86/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0081\n",
      "Epoch 87/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0080\n",
      "Epoch 00087: early stopping\n",
      "Epoch 1/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0761 - val_loss: 0.0091\n",
      "Epoch 2/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0202 - val_loss: 0.0078\n",
      "Epoch 3/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.0048\n",
      "Epoch 4/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0046\n",
      "Epoch 5/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0046\n",
      "Epoch 6/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 7/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0056\n",
      "Epoch 8/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0048\n",
      "Epoch 9/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0045\n",
      "Epoch 10/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0044\n",
      "Epoch 11/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0065\n",
      "Epoch 12/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0045\n",
      "Epoch 13/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0046\n",
      "Epoch 14/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0046\n",
      "Epoch 15/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0046\n",
      "Epoch 16/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0045\n",
      "Epoch 17/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0050\n",
      "Epoch 18/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0044\n",
      "Epoch 19/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0044\n",
      "Epoch 20/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0046\n",
      "Epoch 21/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0048\n",
      "Epoch 22/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0044\n",
      "Epoch 23/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0045\n",
      "Epoch 24/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0048\n",
      "Epoch 25/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0044\n",
      "Epoch 26/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0044\n",
      "Epoch 27/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 28/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0055\n",
      "Epoch 29/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0049\n",
      "Epoch 30/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 31/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 32/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 33/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 34/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 35/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 36/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 37/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 38/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 39/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 40/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 41/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 42/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 43/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 44/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 45/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 46/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 47/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 48/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 49/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 50/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 51/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 52/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 53/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 54/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 55/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 56/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 57/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 58/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 59/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 60/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 61/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 62/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 63/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 64/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 65/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 66/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 67/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 68/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 69/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 70/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 71/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 72/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 73/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 74/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 75/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 76/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 77/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 78/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 79/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 80/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 81/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 82/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 83/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 84/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 85/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 86/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 88/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 89/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 90/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 91/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 92/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 93/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 94/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 95/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 96/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 97/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 98/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 00098: early stopping\n",
      "Epoch 1/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0674 - val_loss: 0.0071\n",
      "Epoch 2/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0173 - val_loss: 0.0049\n",
      "Epoch 3/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.0048\n",
      "Epoch 4/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0040\n",
      "Epoch 5/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0040\n",
      "Epoch 6/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0036\n",
      "Epoch 7/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0039\n",
      "Epoch 8/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0035\n",
      "Epoch 9/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0034\n",
      "Epoch 10/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0034\n",
      "Epoch 11/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0044\n",
      "Epoch 12/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0034\n",
      "Epoch 13/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0032\n",
      "Epoch 14/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0034\n",
      "Epoch 15/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0033\n",
      "Epoch 16/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0032\n",
      "Epoch 17/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0032\n",
      "Epoch 18/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0033\n",
      "Epoch 19/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0034\n",
      "Epoch 20/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 21/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0038\n",
      "Epoch 22/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0039\n",
      "Epoch 23/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0033\n",
      "Epoch 24/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0033\n",
      "Epoch 25/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0033\n",
      "Epoch 26/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0033\n",
      "Epoch 27/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0032\n",
      "Epoch 28/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0033\n",
      "Epoch 29/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 30/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 31/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0032\n",
      "Epoch 32/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 33/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 34/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 35/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 36/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 37/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 38/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0035\n",
      "Epoch 39/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 40/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 41/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 42/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 43/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 44/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0033\n",
      "Epoch 45/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 46/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0033\n",
      "Epoch 47/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 48/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0032\n",
      "Epoch 49/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 50/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 51/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 52/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 53/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 54/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0036\n",
      "Epoch 55/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 56/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 57/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 58/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 59/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 60/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 61/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 62/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 63/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 64/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0036\n",
      "Epoch 65/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 66/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 67/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 68/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 69/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 70/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 71/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 72/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 73/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 74/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 75/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 76/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 77/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 78/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 79/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 80/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 81/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 82/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 83/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 84/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0033\n",
      "Epoch 85/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 86/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 87/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 88/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 89/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 90/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 91/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 92/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 93/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 94/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 95/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 96/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 97/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 98/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 99/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 100/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 101/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 102/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 103/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 104/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 105/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 106/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 107/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 108/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0033\n",
      "Epoch 109/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 110/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 111/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 112/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 113/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 114/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 115/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 116/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 117/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0033\n",
      "Epoch 118/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 119/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 120/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0033\n",
      "Epoch 121/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 122/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0033\n",
      "Epoch 123/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 124/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0033\n",
      "Epoch 125/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 126/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 127/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 128/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 129/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 130/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 131/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 132/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 133/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 134/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 135/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 136/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 137/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 138/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 139/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0033\n",
      "Epoch 140/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 141/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 142/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 143/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 144/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 145/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 146/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 00146: early stopping\n",
      "Epoch 1/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0699 - val_loss: 0.0055\n",
      "Epoch 2/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0175 - val_loss: 0.0058\n",
      "Epoch 3/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.0039\n",
      "Epoch 4/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0031\n",
      "Epoch 5/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0029\n",
      "Epoch 6/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0028\n",
      "Epoch 7/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0027\n",
      "Epoch 8/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0027\n",
      "Epoch 9/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0026\n",
      "Epoch 10/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0031\n",
      "Epoch 11/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0040\n",
      "Epoch 12/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0031\n",
      "Epoch 13/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0024\n",
      "Epoch 14/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0026\n",
      "Epoch 15/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0025\n",
      "Epoch 16/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0025\n",
      "Epoch 17/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0025\n",
      "Epoch 18/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0025\n",
      "Epoch 19/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0025\n",
      "Epoch 20/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0026\n",
      "Epoch 21/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 22/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0026\n",
      "Epoch 23/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0026\n",
      "Epoch 24/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 25/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0034\n",
      "Epoch 26/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 27/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 28/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0025\n",
      "Epoch 29/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 30/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 31/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 32/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0026\n",
      "Epoch 33/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 34/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 35/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 36/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 37/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 38/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 39/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 40/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 41/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 42/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 43/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 44/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 45/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 46/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 47/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 48/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 49/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 50/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 51/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 52/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 53/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 54/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 55/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 56/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 57/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 58/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 59/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 60/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 61/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 62/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 63/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 64/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 65/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 66/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 67/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 68/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 69/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 70/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 71/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 72/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 73/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 74/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 75/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 76/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 77/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 78/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 79/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 80/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 81/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 82/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 83/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 84/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 85/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 86/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 87/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 88/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 89/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 90/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 91/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 92/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 93/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 94/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 95/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 96/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 97/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 98/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 99/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 100/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 101/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 102/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 103/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 104/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 105/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 106/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 107/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 108/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 109/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 110/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 111/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 112/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 113/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 114/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 115/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 116/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 117/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 118/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 119/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 120/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 121/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 122/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 123/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 124/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 125/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 126/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 127/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 128/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 129/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 130/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 131/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 132/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 133/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 134/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 135/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 136/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 137/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 138/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 139/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 140/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 141/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 142/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 143/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 144/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 145/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 146/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 147/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 148/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 149/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 150/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 151/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 152/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 153/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 154/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 155/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 156/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 157/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 158/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 159/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 160/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 161/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 162/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 163/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 164/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 165/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 166/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 167/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 168/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 169/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 170/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 171/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 172/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 173/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 174/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 175/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 176/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 177/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 178/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 179/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 180/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 181/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 182/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 183/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 00183: early stopping\n",
      "Epoch 1/10000\n",
      "151/151 [==============================] - 0s 3ms/step - loss: 0.0592 - val_loss: 0.0055\n",
      "Epoch 2/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0032\n",
      "Epoch 3/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0028\n",
      "Epoch 4/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0024\n",
      "Epoch 5/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0021\n",
      "Epoch 6/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0020\n",
      "Epoch 7/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0030\n",
      "Epoch 8/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0027\n",
      "Epoch 9/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0019\n",
      "Epoch 10/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0020\n",
      "Epoch 11/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0021\n",
      "Epoch 12/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 13/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0020\n",
      "Epoch 14/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0019\n",
      "Epoch 15/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0020\n",
      "Epoch 16/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0019\n",
      "Epoch 17/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0020\n",
      "Epoch 18/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0020\n",
      "Epoch 19/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 20/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0020\n",
      "Epoch 21/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0019\n",
      "Epoch 22/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0018\n",
      "Epoch 23/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0020\n",
      "Epoch 24/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 25/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 26/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 27/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 28/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0018\n",
      "Epoch 29/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 30/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 31/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 32/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 33/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 34/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 35/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 36/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 37/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 38/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 39/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 40/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 41/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 42/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 43/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 44/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 45/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 46/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 47/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 48/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 49/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 50/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 51/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 52/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 53/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 54/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 55/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 56/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 57/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 58/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 59/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 60/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 61/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 62/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 63/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 64/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 65/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 66/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 67/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 68/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 69/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0019\n",
      "Epoch 70/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 71/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 72/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 73/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 74/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 75/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 76/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 77/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 78/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 79/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 80/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 81/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 82/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 83/10000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 84/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 85/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 86/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 87/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 88/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 89/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 90/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 91/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 92/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 93/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 94/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 95/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 96/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 97/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 98/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 99/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 100/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 101/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 102/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 103/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 104/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 105/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 106/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 107/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 108/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 109/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 110/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 111/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 112/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 113/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 114/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 115/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 116/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 117/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 118/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 119/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 120/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 121/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 122/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 123/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 124/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 125/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 126/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 127/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 128/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 129/10000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 00129: early stopping\n",
      "Epoch 1/10000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.6037 - val_loss: 0.2536\n",
      "Epoch 2/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1891 - val_loss: 0.0541\n",
      "Epoch 3/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0981 - val_loss: 0.0352\n",
      "Epoch 4/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0864 - val_loss: 0.0363\n",
      "Epoch 5/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0828 - val_loss: 0.0327\n",
      "Epoch 6/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0774 - val_loss: 0.0325\n",
      "Epoch 7/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0739 - val_loss: 0.0324\n",
      "Epoch 8/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0711 - val_loss: 0.0317\n",
      "Epoch 9/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0671 - val_loss: 0.0320\n",
      "Epoch 10/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0648 - val_loss: 0.0335\n",
      "Epoch 11/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0628 - val_loss: 0.0328\n",
      "Epoch 12/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0601 - val_loss: 0.0322\n",
      "Epoch 13/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0318\n",
      "Epoch 14/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0557 - val_loss: 0.0306\n",
      "Epoch 15/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0537 - val_loss: 0.0304\n",
      "Epoch 16/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0518 - val_loss: 0.0301\n",
      "Epoch 17/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0505 - val_loss: 0.0304\n",
      "Epoch 18/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0497 - val_loss: 0.0293\n",
      "Epoch 19/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0468 - val_loss: 0.0286\n",
      "Epoch 20/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0464 - val_loss: 0.0281\n",
      "Epoch 21/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0441 - val_loss: 0.0272\n",
      "Epoch 22/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0421 - val_loss: 0.0249\n",
      "Epoch 23/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0413 - val_loss: 0.0236\n",
      "Epoch 24/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0393 - val_loss: 0.0223\n",
      "Epoch 25/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0380 - val_loss: 0.0224\n",
      "Epoch 26/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0362 - val_loss: 0.0197\n",
      "Epoch 27/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0344 - val_loss: 0.0194\n",
      "Epoch 28/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0344 - val_loss: 0.0186\n",
      "Epoch 29/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0334 - val_loss: 0.0182\n",
      "Epoch 30/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0320 - val_loss: 0.0184\n",
      "Epoch 31/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0324 - val_loss: 0.0179\n",
      "Epoch 32/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0308 - val_loss: 0.0178\n",
      "Epoch 33/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0314 - val_loss: 0.0176\n",
      "Epoch 34/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0303 - val_loss: 0.0181\n",
      "Epoch 35/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0301 - val_loss: 0.0182\n",
      "Epoch 36/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0302 - val_loss: 0.0184\n",
      "Epoch 37/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0289 - val_loss: 0.0175\n",
      "Epoch 38/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0282 - val_loss: 0.0175\n",
      "Epoch 39/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0286 - val_loss: 0.0177\n",
      "Epoch 40/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0282 - val_loss: 0.0170\n",
      "Epoch 41/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0284 - val_loss: 0.0172\n",
      "Epoch 42/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.0174\n",
      "Epoch 43/10000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.029 - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0174\n",
      "Epoch 44/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.0170\n",
      "Epoch 45/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0266 - val_loss: 0.0170\n",
      "Epoch 46/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0260 - val_loss: 0.0166\n",
      "Epoch 47/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0265 - val_loss: 0.0169\n",
      "Epoch 48/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0251 - val_loss: 0.0166\n",
      "Epoch 49/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.0168\n",
      "Epoch 50/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0245 - val_loss: 0.0166\n",
      "Epoch 51/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.0167\n",
      "Epoch 52/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.0165\n",
      "Epoch 53/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0244 - val_loss: 0.0163\n",
      "Epoch 54/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0246 - val_loss: 0.0169\n",
      "Epoch 55/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.0165\n",
      "Epoch 56/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0238 - val_loss: 0.0161\n",
      "Epoch 57/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0236 - val_loss: 0.0164\n",
      "Epoch 58/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0234 - val_loss: 0.0163\n",
      "Epoch 59/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0238 - val_loss: 0.0161\n",
      "Epoch 60/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.0169\n",
      "Epoch 61/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.0159\n",
      "Epoch 62/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0234 - val_loss: 0.0163\n",
      "Epoch 63/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0226 - val_loss: 0.0160\n",
      "Epoch 64/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.0165\n",
      "Epoch 65/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.0160\n",
      "Epoch 66/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.0161\n",
      "Epoch 67/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.0163\n",
      "Epoch 68/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0226 - val_loss: 0.0160\n",
      "Epoch 69/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0220 - val_loss: 0.0160\n",
      "Epoch 70/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.0159\n",
      "Epoch 71/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.0168\n",
      "Epoch 72/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.0160\n",
      "Epoch 73/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0220 - val_loss: 0.0158\n",
      "Epoch 74/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0159\n",
      "Epoch 75/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.0160\n",
      "Epoch 76/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0158\n",
      "Epoch 77/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.0158\n",
      "Epoch 78/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.0157\n",
      "Epoch 80/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0162\n",
      "Epoch 81/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.0164\n",
      "Epoch 82/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0159\n",
      "Epoch 83/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0157\n",
      "Epoch 84/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0159\n",
      "Epoch 85/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0159\n",
      "Epoch 86/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0156\n",
      "Epoch 87/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0157\n",
      "Epoch 88/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0156\n",
      "Epoch 89/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0156\n",
      "Epoch 90/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0159\n",
      "Epoch 91/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0156\n",
      "Epoch 92/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.0157\n",
      "Epoch 93/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.0157\n",
      "Epoch 94/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0159\n",
      "Epoch 95/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0156\n",
      "Epoch 96/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0155\n",
      "Epoch 97/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0161\n",
      "Epoch 98/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0157\n",
      "Epoch 99/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0158\n",
      "Epoch 100/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0158\n",
      "Epoch 101/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0158\n",
      "Epoch 102/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0156\n",
      "Epoch 103/10000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.021 - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0156\n",
      "Epoch 104/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0156\n",
      "Epoch 105/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0155\n",
      "Epoch 106/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0155\n",
      "Epoch 107/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0155\n",
      "Epoch 108/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0155\n",
      "Epoch 109/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0154\n",
      "Epoch 110/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0155\n",
      "Epoch 111/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0155\n",
      "Epoch 112/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0157\n",
      "Epoch 113/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0155\n",
      "Epoch 114/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0154\n",
      "Epoch 115/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0154\n",
      "Epoch 116/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0155\n",
      "Epoch 117/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0154\n",
      "Epoch 118/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0155\n",
      "Epoch 119/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0155\n",
      "Epoch 120/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0155\n",
      "Epoch 121/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0154\n",
      "Epoch 122/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0153\n",
      "Epoch 123/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0156\n",
      "Epoch 124/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0155\n",
      "Epoch 125/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0153\n",
      "Epoch 126/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0153\n",
      "Epoch 127/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0154\n",
      "Epoch 128/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0153\n",
      "Epoch 129/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0154\n",
      "Epoch 130/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0153\n",
      "Epoch 131/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0154\n",
      "Epoch 132/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0155\n",
      "Epoch 133/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0152\n",
      "Epoch 134/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0150\n",
      "Epoch 135/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0150\n",
      "Epoch 136/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0150\n",
      "Epoch 137/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0155\n",
      "Epoch 138/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0151\n",
      "Epoch 139/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0150\n",
      "Epoch 140/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0151\n",
      "Epoch 141/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0151\n",
      "Epoch 142/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0150\n",
      "Epoch 143/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0150\n",
      "Epoch 144/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0150\n",
      "Epoch 145/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0157\n",
      "Epoch 146/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0150\n",
      "Epoch 147/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0151\n",
      "Epoch 148/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0154\n",
      "Epoch 149/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0151\n",
      "Epoch 150/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0150\n",
      "Epoch 151/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0150\n",
      "Epoch 152/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0151\n",
      "Epoch 153/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0156\n",
      "Epoch 154/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0152\n",
      "Epoch 155/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0150\n",
      "Epoch 156/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0153\n",
      "Epoch 157/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0150\n",
      "Epoch 158/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0150\n",
      "Epoch 159/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0150\n",
      "Epoch 160/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0150\n",
      "Epoch 161/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0152\n",
      "Epoch 162/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0150\n",
      "Epoch 163/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0149\n",
      "Epoch 164/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0150\n",
      "Epoch 165/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0150\n",
      "Epoch 166/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0150\n",
      "Epoch 167/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0152\n",
      "Epoch 168/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0149\n",
      "Epoch 169/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0152\n",
      "Epoch 170/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0151\n",
      "Epoch 171/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0150\n",
      "Epoch 172/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0150\n",
      "Epoch 173/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0150\n",
      "Epoch 174/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0149\n",
      "Epoch 175/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0150\n",
      "Epoch 176/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0151\n",
      "Epoch 177/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0149\n",
      "Epoch 178/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0150\n",
      "Epoch 179/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0149\n",
      "Epoch 180/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0149\n",
      "Epoch 181/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0149\n",
      "Epoch 182/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0151\n",
      "Epoch 183/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0148\n",
      "Epoch 184/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0150\n",
      "Epoch 185/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0149\n",
      "Epoch 186/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0150\n",
      "Epoch 187/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0149\n",
      "Epoch 188/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0149\n",
      "Epoch 189/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0148\n",
      "Epoch 190/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0150\n",
      "Epoch 191/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0149\n",
      "Epoch 192/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0149\n",
      "Epoch 193/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0151\n",
      "Epoch 194/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0149\n",
      "Epoch 195/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0148\n",
      "Epoch 196/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0149\n",
      "Epoch 197/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0150\n",
      "Epoch 198/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0148\n",
      "Epoch 199/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0148\n",
      "Epoch 200/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0148\n",
      "Epoch 201/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0149\n",
      "Epoch 202/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0148\n",
      "Epoch 203/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0149\n",
      "Epoch 204/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0148\n",
      "Epoch 205/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0151\n",
      "Epoch 206/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0153\n",
      "Epoch 207/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0149\n",
      "Epoch 208/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0148\n",
      "Epoch 209/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0149\n",
      "Epoch 210/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0149\n",
      "Epoch 211/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0150\n",
      "Epoch 212/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0149\n",
      "Epoch 213/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0149\n",
      "Epoch 214/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0152\n",
      "Epoch 215/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0148\n",
      "Epoch 216/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0150\n",
      "Epoch 217/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0148\n",
      "Epoch 218/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0149\n",
      "Epoch 219/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0148\n",
      "Epoch 220/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0150\n",
      "Epoch 221/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0150\n",
      "Epoch 222/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0149\n",
      "Epoch 223/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0150\n",
      "Epoch 224/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0151\n",
      "Epoch 225/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0149\n",
      "Epoch 226/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0151\n",
      "Epoch 227/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0151\n",
      "Epoch 228/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0147\n",
      "Epoch 229/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0149\n",
      "Epoch 230/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0148\n",
      "Epoch 231/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0148\n",
      "Epoch 232/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0149\n",
      "Epoch 233/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0148\n",
      "Epoch 234/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0148\n",
      "Epoch 235/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0148\n",
      "Epoch 236/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0150\n",
      "Epoch 237/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0149\n",
      "Epoch 238/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0152\n",
      "Epoch 239/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0148\n",
      "Epoch 240/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0148\n",
      "Epoch 241/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0148\n",
      "Epoch 242/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0148\n",
      "Epoch 243/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0149\n",
      "Epoch 244/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0149\n",
      "Epoch 245/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0148\n",
      "Epoch 246/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0148\n",
      "Epoch 247/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0148\n",
      "Epoch 248/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0148\n",
      "Epoch 249/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0152\n",
      "Epoch 250/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0148\n",
      "Epoch 251/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0148\n",
      "Epoch 252/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 253/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0154\n",
      "Epoch 254/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0154\n",
      "Epoch 255/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0148\n",
      "Epoch 256/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0148\n",
      "Epoch 257/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0148\n",
      "Epoch 258/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0147\n",
      "Epoch 259/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0147\n",
      "Epoch 260/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0148\n",
      "Epoch 261/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0148\n",
      "Epoch 262/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 263/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0149\n",
      "Epoch 264/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0149\n",
      "Epoch 265/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0151\n",
      "Epoch 266/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0149\n",
      "Epoch 267/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0148\n",
      "Epoch 268/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0150\n",
      "Epoch 269/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0147\n",
      "Epoch 270/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0149\n",
      "Epoch 271/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0148\n",
      "Epoch 272/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0147\n",
      "Epoch 273/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0148\n",
      "Epoch 274/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 275/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0147\n",
      "Epoch 276/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0163\n",
      "Epoch 277/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0151\n",
      "Epoch 278/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0151\n",
      "Epoch 279/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0148\n",
      "Epoch 280/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0148\n",
      "Epoch 281/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0148\n",
      "Epoch 282/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0147\n",
      "Epoch 283/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0150\n",
      "Epoch 284/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0148\n",
      "Epoch 285/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0150\n",
      "Epoch 286/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0148\n",
      "Epoch 287/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0147\n",
      "Epoch 288/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0147\n",
      "Epoch 289/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 290/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0148\n",
      "Epoch 291/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0147\n",
      "Epoch 292/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0150\n",
      "Epoch 293/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0148\n",
      "Epoch 294/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 295/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0149\n",
      "Epoch 296/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0150\n",
      "Epoch 297/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0151\n",
      "Epoch 298/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0147\n",
      "Epoch 299/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0148\n",
      "Epoch 300/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 301/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 302/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0156\n",
      "Epoch 303/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0149\n",
      "Epoch 304/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0150\n",
      "Epoch 305/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0151\n",
      "Epoch 306/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0149\n",
      "Epoch 307/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0147\n",
      "Epoch 308/10000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.014 - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0149\n",
      "Epoch 309/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0147\n",
      "Epoch 310/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0153\n",
      "Epoch 311/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 312/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0148\n",
      "Epoch 313/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0147\n",
      "Epoch 314/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0152\n",
      "Epoch 315/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0148\n",
      "Epoch 316/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0149\n",
      "Epoch 317/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0148\n",
      "Epoch 318/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0148\n",
      "Epoch 319/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0148\n",
      "Epoch 320/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0150\n",
      "Epoch 321/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0148\n",
      "Epoch 322/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0154\n",
      "Epoch 323/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0150\n",
      "Epoch 324/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0148\n",
      "Epoch 325/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0149\n",
      "Epoch 326/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0150\n",
      "Epoch 327/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0148\n",
      "Epoch 328/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0148\n",
      "Epoch 329/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0153\n",
      "Epoch 330/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0150\n",
      "Epoch 331/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 332/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 333/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0148\n",
      "Epoch 334/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0149\n",
      "Epoch 335/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0152\n",
      "Epoch 336/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0148\n",
      "Epoch 337/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0147\n",
      "Epoch 338/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 339/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0149\n",
      "Epoch 340/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 341/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0149\n",
      "Epoch 342/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0151\n",
      "Epoch 343/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0150\n",
      "Epoch 344/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0148\n",
      "Epoch 345/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0148\n",
      "Epoch 346/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 347/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0151\n",
      "Epoch 348/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0153\n",
      "Epoch 349/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0148\n",
      "Epoch 350/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 351/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0153\n",
      "Epoch 352/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0157\n",
      "Epoch 353/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0152\n",
      "Epoch 354/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0149\n",
      "Epoch 355/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 356/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0154\n",
      "Epoch 357/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0152\n",
      "Epoch 358/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0147\n",
      "Epoch 359/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 360/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0148\n",
      "Epoch 361/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0152\n",
      "Epoch 362/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0148\n",
      "Epoch 363/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0151\n",
      "Epoch 364/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0147\n",
      "Epoch 365/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 366/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0147\n",
      "Epoch 367/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 368/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0149\n",
      "Epoch 369/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0150\n",
      "Epoch 370/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0151\n",
      "Epoch 371/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0147\n",
      "Epoch 372/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 373/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0150\n",
      "Epoch 374/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 375/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0147\n",
      "Epoch 376/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0149\n",
      "Epoch 377/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0148\n",
      "Epoch 378/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0149\n",
      "Epoch 379/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 380/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0148\n",
      "Epoch 381/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 382/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0148\n",
      "Epoch 383/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 384/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0149\n",
      "Epoch 385/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0150\n",
      "Epoch 386/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 387/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 388/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0147\n",
      "Epoch 389/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0147\n",
      "Epoch 390/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0149\n",
      "Epoch 391/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0147\n",
      "Epoch 392/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0146\n",
      "Epoch 393/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 394/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0149\n",
      "Epoch 395/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0149\n",
      "Epoch 396/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0148\n",
      "Epoch 397/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 398/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 399/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0149\n",
      "Epoch 400/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 401/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0148\n",
      "Epoch 402/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0149\n",
      "Epoch 403/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 404/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0157\n",
      "Epoch 405/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0150\n",
      "Epoch 406/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0151\n",
      "Epoch 407/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0149\n",
      "Epoch 408/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 409/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0150\n",
      "Epoch 410/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0152\n",
      "Epoch 411/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0148\n",
      "Epoch 412/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0152\n",
      "Epoch 413/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 414/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0153\n",
      "Epoch 415/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0147\n",
      "Epoch 416/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0149\n",
      "Epoch 417/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0148\n",
      "Epoch 418/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0150\n",
      "Epoch 419/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 420/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 421/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0152\n",
      "Epoch 422/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0148\n",
      "Epoch 423/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0148\n",
      "Epoch 424/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0150\n",
      "Epoch 425/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 426/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0151\n",
      "Epoch 427/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0149\n",
      "Epoch 428/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 429/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 430/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 431/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 432/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0149\n",
      "Epoch 433/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0146\n",
      "Epoch 434/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0154\n",
      "Epoch 435/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0146\n",
      "Epoch 436/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0150\n",
      "Epoch 437/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0151\n",
      "Epoch 438/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 439/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0146\n",
      "Epoch 440/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0146\n",
      "Epoch 441/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0146\n",
      "Epoch 442/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0148\n",
      "Epoch 443/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0146\n",
      "Epoch 444/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0147\n",
      "Epoch 445/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 446/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0146\n",
      "Epoch 447/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 448/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0147\n",
      "Epoch 449/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0146\n",
      "Epoch 450/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0147\n",
      "Epoch 451/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0145\n",
      "Epoch 452/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0146\n",
      "Epoch 453/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0146\n",
      "Epoch 454/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 455/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0149\n",
      "Epoch 456/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 457/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0146\n",
      "Epoch 458/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0149\n",
      "Epoch 459/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 460/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0148\n",
      "Epoch 461/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0148\n",
      "Epoch 462/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0152\n",
      "Epoch 463/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0152\n",
      "Epoch 464/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0149\n",
      "Epoch 465/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0146\n",
      "Epoch 466/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0149\n",
      "Epoch 467/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0148\n",
      "Epoch 468/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0147\n",
      "Epoch 469/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 470/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 471/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0146\n",
      "Epoch 472/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0148\n",
      "Epoch 473/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 474/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 475/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0156\n",
      "Epoch 476/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0147\n",
      "Epoch 477/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0148\n",
      "Epoch 478/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0146\n",
      "Epoch 479/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 480/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0150\n",
      "Epoch 481/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0146\n",
      "Epoch 482/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0146\n",
      "Epoch 483/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0151\n",
      "Epoch 484/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 485/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0148\n",
      "Epoch 486/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 487/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0149\n",
      "Epoch 488/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 489/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 490/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 491/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0146\n",
      "Epoch 492/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0146\n",
      "Epoch 493/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 494/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0146\n",
      "Epoch 495/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0150\n",
      "Epoch 496/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0146\n",
      "Epoch 497/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 498/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0148\n",
      "Epoch 499/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0147\n",
      "Epoch 500/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0151\n",
      "Epoch 501/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 502/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 503/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0146\n",
      "Epoch 504/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0151\n",
      "Epoch 505/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0147\n",
      "Epoch 506/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 507/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0150\n",
      "Epoch 508/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0147\n",
      "Epoch 509/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0160\n",
      "Epoch 510/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0151\n",
      "Epoch 511/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0148\n",
      "Epoch 512/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 513/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 514/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 515/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0148\n",
      "Epoch 516/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0146\n",
      "Epoch 517/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0146\n",
      "Epoch 518/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 519/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 520/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0146\n",
      "Epoch 521/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0146\n",
      "Epoch 522/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0149\n",
      "Epoch 523/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0146\n",
      "Epoch 524/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0146\n",
      "Epoch 525/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0151\n",
      "Epoch 526/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0154\n",
      "Epoch 527/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0151\n",
      "Epoch 528/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0145\n",
      "Epoch 529/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0146\n",
      "Epoch 530/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0149\n",
      "Epoch 531/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 532/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 533/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0150\n",
      "Epoch 534/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0149\n",
      "Epoch 535/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 536/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 537/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0148\n",
      "Epoch 538/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0150\n",
      "Epoch 539/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0147\n",
      "Epoch 540/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0145\n",
      "Epoch 541/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0149\n",
      "Epoch 542/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 543/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0146\n",
      "Epoch 544/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0154\n",
      "Epoch 545/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0147\n",
      "Epoch 546/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0148\n",
      "Epoch 547/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0146\n",
      "Epoch 548/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0146\n",
      "Epoch 549/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0146\n",
      "Epoch 550/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 551/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0148\n",
      "Epoch 00551: early stopping\n",
      "Epoch 1/10000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.6982 - val_loss: 0.3485\n",
      "Epoch 2/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2302 - val_loss: 0.0634\n",
      "Epoch 3/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1010 - val_loss: 0.0382\n",
      "Epoch 4/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0882 - val_loss: 0.0339\n",
      "Epoch 5/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0816 - val_loss: 0.0339\n",
      "Epoch 6/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0777 - val_loss: 0.0333\n",
      "Epoch 7/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0740 - val_loss: 0.0322\n",
      "Epoch 8/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0711 - val_loss: 0.0333\n",
      "Epoch 9/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0677 - val_loss: 0.0316\n",
      "Epoch 10/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0650 - val_loss: 0.0317\n",
      "Epoch 11/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0611 - val_loss: 0.0300\n",
      "Epoch 12/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0290\n",
      "Epoch 13/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0567 - val_loss: 0.0265\n",
      "Epoch 14/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.0238\n",
      "Epoch 15/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.0215\n",
      "Epoch 16/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0459 - val_loss: 0.0214\n",
      "Epoch 17/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0444 - val_loss: 0.0214\n",
      "Epoch 18/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0414 - val_loss: 0.0200\n",
      "Epoch 19/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0396 - val_loss: 0.0173\n",
      "Epoch 20/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0378 - val_loss: 0.0181\n",
      "Epoch 21/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0366 - val_loss: 0.0176\n",
      "Epoch 22/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0350 - val_loss: 0.0170\n",
      "Epoch 23/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0352 - val_loss: 0.0170\n",
      "Epoch 24/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0339 - val_loss: 0.0175\n",
      "Epoch 25/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0331 - val_loss: 0.0170\n",
      "Epoch 26/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0338 - val_loss: 0.0167\n",
      "Epoch 27/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0312 - val_loss: 0.0168\n",
      "Epoch 28/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0306 - val_loss: 0.0172\n",
      "Epoch 29/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0304 - val_loss: 0.0169\n",
      "Epoch 30/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0299 - val_loss: 0.0172\n",
      "Epoch 31/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0294 - val_loss: 0.0170\n",
      "Epoch 32/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0294 - val_loss: 0.0173\n",
      "Epoch 33/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0284 - val_loss: 0.0168\n",
      "Epoch 34/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0282 - val_loss: 0.0167\n",
      "Epoch 35/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.0166\n",
      "Epoch 36/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0163\n",
      "Epoch 37/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.0164\n",
      "Epoch 38/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0274 - val_loss: 0.0168\n",
      "Epoch 39/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0268 - val_loss: 0.0165\n",
      "Epoch 40/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.0162\n",
      "Epoch 41/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.0164\n",
      "Epoch 42/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.0163\n",
      "Epoch 43/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0260 - val_loss: 0.0163\n",
      "Epoch 44/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.0163\n",
      "Epoch 45/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.0168\n",
      "Epoch 46/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0261 - val_loss: 0.0164\n",
      "Epoch 47/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.0161\n",
      "Epoch 48/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.0163\n",
      "Epoch 49/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0252 - val_loss: 0.0163\n",
      "Epoch 50/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.0165\n",
      "Epoch 51/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.0165\n",
      "Epoch 52/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0250 - val_loss: 0.0175\n",
      "Epoch 53/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0244 - val_loss: 0.0166\n",
      "Epoch 54/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.0160\n",
      "Epoch 55/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.0161\n",
      "Epoch 56/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.0163\n",
      "Epoch 57/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.0171\n",
      "Epoch 58/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0246 - val_loss: 0.0160\n",
      "Epoch 59/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0238 - val_loss: 0.0161\n",
      "Epoch 60/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.0162\n",
      "Epoch 61/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.0163\n",
      "Epoch 62/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.0161\n",
      "Epoch 63/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0236 - val_loss: 0.0163\n",
      "Epoch 64/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.0161\n",
      "Epoch 65/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.0162\n",
      "Epoch 66/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0226 - val_loss: 0.0159\n",
      "Epoch 67/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.0160\n",
      "Epoch 68/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.0180\n",
      "Epoch 69/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.0166\n",
      "Epoch 70/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.0163\n",
      "Epoch 71/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0160\n",
      "Epoch 72/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.0159\n",
      "Epoch 73/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0220 - val_loss: 0.0167\n",
      "Epoch 74/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0226 - val_loss: 0.0163\n",
      "Epoch 75/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.0161\n",
      "Epoch 76/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.0161\n",
      "Epoch 77/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0219 - val_loss: 0.0163\n",
      "Epoch 78/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0166\n",
      "Epoch 79/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.0159\n",
      "Epoch 80/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0215 - val_loss: 0.0161\n",
      "Epoch 81/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.0158\n",
      "Epoch 82/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.0158\n",
      "Epoch 83/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.0157\n",
      "Epoch 84/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.0158\n",
      "Epoch 85/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0158\n",
      "Epoch 86/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.0157\n",
      "Epoch 87/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0156\n",
      "Epoch 88/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0159\n",
      "Epoch 89/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0160\n",
      "Epoch 90/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.0158\n",
      "Epoch 91/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0156\n",
      "Epoch 92/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.0157\n",
      "Epoch 93/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0157\n",
      "Epoch 94/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.0156\n",
      "Epoch 95/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0157\n",
      "Epoch 96/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0165\n",
      "Epoch 97/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0157\n",
      "Epoch 98/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.0157\n",
      "Epoch 99/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0157\n",
      "Epoch 100/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0164\n",
      "Epoch 101/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0155\n",
      "Epoch 102/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0155\n",
      "Epoch 103/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0156\n",
      "Epoch 104/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0157\n",
      "Epoch 105/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0156\n",
      "Epoch 106/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0159\n",
      "Epoch 107/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0154\n",
      "Epoch 108/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0161\n",
      "Epoch 109/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0155\n",
      "Epoch 110/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0157\n",
      "Epoch 111/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0155\n",
      "Epoch 112/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0155\n",
      "Epoch 113/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0160\n",
      "Epoch 114/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0156\n",
      "Epoch 115/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0157\n",
      "Epoch 116/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0156\n",
      "Epoch 117/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0157\n",
      "Epoch 118/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0154\n",
      "Epoch 119/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0158\n",
      "Epoch 120/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0156\n",
      "Epoch 121/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0159\n",
      "Epoch 122/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0152\n",
      "Epoch 123/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0157\n",
      "Epoch 124/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0157\n",
      "Epoch 125/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0153\n",
      "Epoch 126/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0154\n",
      "Epoch 127/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0154\n",
      "Epoch 128/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0153\n",
      "Epoch 129/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0153\n",
      "Epoch 130/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0154\n",
      "Epoch 131/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0154\n",
      "Epoch 132/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0152\n",
      "Epoch 133/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0155\n",
      "Epoch 134/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0153\n",
      "Epoch 135/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0154\n",
      "Epoch 136/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0152\n",
      "Epoch 137/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0153\n",
      "Epoch 138/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0154\n",
      "Epoch 139/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0155\n",
      "Epoch 140/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0151\n",
      "Epoch 141/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0152\n",
      "Epoch 142/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0152\n",
      "Epoch 143/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0150\n",
      "Epoch 144/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0150\n",
      "Epoch 145/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0151\n",
      "Epoch 146/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0151\n",
      "Epoch 147/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0149\n",
      "Epoch 148/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0149\n",
      "Epoch 149/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0150\n",
      "Epoch 150/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0148\n",
      "Epoch 151/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0146\n",
      "Epoch 152/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0143\n",
      "Epoch 153/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0145\n",
      "Epoch 154/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0142\n",
      "Epoch 155/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0141\n",
      "Epoch 156/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0148\n",
      "Epoch 157/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0138\n",
      "Epoch 158/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0135\n",
      "Epoch 159/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0136\n",
      "Epoch 160/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0135\n",
      "Epoch 161/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0131\n",
      "Epoch 163/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0131\n",
      "Epoch 164/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0128\n",
      "Epoch 165/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0128\n",
      "Epoch 166/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0128\n",
      "Epoch 167/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0127\n",
      "Epoch 168/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0132\n",
      "Epoch 169/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0126\n",
      "Epoch 170/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0126\n",
      "Epoch 171/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0127\n",
      "Epoch 172/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0125\n",
      "Epoch 173/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0124\n",
      "Epoch 174/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0127\n",
      "Epoch 175/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0124\n",
      "Epoch 176/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0126\n",
      "Epoch 177/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0124\n",
      "Epoch 178/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0132\n",
      "Epoch 179/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0124\n",
      "Epoch 180/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0128\n",
      "Epoch 181/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0126\n",
      "Epoch 182/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0124\n",
      "Epoch 183/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0123\n",
      "Epoch 184/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0130\n",
      "Epoch 185/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0123\n",
      "Epoch 186/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0124\n",
      "Epoch 187/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0122\n",
      "Epoch 188/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0122\n",
      "Epoch 189/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0129\n",
      "Epoch 190/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0129\n",
      "Epoch 191/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0125\n",
      "Epoch 192/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0123\n",
      "Epoch 193/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0122\n",
      "Epoch 194/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0128\n",
      "Epoch 195/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0123\n",
      "Epoch 196/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0133\n",
      "Epoch 197/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0129\n",
      "Epoch 198/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0122\n",
      "Epoch 199/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0121\n",
      "Epoch 200/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0127\n",
      "Epoch 201/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0123\n",
      "Epoch 202/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0122\n",
      "Epoch 203/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0124\n",
      "Epoch 204/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0125\n",
      "Epoch 205/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0123\n",
      "Epoch 206/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0122\n",
      "Epoch 207/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0124\n",
      "Epoch 208/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 209/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0122\n",
      "Epoch 210/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0121\n",
      "Epoch 211/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0130\n",
      "Epoch 212/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0130\n",
      "Epoch 213/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0122\n",
      "Epoch 214/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0123\n",
      "Epoch 215/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0122\n",
      "Epoch 216/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0122\n",
      "Epoch 217/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0127\n",
      "Epoch 218/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0124\n",
      "Epoch 219/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0121\n",
      "Epoch 220/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0124\n",
      "Epoch 221/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0124\n",
      "Epoch 222/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0126\n",
      "Epoch 223/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0123\n",
      "Epoch 224/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0121\n",
      "Epoch 225/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0121\n",
      "Epoch 226/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0126\n",
      "Epoch 227/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0123\n",
      "Epoch 228/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0122\n",
      "Epoch 229/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0121\n",
      "Epoch 230/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0121\n",
      "Epoch 231/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0121\n",
      "Epoch 232/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0120\n",
      "Epoch 233/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0119\n",
      "Epoch 234/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0124\n",
      "Epoch 235/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0120\n",
      "Epoch 236/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0123\n",
      "Epoch 237/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0123\n",
      "Epoch 238/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0120\n",
      "Epoch 239/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0121\n",
      "Epoch 240/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0121\n",
      "Epoch 241/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0130\n",
      "Epoch 242/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0122\n",
      "Epoch 243/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0125\n",
      "Epoch 244/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0128\n",
      "Epoch 245/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0123\n",
      "Epoch 246/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0122\n",
      "Epoch 247/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0121\n",
      "Epoch 248/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0120\n",
      "Epoch 249/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0121\n",
      "Epoch 250/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0120\n",
      "Epoch 251/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0119\n",
      "Epoch 252/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0122\n",
      "Epoch 253/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 254/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0120\n",
      "Epoch 255/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0132\n",
      "Epoch 256/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0120\n",
      "Epoch 257/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0119\n",
      "Epoch 258/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0121\n",
      "Epoch 259/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0121\n",
      "Epoch 260/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0122\n",
      "Epoch 261/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0119\n",
      "Epoch 262/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0120\n",
      "Epoch 263/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0118\n",
      "Epoch 264/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0133\n",
      "Epoch 265/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0121\n",
      "Epoch 266/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0123\n",
      "Epoch 267/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0119\n",
      "Epoch 268/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0119\n",
      "Epoch 269/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0120\n",
      "Epoch 270/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0124\n",
      "Epoch 271/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0119\n",
      "Epoch 272/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0121\n",
      "Epoch 273/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0119\n",
      "Epoch 274/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0129\n",
      "Epoch 275/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0119\n",
      "Epoch 276/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0120\n",
      "Epoch 277/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0119\n",
      "Epoch 278/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0117\n",
      "Epoch 279/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0128\n",
      "Epoch 280/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0119\n",
      "Epoch 281/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0119\n",
      "Epoch 282/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0119\n",
      "Epoch 283/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0118\n",
      "Epoch 284/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0121\n",
      "Epoch 285/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0120\n",
      "Epoch 286/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0124\n",
      "Epoch 287/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0115\n",
      "Epoch 288/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0115\n",
      "Epoch 289/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0116\n",
      "Epoch 290/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0121\n",
      "Epoch 291/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0119\n",
      "Epoch 292/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0118\n",
      "Epoch 293/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0116\n",
      "Epoch 294/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0118\n",
      "Epoch 295/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0117\n",
      "Epoch 296/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0116\n",
      "Epoch 297/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0117\n",
      "Epoch 298/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0116\n",
      "Epoch 299/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0117\n",
      "Epoch 300/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0120\n",
      "Epoch 301/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0119\n",
      "Epoch 302/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0115\n",
      "Epoch 303/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0116\n",
      "Epoch 304/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0121\n",
      "Epoch 305/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0119\n",
      "Epoch 306/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0117\n",
      "Epoch 307/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0117\n",
      "Epoch 308/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0116\n",
      "Epoch 309/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0118\n",
      "Epoch 310/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0118\n",
      "Epoch 311/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0117\n",
      "Epoch 312/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0116\n",
      "Epoch 313/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0118\n",
      "Epoch 314/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0115\n",
      "Epoch 315/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0114\n",
      "Epoch 316/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0115\n",
      "Epoch 317/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0121\n",
      "Epoch 318/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0119\n",
      "Epoch 319/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0135\n",
      "Epoch 320/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0121\n",
      "Epoch 321/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0118\n",
      "Epoch 322/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0118\n",
      "Epoch 323/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0116\n",
      "Epoch 324/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0118\n",
      "Epoch 325/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0115\n",
      "Epoch 326/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0115\n",
      "Epoch 327/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0116\n",
      "Epoch 328/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0114\n",
      "Epoch 329/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0119\n",
      "Epoch 330/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0115\n",
      "Epoch 331/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0127\n",
      "Epoch 332/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0119\n",
      "Epoch 333/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0123\n",
      "Epoch 334/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0116\n",
      "Epoch 335/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0114\n",
      "Epoch 336/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0116\n",
      "Epoch 337/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0114\n",
      "Epoch 338/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0116\n",
      "Epoch 339/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0114\n",
      "Epoch 340/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0121\n",
      "Epoch 341/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0115\n",
      "Epoch 342/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0115\n",
      "Epoch 343/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0123\n",
      "Epoch 344/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0115\n",
      "Epoch 345/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0116\n",
      "Epoch 346/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0117\n",
      "Epoch 347/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0119\n",
      "Epoch 348/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0115\n",
      "Epoch 349/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0115\n",
      "Epoch 350/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0118\n",
      "Epoch 351/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0118\n",
      "Epoch 352/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0121\n",
      "Epoch 353/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0113\n",
      "Epoch 354/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0114\n",
      "Epoch 355/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0117\n",
      "Epoch 356/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0117\n",
      "Epoch 357/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0126\n",
      "Epoch 358/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0121\n",
      "Epoch 359/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0115\n",
      "Epoch 360/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0115\n",
      "Epoch 361/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0117\n",
      "Epoch 362/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0113\n",
      "Epoch 363/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0113\n",
      "Epoch 364/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0115\n",
      "Epoch 365/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0116\n",
      "Epoch 366/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0114\n",
      "Epoch 367/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0113\n",
      "Epoch 368/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0113\n",
      "Epoch 369/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0115\n",
      "Epoch 370/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0114\n",
      "Epoch 371/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0114\n",
      "Epoch 372/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0115\n",
      "Epoch 373/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0113\n",
      "Epoch 374/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0113\n",
      "Epoch 375/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0116\n",
      "Epoch 376/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0114\n",
      "Epoch 377/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0114\n",
      "Epoch 378/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0116\n",
      "Epoch 379/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0114\n",
      "Epoch 380/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0112\n",
      "Epoch 381/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0121\n",
      "Epoch 382/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0112\n",
      "Epoch 383/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0125\n",
      "Epoch 384/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0113\n",
      "Epoch 385/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0113\n",
      "Epoch 386/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0116\n",
      "Epoch 387/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0113\n",
      "Epoch 388/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0119\n",
      "Epoch 389/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0117\n",
      "Epoch 390/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0110\n",
      "Epoch 391/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0112\n",
      "Epoch 392/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0114\n",
      "Epoch 393/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0113\n",
      "Epoch 394/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0112\n",
      "Epoch 395/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0118\n",
      "Epoch 396/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0122\n",
      "Epoch 397/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0114\n",
      "Epoch 398/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0115\n",
      "Epoch 399/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0113\n",
      "Epoch 400/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0112\n",
      "Epoch 401/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0112\n",
      "Epoch 402/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0112\n",
      "Epoch 403/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0111\n",
      "Epoch 404/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0113\n",
      "Epoch 405/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0111\n",
      "Epoch 406/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0111\n",
      "Epoch 407/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0126\n",
      "Epoch 408/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0126\n",
      "Epoch 409/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0114\n",
      "Epoch 410/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0114\n",
      "Epoch 411/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0112\n",
      "Epoch 412/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0113\n",
      "Epoch 413/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0118\n",
      "Epoch 414/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0113\n",
      "Epoch 415/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0112\n",
      "Epoch 416/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0111\n",
      "Epoch 417/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0113\n",
      "Epoch 418/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0111\n",
      "Epoch 419/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0112\n",
      "Epoch 420/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0112\n",
      "Epoch 421/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0110\n",
      "Epoch 422/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0111\n",
      "Epoch 423/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0110\n",
      "Epoch 424/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0111\n",
      "Epoch 425/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0119\n",
      "Epoch 426/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0120\n",
      "Epoch 427/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0111\n",
      "Epoch 428/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0113\n",
      "Epoch 429/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0113\n",
      "Epoch 430/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0114\n",
      "Epoch 431/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 432/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0118\n",
      "Epoch 433/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0116\n",
      "Epoch 434/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0112\n",
      "Epoch 435/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0112\n",
      "Epoch 436/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0110\n",
      "Epoch 437/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0111\n",
      "Epoch 438/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0112\n",
      "Epoch 439/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0110\n",
      "Epoch 440/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0112\n",
      "Epoch 441/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 442/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0109\n",
      "Epoch 443/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0123\n",
      "Epoch 444/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0112\n",
      "Epoch 445/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0116\n",
      "Epoch 446/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0114\n",
      "Epoch 447/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0111\n",
      "Epoch 448/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0110\n",
      "Epoch 449/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0110\n",
      "Epoch 450/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0112\n",
      "Epoch 451/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0110\n",
      "Epoch 452/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0120\n",
      "Epoch 453/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0117\n",
      "Epoch 454/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0111\n",
      "Epoch 455/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0114\n",
      "Epoch 456/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0113\n",
      "Epoch 457/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0112\n",
      "Epoch 458/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0111\n",
      "Epoch 459/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0111\n",
      "Epoch 460/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0112\n",
      "Epoch 461/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0113\n",
      "Epoch 462/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0112\n",
      "Epoch 463/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0113\n",
      "Epoch 464/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0109\n",
      "Epoch 465/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0120\n",
      "Epoch 466/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0117\n",
      "Epoch 467/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0110\n",
      "Epoch 468/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0110\n",
      "Epoch 469/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0122\n",
      "Epoch 470/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0111\n",
      "Epoch 471/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0114\n",
      "Epoch 472/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0115\n",
      "Epoch 473/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0116\n",
      "Epoch 474/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0112\n",
      "Epoch 475/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0109\n",
      "Epoch 476/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0111\n",
      "Epoch 477/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0115\n",
      "Epoch 478/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0114\n",
      "Epoch 479/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0111\n",
      "Epoch 480/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0122\n",
      "Epoch 481/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0109\n",
      "Epoch 482/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0110\n",
      "Epoch 483/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0111\n",
      "Epoch 484/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0110\n",
      "Epoch 485/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 486/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0109\n",
      "Epoch 487/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0109\n",
      "Epoch 488/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0110\n",
      "Epoch 489/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0114\n",
      "Epoch 490/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0112\n",
      "Epoch 491/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0111\n",
      "Epoch 492/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0109\n",
      "Epoch 493/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0108\n",
      "Epoch 494/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0111\n",
      "Epoch 495/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 496/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0108\n",
      "Epoch 497/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0111\n",
      "Epoch 498/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0109\n",
      "Epoch 499/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0115\n",
      "Epoch 500/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0109\n",
      "Epoch 501/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0109\n",
      "Epoch 502/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0109\n",
      "Epoch 503/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0111\n",
      "Epoch 504/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0108\n",
      "Epoch 505/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0110\n",
      "Epoch 506/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0108\n",
      "Epoch 507/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0114\n",
      "Epoch 508/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0111\n",
      "Epoch 509/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0109\n",
      "Epoch 510/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0110\n",
      "Epoch 511/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0109\n",
      "Epoch 512/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0112\n",
      "Epoch 513/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0108\n",
      "Epoch 514/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0109\n",
      "Epoch 515/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0108\n",
      "Epoch 516/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0114\n",
      "Epoch 517/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0111\n",
      "Epoch 518/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0109\n",
      "Epoch 519/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0107\n",
      "Epoch 520/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0112\n",
      "Epoch 521/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0115\n",
      "Epoch 522/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0109\n",
      "Epoch 523/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0108\n",
      "Epoch 524/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0111\n",
      "Epoch 525/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0122\n",
      "Epoch 526/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0113\n",
      "Epoch 527/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0114\n",
      "Epoch 528/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0108\n",
      "Epoch 529/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0108\n",
      "Epoch 530/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0109\n",
      "Epoch 531/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0107\n",
      "Epoch 532/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0112\n",
      "Epoch 533/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0108\n",
      "Epoch 534/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0109\n",
      "Epoch 535/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0108\n",
      "Epoch 536/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0108\n",
      "Epoch 537/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0107\n",
      "Epoch 538/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0111\n",
      "Epoch 539/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0112\n",
      "Epoch 540/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0108\n",
      "Epoch 541/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0109\n",
      "Epoch 542/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0107\n",
      "Epoch 543/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0108\n",
      "Epoch 544/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0108\n",
      "Epoch 545/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0108\n",
      "Epoch 546/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0108\n",
      "Epoch 547/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0109\n",
      "Epoch 548/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0111\n",
      "Epoch 549/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0109\n",
      "Epoch 550/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0108\n",
      "Epoch 551/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0108\n",
      "Epoch 552/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0110\n",
      "Epoch 553/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0106\n",
      "Epoch 554/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0114\n",
      "Epoch 555/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0109\n",
      "Epoch 556/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0113\n",
      "Epoch 557/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0111\n",
      "Epoch 558/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 559/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0109\n",
      "Epoch 560/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0108\n",
      "Epoch 561/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0110\n",
      "Epoch 562/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0106\n",
      "Epoch 563/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0107\n",
      "Epoch 564/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 565/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0109\n",
      "Epoch 566/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0106\n",
      "Epoch 567/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0106\n",
      "Epoch 568/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0106\n",
      "Epoch 569/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0107\n",
      "Epoch 570/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0106\n",
      "Epoch 571/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0116\n",
      "Epoch 572/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0112\n",
      "Epoch 573/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0115\n",
      "Epoch 574/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0114\n",
      "Epoch 575/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0121\n",
      "Epoch 576/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0109\n",
      "Epoch 577/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0112\n",
      "Epoch 578/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0111\n",
      "Epoch 579/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0109\n",
      "Epoch 580/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0111\n",
      "Epoch 581/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 582/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0107\n",
      "Epoch 583/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0106\n",
      "Epoch 584/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 585/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0106\n",
      "Epoch 586/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0107\n",
      "Epoch 587/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0107\n",
      "Epoch 588/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0108\n",
      "Epoch 589/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0106\n",
      "Epoch 590/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0109\n",
      "Epoch 591/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0111\n",
      "Epoch 592/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0111\n",
      "Epoch 593/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 594/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0106\n",
      "Epoch 595/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0107\n",
      "Epoch 596/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0106\n",
      "Epoch 597/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0109\n",
      "Epoch 598/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0108\n",
      "Epoch 599/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0106\n",
      "Epoch 600/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 601/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0107\n",
      "Epoch 602/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0107\n",
      "Epoch 603/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0108\n",
      "Epoch 604/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0110\n",
      "Epoch 605/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 606/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 607/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0109\n",
      "Epoch 608/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0109\n",
      "Epoch 609/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0113\n",
      "Epoch 610/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0106\n",
      "Epoch 611/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0109\n",
      "Epoch 612/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 613/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0104\n",
      "Epoch 614/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0110\n",
      "Epoch 615/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0106\n",
      "Epoch 616/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 617/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0107\n",
      "Epoch 618/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0117\n",
      "Epoch 619/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0109\n",
      "Epoch 620/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0107\n",
      "Epoch 621/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0109\n",
      "Epoch 622/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0107\n",
      "Epoch 623/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 624/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0106\n",
      "Epoch 625/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0107\n",
      "Epoch 626/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0108\n",
      "Epoch 627/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0107\n",
      "Epoch 628/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0105\n",
      "Epoch 629/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 630/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 631/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0111\n",
      "Epoch 632/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0110\n",
      "Epoch 633/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0109\n",
      "Epoch 634/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0113\n",
      "Epoch 635/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0109\n",
      "Epoch 636/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0107\n",
      "Epoch 637/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 638/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0106\n",
      "Epoch 639/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0107\n",
      "Epoch 640/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0111\n",
      "Epoch 641/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0114\n",
      "Epoch 642/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0105\n",
      "Epoch 643/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0109\n",
      "Epoch 644/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0108\n",
      "Epoch 645/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 646/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0109\n",
      "Epoch 647/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0108\n",
      "Epoch 648/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0107\n",
      "Epoch 649/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0106\n",
      "Epoch 650/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0107\n",
      "Epoch 651/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0106\n",
      "Epoch 652/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0107\n",
      "Epoch 653/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0111\n",
      "Epoch 654/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0107\n",
      "Epoch 655/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0112\n",
      "Epoch 656/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0107\n",
      "Epoch 657/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0107\n",
      "Epoch 658/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0108\n",
      "Epoch 659/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0106\n",
      "Epoch 660/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0108\n",
      "Epoch 661/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 662/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 663/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0108\n",
      "Epoch 664/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0109\n",
      "Epoch 665/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 666/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0104\n",
      "Epoch 667/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 668/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0108\n",
      "Epoch 669/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0107\n",
      "Epoch 670/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0106\n",
      "Epoch 671/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 672/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0108\n",
      "Epoch 673/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0106\n",
      "Epoch 674/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0109\n",
      "Epoch 675/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 676/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0104\n",
      "Epoch 677/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0104\n",
      "Epoch 678/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0110\n",
      "Epoch 679/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0106\n",
      "Epoch 680/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0108\n",
      "Epoch 681/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 682/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0105\n",
      "Epoch 683/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0106\n",
      "Epoch 684/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0106\n",
      "Epoch 685/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0107\n",
      "Epoch 686/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 687/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 688/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 689/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0106\n",
      "Epoch 690/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0106\n",
      "Epoch 691/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0111\n",
      "Epoch 692/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0105\n",
      "Epoch 693/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0110\n",
      "Epoch 694/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 695/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0111\n",
      "Epoch 696/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0106\n",
      "Epoch 697/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0107\n",
      "Epoch 698/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 699/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0106\n",
      "Epoch 700/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0108\n",
      "Epoch 701/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 702/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0111\n",
      "Epoch 703/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0109\n",
      "Epoch 704/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 705/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 706/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0108\n",
      "Epoch 707/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0108\n",
      "Epoch 708/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 709/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0107\n",
      "Epoch 710/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0111\n",
      "Epoch 711/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 712/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0114\n",
      "Epoch 713/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0108\n",
      "Epoch 714/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0106\n",
      "Epoch 715/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 716/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 717/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 718/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0112\n",
      "Epoch 719/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0109\n",
      "Epoch 720/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0108\n",
      "Epoch 721/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 722/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0106\n",
      "Epoch 723/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0107\n",
      "Epoch 724/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0109\n",
      "Epoch 725/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0104\n",
      "Epoch 726/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 727/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 728/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0107\n",
      "Epoch 729/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0107\n",
      "Epoch 730/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 731/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0107\n",
      "Epoch 732/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0112\n",
      "Epoch 733/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0104\n",
      "Epoch 734/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0112\n",
      "Epoch 735/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 736/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0106\n",
      "Epoch 737/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 738/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 739/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0114\n",
      "Epoch 740/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0105\n",
      "Epoch 741/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 742/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 743/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0109\n",
      "Epoch 744/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0108\n",
      "Epoch 745/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 746/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0104\n",
      "Epoch 747/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0105\n",
      "Epoch 748/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0109\n",
      "Epoch 749/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0107\n",
      "Epoch 750/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 751/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0107\n",
      "Epoch 752/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 753/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 754/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0104\n",
      "Epoch 755/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0104\n",
      "Epoch 756/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0112\n",
      "Epoch 757/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0107\n",
      "Epoch 758/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0104\n",
      "Epoch 759/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0114\n",
      "Epoch 760/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0106\n",
      "Epoch 761/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 762/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0105\n",
      "Epoch 763/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 764/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0110\n",
      "Epoch 765/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 766/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0112\n",
      "Epoch 767/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0109\n",
      "Epoch 768/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0109\n",
      "Epoch 769/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0109\n",
      "Epoch 770/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0105\n",
      "Epoch 771/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0104\n",
      "Epoch 772/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0108\n",
      "Epoch 773/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0103\n",
      "Epoch 774/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0104\n",
      "Epoch 775/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0104\n",
      "Epoch 776/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0109\n",
      "Epoch 777/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0106\n",
      "Epoch 778/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0109\n",
      "Epoch 779/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0107\n",
      "Epoch 780/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 781/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0108\n",
      "Epoch 782/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 783/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0108\n",
      "Epoch 784/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0105\n",
      "Epoch 785/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 786/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 787/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0104\n",
      "Epoch 788/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 789/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0105\n",
      "Epoch 790/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 791/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0104\n",
      "Epoch 792/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 793/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0104\n",
      "Epoch 794/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0107\n",
      "Epoch 795/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0105\n",
      "Epoch 796/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0107\n",
      "Epoch 797/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 798/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0107\n",
      "Epoch 799/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0109\n",
      "Epoch 800/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0104\n",
      "Epoch 801/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0113\n",
      "Epoch 802/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0106\n",
      "Epoch 803/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 804/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 805/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 806/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0107\n",
      "Epoch 807/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 808/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0109\n",
      "Epoch 809/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0120\n",
      "Epoch 810/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0104\n",
      "Epoch 811/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0104\n",
      "Epoch 812/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0104\n",
      "Epoch 813/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0109\n",
      "Epoch 814/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 815/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0106\n",
      "Epoch 816/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0108\n",
      "Epoch 817/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0106\n",
      "Epoch 818/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 819/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0107\n",
      "Epoch 820/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0104\n",
      "Epoch 821/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0104\n",
      "Epoch 822/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0104\n",
      "Epoch 823/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0104\n",
      "Epoch 824/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0108\n",
      "Epoch 825/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0107\n",
      "Epoch 826/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 827/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0107\n",
      "Epoch 828/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0112\n",
      "Epoch 829/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0106\n",
      "Epoch 830/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 831/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 832/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0105\n",
      "Epoch 833/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 834/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0110\n",
      "Epoch 835/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0143\n",
      "Epoch 836/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0123\n",
      "Epoch 837/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0109\n",
      "Epoch 838/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0107\n",
      "Epoch 839/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0109\n",
      "Epoch 840/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0105\n",
      "Epoch 841/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0107\n",
      "Epoch 842/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 843/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 844/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0109\n",
      "Epoch 845/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 846/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 847/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0104\n",
      "Epoch 848/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 849/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0105\n",
      "Epoch 850/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0110\n",
      "Epoch 851/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 852/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0115\n",
      "Epoch 853/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0116\n",
      "Epoch 854/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0106\n",
      "Epoch 855/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 856/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0106\n",
      "Epoch 857/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 858/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0107\n",
      "Epoch 859/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0109\n",
      "Epoch 860/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 861/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0104\n",
      "Epoch 862/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0116\n",
      "Epoch 863/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0111\n",
      "Epoch 864/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 865/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 866/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 867/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 868/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0102\n",
      "Epoch 869/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0102\n",
      "Epoch 870/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0109\n",
      "Epoch 871/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0103\n",
      "Epoch 872/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0103\n",
      "Epoch 873/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0103\n",
      "Epoch 874/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0102\n",
      "Epoch 875/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0104\n",
      "Epoch 876/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 877/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 878/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 879/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0103\n",
      "Epoch 880/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0102\n",
      "Epoch 881/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 882/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0102\n",
      "Epoch 883/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0120\n",
      "Epoch 884/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0107\n",
      "Epoch 885/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0108\n",
      "Epoch 886/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 887/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0109\n",
      "Epoch 888/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0104\n",
      "Epoch 889/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0107\n",
      "Epoch 890/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0114\n",
      "Epoch 891/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0103\n",
      "Epoch 892/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0102\n",
      "Epoch 893/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0102\n",
      "Epoch 894/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0109\n",
      "Epoch 895/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0104\n",
      "Epoch 896/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0105\n",
      "Epoch 897/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0104\n",
      "Epoch 898/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 899/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0110\n",
      "Epoch 900/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0104\n",
      "Epoch 901/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0105\n",
      "Epoch 902/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0104\n",
      "Epoch 903/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0109\n",
      "Epoch 904/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0108\n",
      "Epoch 905/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 906/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 907/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 908/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0107\n",
      "Epoch 909/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0104\n",
      "Epoch 910/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0109\n",
      "Epoch 911/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0104\n",
      "Epoch 912/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0106\n",
      "Epoch 913/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0103\n",
      "Epoch 914/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0106\n",
      "Epoch 915/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0103\n",
      "Epoch 916/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0103\n",
      "Epoch 917/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 918/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0110\n",
      "Epoch 919/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 920/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0105\n",
      "Epoch 921/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0102\n",
      "Epoch 922/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0103\n",
      "Epoch 923/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0102\n",
      "Epoch 924/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0103\n",
      "Epoch 925/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 926/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0103\n",
      "Epoch 927/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0103\n",
      "Epoch 928/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0107\n",
      "Epoch 929/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0110\n",
      "Epoch 930/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 931/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0106\n",
      "Epoch 932/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0107\n",
      "Epoch 933/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 934/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0105\n",
      "Epoch 935/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 936/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0107\n",
      "Epoch 937/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0107\n",
      "Epoch 938/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0105\n",
      "Epoch 939/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 940/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0107\n",
      "Epoch 941/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0104\n",
      "Epoch 942/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0104\n",
      "Epoch 943/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 944/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0104\n",
      "Epoch 945/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0106\n",
      "Epoch 946/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0104\n",
      "Epoch 947/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0107\n",
      "Epoch 948/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0104\n",
      "Epoch 949/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 950/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0106\n",
      "Epoch 951/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0106\n",
      "Epoch 952/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 953/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0102\n",
      "Epoch 954/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0103\n",
      "Epoch 955/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0103\n",
      "Epoch 956/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0103\n",
      "Epoch 957/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0104\n",
      "Epoch 958/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 959/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 960/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 961/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0109\n",
      "Epoch 962/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0104\n",
      "Epoch 963/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0103\n",
      "Epoch 964/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 965/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0104\n",
      "Epoch 966/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0103\n",
      "Epoch 967/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0125\n",
      "Epoch 968/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0105\n",
      "Epoch 969/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0103\n",
      "Epoch 970/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0103\n",
      "Epoch 971/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0102\n",
      "Epoch 972/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0103\n",
      "Epoch 973/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0108\n",
      "Epoch 974/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0103\n",
      "Epoch 975/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 976/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 977/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0103\n",
      "Epoch 978/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0105\n",
      "Epoch 979/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0102\n",
      "Epoch 980/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0103\n",
      "Epoch 981/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0106\n",
      "Epoch 982/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 983/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0105\n",
      "Epoch 984/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0103\n",
      "Epoch 985/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 986/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 987/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0107\n",
      "Epoch 988/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0103\n",
      "Epoch 989/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0104\n",
      "Epoch 990/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0105\n",
      "Epoch 991/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0104\n",
      "Epoch 992/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0110\n",
      "Epoch 00992: early stopping\n",
      "Epoch 1/10000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.6610 - val_loss: 0.3172\n",
      "Epoch 2/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2204 - val_loss: 0.0625\n",
      "Epoch 3/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1024 - val_loss: 0.0394\n",
      "Epoch 4/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0894 - val_loss: 0.0346\n",
      "Epoch 5/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0824 - val_loss: 0.0361\n",
      "Epoch 6/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0793 - val_loss: 0.0334\n",
      "Epoch 7/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0748 - val_loss: 0.0345\n",
      "Epoch 8/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0725 - val_loss: 0.0349\n",
      "Epoch 9/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0691 - val_loss: 0.0319\n",
      "Epoch 10/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0658 - val_loss: 0.0323\n",
      "Epoch 11/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0626 - val_loss: 0.0308\n",
      "Epoch 12/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0592 - val_loss: 0.0276\n",
      "Epoch 13/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0556 - val_loss: 0.0260\n",
      "Epoch 14/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0528 - val_loss: 0.0232\n",
      "Epoch 15/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0497 - val_loss: 0.0228\n",
      "Epoch 16/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0474 - val_loss: 0.0202\n",
      "Epoch 17/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0440 - val_loss: 0.0202\n",
      "Epoch 18/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0421 - val_loss: 0.0181\n",
      "Epoch 19/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0191\n",
      "Epoch 20/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0386 - val_loss: 0.0190\n",
      "Epoch 21/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0380 - val_loss: 0.0177\n",
      "Epoch 22/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0372 - val_loss: 0.0172\n",
      "Epoch 23/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0342 - val_loss: 0.0185\n",
      "Epoch 24/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0348 - val_loss: 0.0177\n",
      "Epoch 25/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0337 - val_loss: 0.0173\n",
      "Epoch 26/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0330 - val_loss: 0.0176\n",
      "Epoch 27/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0321 - val_loss: 0.0169\n",
      "Epoch 28/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0309 - val_loss: 0.0175\n",
      "Epoch 29/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0304 - val_loss: 0.0169\n",
      "Epoch 30/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0304 - val_loss: 0.0166\n",
      "Epoch 31/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0302 - val_loss: 0.0168\n",
      "Epoch 32/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0287 - val_loss: 0.0169\n",
      "Epoch 33/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0293 - val_loss: 0.0180\n",
      "Epoch 34/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0292 - val_loss: 0.0166\n",
      "Epoch 35/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0288 - val_loss: 0.0168\n",
      "Epoch 36/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0284 - val_loss: 0.0169\n",
      "Epoch 37/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0285 - val_loss: 0.0174\n",
      "Epoch 38/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.0167\n",
      "Epoch 39/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0261 - val_loss: 0.0165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0266 - val_loss: 0.0165\n",
      "Epoch 41/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0263 - val_loss: 0.0163\n",
      "Epoch 42/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.0170\n",
      "Epoch 43/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.0163\n",
      "Epoch 44/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.0165\n",
      "Epoch 45/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0256 - val_loss: 0.0165\n",
      "Epoch 46/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.0163\n",
      "Epoch 47/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.0162\n",
      "Epoch 48/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0256 - val_loss: 0.0164\n",
      "Epoch 49/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0249 - val_loss: 0.0173\n",
      "Epoch 50/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0250 - val_loss: 0.0161\n",
      "Epoch 51/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.0164\n",
      "Epoch 52/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0244 - val_loss: 0.0160\n",
      "Epoch 53/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0246 - val_loss: 0.0162\n",
      "Epoch 54/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.0162\n",
      "Epoch 55/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0234 - val_loss: 0.0161\n",
      "Epoch 56/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0236 - val_loss: 0.0160\n",
      "Epoch 57/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0238 - val_loss: 0.0163\n",
      "Epoch 58/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0234 - val_loss: 0.0162\n",
      "Epoch 59/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0229 - val_loss: 0.0166\n",
      "Epoch 60/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0238 - val_loss: 0.0160\n",
      "Epoch 61/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0234 - val_loss: 0.0165\n",
      "Epoch 62/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0226 - val_loss: 0.0161\n",
      "Epoch 63/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0233 - val_loss: 0.0160\n",
      "Epoch 64/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.0161\n",
      "Epoch 65/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0226 - val_loss: 0.0160\n",
      "Epoch 66/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.0161\n",
      "Epoch 67/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0228 - val_loss: 0.0162\n",
      "Epoch 68/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0219 - val_loss: 0.0160\n",
      "Epoch 69/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0219 - val_loss: 0.0156\n",
      "Epoch 70/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.0159\n",
      "Epoch 71/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0160\n",
      "Epoch 72/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.0158\n",
      "Epoch 73/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0219 - val_loss: 0.0162\n",
      "Epoch 74/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.0160\n",
      "Epoch 75/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0221 - val_loss: 0.0157\n",
      "Epoch 76/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0157\n",
      "Epoch 77/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0215 - val_loss: 0.0159\n",
      "Epoch 78/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.0156\n",
      "Epoch 79/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.0155\n",
      "Epoch 80/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.0155\n",
      "Epoch 81/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0155\n",
      "Epoch 82/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0158\n",
      "Epoch 83/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0155\n",
      "Epoch 84/10000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.018 - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0154\n",
      "Epoch 85/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.0155\n",
      "Epoch 86/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0155\n",
      "Epoch 87/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.0157\n",
      "Epoch 88/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0157\n",
      "Epoch 89/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.0152\n",
      "Epoch 90/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0167\n",
      "Epoch 91/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0155\n",
      "Epoch 92/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0155\n",
      "Epoch 93/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0150\n",
      "Epoch 94/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.0154\n",
      "Epoch 95/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0199 - val_loss: 0.0147\n",
      "Epoch 96/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0193 - val_loss: 0.0146\n",
      "Epoch 97/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0148\n",
      "Epoch 98/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0144\n",
      "Epoch 99/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0145\n",
      "Epoch 100/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0145\n",
      "Epoch 101/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0142\n",
      "Epoch 102/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0141\n",
      "Epoch 103/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0140\n",
      "Epoch 104/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0139\n",
      "Epoch 105/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0136\n",
      "Epoch 106/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0137\n",
      "Epoch 107/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0183 - val_loss: 0.0134\n",
      "Epoch 108/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0138\n",
      "Epoch 109/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0132\n",
      "Epoch 110/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0133\n",
      "Epoch 111/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0180 - val_loss: 0.0135\n",
      "Epoch 112/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0177 - val_loss: 0.0135\n",
      "Epoch 113/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0133\n",
      "Epoch 114/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0135\n",
      "Epoch 115/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0132\n",
      "Epoch 116/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0132\n",
      "Epoch 117/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0131\n",
      "Epoch 118/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0140\n",
      "Epoch 119/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0132\n",
      "Epoch 121/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0132\n",
      "Epoch 122/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0129\n",
      "Epoch 123/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0130\n",
      "Epoch 124/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0129\n",
      "Epoch 125/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0128\n",
      "Epoch 126/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0129\n",
      "Epoch 127/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0128\n",
      "Epoch 128/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0130\n",
      "Epoch 129/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0129\n",
      "Epoch 130/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0144\n",
      "Epoch 131/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0129\n",
      "Epoch 132/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0128\n",
      "Epoch 133/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0127\n",
      "Epoch 134/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0131\n",
      "Epoch 135/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0129\n",
      "Epoch 136/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0129\n",
      "Epoch 137/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0128\n",
      "Epoch 138/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0133\n",
      "Epoch 139/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0128\n",
      "Epoch 140/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0128\n",
      "Epoch 141/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0127\n",
      "Epoch 142/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0127\n",
      "Epoch 143/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0126\n",
      "Epoch 144/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0126\n",
      "Epoch 145/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0125\n",
      "Epoch 146/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0125\n",
      "Epoch 147/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0125\n",
      "Epoch 148/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0128\n",
      "Epoch 149/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0128\n",
      "Epoch 150/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0125\n",
      "Epoch 151/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0125\n",
      "Epoch 152/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0125\n",
      "Epoch 153/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0127\n",
      "Epoch 154/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0125\n",
      "Epoch 155/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0129\n",
      "Epoch 156/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0124\n",
      "Epoch 157/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0126\n",
      "Epoch 158/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0125\n",
      "Epoch 159/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0124\n",
      "Epoch 160/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0123\n",
      "Epoch 161/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0122\n",
      "Epoch 162/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0124\n",
      "Epoch 163/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0127\n",
      "Epoch 164/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0126\n",
      "Epoch 165/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0123\n",
      "Epoch 166/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0128\n",
      "Epoch 167/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0124\n",
      "Epoch 168/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0122\n",
      "Epoch 169/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0123\n",
      "Epoch 170/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0128\n",
      "Epoch 171/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0124\n",
      "Epoch 172/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0126\n",
      "Epoch 173/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0125\n",
      "Epoch 174/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0123\n",
      "Epoch 175/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0124\n",
      "Epoch 176/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0129\n",
      "Epoch 177/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0125\n",
      "Epoch 178/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0121\n",
      "Epoch 179/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0132\n",
      "Epoch 180/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0134\n",
      "Epoch 181/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0123\n",
      "Epoch 182/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0123\n",
      "Epoch 183/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0120\n",
      "Epoch 184/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0121\n",
      "Epoch 185/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0123\n",
      "Epoch 186/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 187/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0121\n",
      "Epoch 188/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0120\n",
      "Epoch 189/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0120\n",
      "Epoch 190/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0121\n",
      "Epoch 191/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0131\n",
      "Epoch 192/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0125\n",
      "Epoch 193/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0121\n",
      "Epoch 194/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.0122\n",
      "Epoch 195/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0120\n",
      "Epoch 196/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0122\n",
      "Epoch 197/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0124\n",
      "Epoch 198/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0120\n",
      "Epoch 199/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0120\n",
      "Epoch 200/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0120\n",
      "Epoch 201/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0120\n",
      "Epoch 202/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0119\n",
      "Epoch 203/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0120\n",
      "Epoch 204/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0122\n",
      "Epoch 205/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0118\n",
      "Epoch 206/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0126\n",
      "Epoch 207/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0130 - val_loss: 0.0121\n",
      "Epoch 208/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0119\n",
      "Epoch 209/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0130\n",
      "Epoch 210/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0120\n",
      "Epoch 211/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0120\n",
      "Epoch 212/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0119\n",
      "Epoch 213/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0119\n",
      "Epoch 214/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0118\n",
      "Epoch 215/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0118\n",
      "Epoch 216/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0119\n",
      "Epoch 217/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0119\n",
      "Epoch 218/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0119\n",
      "Epoch 219/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0119\n",
      "Epoch 220/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0117\n",
      "Epoch 221/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0119\n",
      "Epoch 222/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0119\n",
      "Epoch 223/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0119\n",
      "Epoch 224/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0119\n",
      "Epoch 225/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0119\n",
      "Epoch 226/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0116\n",
      "Epoch 227/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0117\n",
      "Epoch 228/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0117\n",
      "Epoch 229/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0123\n",
      "Epoch 230/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0116\n",
      "Epoch 231/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0119\n",
      "Epoch 232/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0119\n",
      "Epoch 233/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0115\n",
      "Epoch 234/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.0119\n",
      "Epoch 235/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0117\n",
      "Epoch 236/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0110\n",
      "Epoch 237/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0106\n",
      "Epoch 238/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0104\n",
      "Epoch 239/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0098\n",
      "Epoch 240/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0099\n",
      "Epoch 241/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0099\n",
      "Epoch 242/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0092\n",
      "Epoch 243/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0094\n",
      "Epoch 244/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0093\n",
      "Epoch 245/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0092\n",
      "Epoch 246/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0091\n",
      "Epoch 247/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0091\n",
      "Epoch 248/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0092\n",
      "Epoch 249/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0091\n",
      "Epoch 250/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0097\n",
      "Epoch 251/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0100\n",
      "Epoch 252/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0091\n",
      "Epoch 253/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0090\n",
      "Epoch 254/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0090\n",
      "Epoch 255/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0091\n",
      "Epoch 256/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0098\n",
      "Epoch 257/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0092\n",
      "Epoch 258/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0091\n",
      "Epoch 259/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0102\n",
      "Epoch 260/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0091\n",
      "Epoch 261/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0091\n",
      "Epoch 262/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0092\n",
      "Epoch 263/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0089\n",
      "Epoch 264/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0092\n",
      "Epoch 265/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0094\n",
      "Epoch 266/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0093\n",
      "Epoch 267/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0091\n",
      "Epoch 268/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0094\n",
      "Epoch 269/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0091\n",
      "Epoch 270/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0092\n",
      "Epoch 271/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0094\n",
      "Epoch 272/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0092\n",
      "Epoch 273/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0088\n",
      "Epoch 274/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0089\n",
      "Epoch 275/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0089\n",
      "Epoch 276/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0095\n",
      "Epoch 277/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0090\n",
      "Epoch 278/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0090\n",
      "Epoch 279/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0088\n",
      "Epoch 280/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0088\n",
      "Epoch 281/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0090\n",
      "Epoch 282/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0088\n",
      "Epoch 283/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0090\n",
      "Epoch 284/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0089\n",
      "Epoch 285/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0092\n",
      "Epoch 286/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0090\n",
      "Epoch 287/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0088\n",
      "Epoch 288/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0089\n",
      "Epoch 289/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0088\n",
      "Epoch 290/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0087\n",
      "Epoch 291/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 292/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0088\n",
      "Epoch 293/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0092\n",
      "Epoch 294/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0088\n",
      "Epoch 295/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0088\n",
      "Epoch 296/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0089\n",
      "Epoch 297/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0088\n",
      "Epoch 298/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0087\n",
      "Epoch 299/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0091\n",
      "Epoch 300/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0087\n",
      "Epoch 301/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0092\n",
      "Epoch 302/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0088\n",
      "Epoch 303/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0088\n",
      "Epoch 304/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0088\n",
      "Epoch 305/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0089\n",
      "Epoch 306/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0091\n",
      "Epoch 307/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0089\n",
      "Epoch 308/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0092\n",
      "Epoch 309/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0089\n",
      "Epoch 310/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0088\n",
      "Epoch 311/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0088\n",
      "Epoch 312/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0088\n",
      "Epoch 313/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0088\n",
      "Epoch 314/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0087\n",
      "Epoch 315/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0090\n",
      "Epoch 316/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0090\n",
      "Epoch 317/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0093\n",
      "Epoch 318/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0087\n",
      "Epoch 319/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0090\n",
      "Epoch 320/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0086\n",
      "Epoch 321/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0087\n",
      "Epoch 322/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0088\n",
      "Epoch 323/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0094\n",
      "Epoch 324/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0089\n",
      "Epoch 325/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0088\n",
      "Epoch 326/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0103\n",
      "Epoch 327/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0091\n",
      "Epoch 328/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0095\n",
      "Epoch 329/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0093\n",
      "Epoch 330/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0088\n",
      "Epoch 331/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0090\n",
      "Epoch 332/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0089\n",
      "Epoch 333/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0088\n",
      "Epoch 334/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0088\n",
      "Epoch 335/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0086\n",
      "Epoch 336/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0088\n",
      "Epoch 337/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0087\n",
      "Epoch 338/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0086\n",
      "Epoch 339/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0086\n",
      "Epoch 340/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0087\n",
      "Epoch 341/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0086\n",
      "Epoch 342/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0087\n",
      "Epoch 343/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0087\n",
      "Epoch 344/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0087\n",
      "Epoch 345/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0087\n",
      "Epoch 346/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0086\n",
      "Epoch 347/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0086\n",
      "Epoch 348/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0086\n",
      "Epoch 349/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0086\n",
      "Epoch 350/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0088\n",
      "Epoch 351/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0090\n",
      "Epoch 352/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0092\n",
      "Epoch 353/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0088\n",
      "Epoch 354/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0085\n",
      "Epoch 355/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0091\n",
      "Epoch 356/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0091\n",
      "Epoch 357/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0086\n",
      "Epoch 358/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0086\n",
      "Epoch 359/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0086\n",
      "Epoch 360/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0085\n",
      "Epoch 361/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0084\n",
      "Epoch 362/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0089\n",
      "Epoch 363/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0087\n",
      "Epoch 364/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0086\n",
      "Epoch 365/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0086\n",
      "Epoch 366/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0088\n",
      "Epoch 367/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0085\n",
      "Epoch 368/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0094\n",
      "Epoch 369/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0090\n",
      "Epoch 370/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0097\n",
      "Epoch 371/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0087\n",
      "Epoch 372/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0085\n",
      "Epoch 373/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0086\n",
      "Epoch 374/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0086\n",
      "Epoch 375/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0084\n",
      "Epoch 376/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0085\n",
      "Epoch 377/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0087\n",
      "Epoch 378/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0088\n",
      "Epoch 379/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0084\n",
      "Epoch 380/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0087\n",
      "Epoch 381/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0091\n",
      "Epoch 382/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0092\n",
      "Epoch 383/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0085\n",
      "Epoch 384/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0085\n",
      "Epoch 385/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0083\n",
      "Epoch 386/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0084\n",
      "Epoch 387/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0088\n",
      "Epoch 388/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0086\n",
      "Epoch 389/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0092\n",
      "Epoch 390/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0086\n",
      "Epoch 391/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0086\n",
      "Epoch 392/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0086\n",
      "Epoch 393/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0085\n",
      "Epoch 394/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0083\n",
      "Epoch 395/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0082\n",
      "Epoch 396/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0084\n",
      "Epoch 397/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0087\n",
      "Epoch 398/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0084\n",
      "Epoch 399/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0087\n",
      "Epoch 400/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0084\n",
      "Epoch 401/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0084\n",
      "Epoch 402/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0085\n",
      "Epoch 403/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0088\n",
      "Epoch 404/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0084\n",
      "Epoch 405/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0083\n",
      "Epoch 406/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0085\n",
      "Epoch 407/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0085\n",
      "Epoch 408/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0085\n",
      "Epoch 409/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0086\n",
      "Epoch 410/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0089\n",
      "Epoch 411/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0091\n",
      "Epoch 412/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0090\n",
      "Epoch 413/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0086\n",
      "Epoch 414/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0085\n",
      "Epoch 415/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0088\n",
      "Epoch 416/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0084\n",
      "Epoch 417/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0084\n",
      "Epoch 418/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0083\n",
      "Epoch 419/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0084\n",
      "Epoch 420/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0084\n",
      "Epoch 421/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0085\n",
      "Epoch 422/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0084\n",
      "Epoch 423/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0090\n",
      "Epoch 424/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0084\n",
      "Epoch 425/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0083\n",
      "Epoch 426/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0083\n",
      "Epoch 427/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0084\n",
      "Epoch 428/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0089\n",
      "Epoch 429/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0086\n",
      "Epoch 430/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0084\n",
      "Epoch 431/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0092\n",
      "Epoch 432/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0087\n",
      "Epoch 433/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0085\n",
      "Epoch 434/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0085\n",
      "Epoch 435/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0084\n",
      "Epoch 436/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0085\n",
      "Epoch 437/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0084\n",
      "Epoch 438/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0089\n",
      "Epoch 439/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0083\n",
      "Epoch 440/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0086\n",
      "Epoch 441/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0083\n",
      "Epoch 442/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0086\n",
      "Epoch 443/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0083\n",
      "Epoch 444/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0084\n",
      "Epoch 445/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0083\n",
      "Epoch 446/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0082\n",
      "Epoch 447/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0086\n",
      "Epoch 448/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0086\n",
      "Epoch 449/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0088\n",
      "Epoch 450/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0083\n",
      "Epoch 451/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0086\n",
      "Epoch 452/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0085\n",
      "Epoch 453/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0086\n",
      "Epoch 454/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0087\n",
      "Epoch 455/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0083\n",
      "Epoch 456/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0083\n",
      "Epoch 457/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0083\n",
      "Epoch 458/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0082\n",
      "Epoch 459/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0084\n",
      "Epoch 460/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0084\n",
      "Epoch 461/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0082\n",
      "Epoch 462/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 463/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0082\n",
      "Epoch 464/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0084\n",
      "Epoch 465/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0089\n",
      "Epoch 466/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0084\n",
      "Epoch 467/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0083\n",
      "Epoch 468/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0084\n",
      "Epoch 469/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0083\n",
      "Epoch 470/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0084\n",
      "Epoch 471/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0084\n",
      "Epoch 472/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0083\n",
      "Epoch 473/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 474/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0083\n",
      "Epoch 475/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0085\n",
      "Epoch 476/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0088\n",
      "Epoch 477/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0086\n",
      "Epoch 478/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0082\n",
      "Epoch 479/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0083\n",
      "Epoch 480/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0082\n",
      "Epoch 481/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0084\n",
      "Epoch 482/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0084\n",
      "Epoch 483/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0082\n",
      "Epoch 484/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0082\n",
      "Epoch 485/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0082\n",
      "Epoch 486/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 487/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0083\n",
      "Epoch 488/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0083\n",
      "Epoch 489/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0082\n",
      "Epoch 490/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0082\n",
      "Epoch 491/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0085\n",
      "Epoch 492/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0086\n",
      "Epoch 493/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0085\n",
      "Epoch 494/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0086\n",
      "Epoch 495/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0084\n",
      "Epoch 496/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0084\n",
      "Epoch 497/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0082\n",
      "Epoch 498/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.0082\n",
      "Epoch 499/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.0090\n",
      "Epoch 500/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.0086\n",
      "Epoch 501/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.0083\n",
      "Epoch 502/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.0082\n",
      "Epoch 503/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0082\n",
      "Epoch 504/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.0082\n",
      "Epoch 505/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0083\n",
      "Epoch 506/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0082\n",
      "Epoch 507/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0082\n",
      "Epoch 508/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0085\n",
      "Epoch 509/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0082\n",
      "Epoch 510/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0084\n",
      "Epoch 511/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0083\n",
      "Epoch 512/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 513/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0081\n",
      "Epoch 514/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0086\n",
      "Epoch 515/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0090\n",
      "Epoch 516/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0084\n",
      "Epoch 517/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0082\n",
      "Epoch 518/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0082\n",
      "Epoch 519/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0084\n",
      "Epoch 520/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0081\n",
      "Epoch 521/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 522/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0084\n",
      "Epoch 523/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0081\n",
      "Epoch 524/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0082\n",
      "Epoch 525/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0086\n",
      "Epoch 526/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0084\n",
      "Epoch 527/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0084\n",
      "Epoch 528/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0089\n",
      "Epoch 529/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0085\n",
      "Epoch 530/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0082\n",
      "Epoch 531/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0081\n",
      "Epoch 532/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0081\n",
      "Epoch 533/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0083\n",
      "Epoch 534/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0084\n",
      "Epoch 535/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0082\n",
      "Epoch 536/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0083\n",
      "Epoch 537/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0081\n",
      "Epoch 538/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 539/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0083\n",
      "Epoch 540/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0086\n",
      "Epoch 541/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0083\n",
      "Epoch 542/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0085\n",
      "Epoch 543/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0083\n",
      "Epoch 544/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0084\n",
      "Epoch 545/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0086\n",
      "Epoch 546/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0081\n",
      "Epoch 547/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0082\n",
      "Epoch 548/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0084\n",
      "Epoch 549/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 550/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 551/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0082\n",
      "Epoch 552/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0082\n",
      "Epoch 553/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0082\n",
      "Epoch 554/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0083\n",
      "Epoch 555/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0088\n",
      "Epoch 556/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0082\n",
      "Epoch 557/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0084\n",
      "Epoch 558/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0083\n",
      "Epoch 559/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0083\n",
      "Epoch 560/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0084\n",
      "Epoch 561/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 562/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0085\n",
      "Epoch 563/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0081\n",
      "Epoch 564/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0084\n",
      "Epoch 565/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0086\n",
      "Epoch 566/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0086\n",
      "Epoch 567/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0082\n",
      "Epoch 568/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0082\n",
      "Epoch 569/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0082\n",
      "Epoch 570/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0084\n",
      "Epoch 571/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0082\n",
      "Epoch 572/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0088\n",
      "Epoch 573/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0082\n",
      "Epoch 574/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0080\n",
      "Epoch 575/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0083\n",
      "Epoch 576/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0081\n",
      "Epoch 577/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 578/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0085\n",
      "Epoch 579/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0083\n",
      "Epoch 580/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0081\n",
      "Epoch 581/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0080\n",
      "Epoch 582/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0083\n",
      "Epoch 583/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0081\n",
      "Epoch 584/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0082\n",
      "Epoch 585/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0088\n",
      "Epoch 586/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0083\n",
      "Epoch 587/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0082\n",
      "Epoch 588/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 589/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0091\n",
      "Epoch 590/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0085\n",
      "Epoch 591/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0082\n",
      "Epoch 592/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0083\n",
      "Epoch 593/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0080\n",
      "Epoch 594/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0084\n",
      "Epoch 595/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0083\n",
      "Epoch 596/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0085\n",
      "Epoch 597/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0081\n",
      "Epoch 598/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0082\n",
      "Epoch 599/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0084\n",
      "Epoch 600/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0083\n",
      "Epoch 601/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0084\n",
      "Epoch 602/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 603/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0080\n",
      "Epoch 604/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 605/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0081\n",
      "Epoch 606/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0086\n",
      "Epoch 607/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0084\n",
      "Epoch 608/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0081\n",
      "Epoch 609/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0081\n",
      "Epoch 610/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0086\n",
      "Epoch 611/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0082\n",
      "Epoch 612/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0082\n",
      "Epoch 613/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0080\n",
      "Epoch 614/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0080\n",
      "Epoch 615/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0081\n",
      "Epoch 616/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0083\n",
      "Epoch 617/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 618/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0080\n",
      "Epoch 619/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0080\n",
      "Epoch 620/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0086\n",
      "Epoch 621/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0084\n",
      "Epoch 622/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0082\n",
      "Epoch 623/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0087\n",
      "Epoch 624/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0098\n",
      "Epoch 625/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0082\n",
      "Epoch 626/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 627/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 628/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 629/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0084\n",
      "Epoch 630/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0083\n",
      "Epoch 631/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0081\n",
      "Epoch 632/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0082\n",
      "Epoch 633/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 634/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0083\n",
      "Epoch 635/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0083\n",
      "Epoch 636/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0082\n",
      "Epoch 637/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0088\n",
      "Epoch 638/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0084\n",
      "Epoch 639/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0083\n",
      "Epoch 640/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0081\n",
      "Epoch 641/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0084\n",
      "Epoch 642/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0083\n",
      "Epoch 643/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0081\n",
      "Epoch 644/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0084\n",
      "Epoch 645/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0082\n",
      "Epoch 646/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0082\n",
      "Epoch 647/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 648/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0082\n",
      "Epoch 649/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0081\n",
      "Epoch 650/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0080\n",
      "Epoch 651/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0080\n",
      "Epoch 652/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0082\n",
      "Epoch 653/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0084\n",
      "Epoch 654/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0082\n",
      "Epoch 655/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0082\n",
      "Epoch 656/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0088\n",
      "Epoch 657/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0082\n",
      "Epoch 658/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0082\n",
      "Epoch 659/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0084\n",
      "Epoch 660/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0095\n",
      "Epoch 661/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0081\n",
      "Epoch 662/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0081\n",
      "Epoch 663/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0080\n",
      "Epoch 664/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0082\n",
      "Epoch 665/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 666/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0080\n",
      "Epoch 667/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0084\n",
      "Epoch 668/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0088\n",
      "Epoch 669/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0082\n",
      "Epoch 670/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0082\n",
      "Epoch 671/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0083\n",
      "Epoch 672/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0086\n",
      "Epoch 673/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0087\n",
      "Epoch 674/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0081\n",
      "Epoch 675/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0081\n",
      "Epoch 676/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 677/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0081\n",
      "Epoch 678/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0082\n",
      "Epoch 679/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0081\n",
      "Epoch 680/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0080\n",
      "Epoch 681/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0084\n",
      "Epoch 682/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 683/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0081\n",
      "Epoch 684/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0084\n",
      "Epoch 685/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0086\n",
      "Epoch 686/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0080\n",
      "Epoch 687/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0083\n",
      "Epoch 688/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0080\n",
      "Epoch 689/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0082\n",
      "Epoch 690/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0085\n",
      "Epoch 691/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0084\n",
      "Epoch 692/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0084\n",
      "Epoch 693/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0080\n",
      "Epoch 694/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0082\n",
      "Epoch 695/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0084\n",
      "Epoch 696/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0082\n",
      "Epoch 697/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0082\n",
      "Epoch 698/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0083\n",
      "Epoch 699/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0082\n",
      "Epoch 700/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0086\n",
      "Epoch 701/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0083\n",
      "Epoch 702/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0081\n",
      "Epoch 703/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0081\n",
      "Epoch 704/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0081\n",
      "Epoch 705/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0082\n",
      "Epoch 706/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0086\n",
      "Epoch 707/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0093\n",
      "Epoch 708/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0083\n",
      "Epoch 709/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0081\n",
      "Epoch 710/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 711/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0081\n",
      "Epoch 712/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0086\n",
      "Epoch 713/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 714/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0091\n",
      "Epoch 00714: early stopping\n",
      "Epoch 1/10000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.6974 - val_loss: 0.3407\n",
      "Epoch 2/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2347 - val_loss: 0.0678\n",
      "Epoch 3/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1065 - val_loss: 0.0374\n",
      "Epoch 4/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0900 - val_loss: 0.0334\n",
      "Epoch 5/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0838 - val_loss: 0.0330\n",
      "Epoch 6/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0780 - val_loss: 0.0315\n",
      "Epoch 7/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0753 - val_loss: 0.0314\n",
      "Epoch 8/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0718 - val_loss: 0.0315\n",
      "Epoch 9/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0664 - val_loss: 0.0288\n",
      "Epoch 10/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0637 - val_loss: 0.0274\n",
      "Epoch 11/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0260\n",
      "Epoch 12/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0559 - val_loss: 0.0229\n",
      "Epoch 13/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.0217\n",
      "Epoch 14/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0193\n",
      "Epoch 15/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0476 - val_loss: 0.0193\n",
      "Epoch 16/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0453 - val_loss: 0.0192\n",
      "Epoch 17/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0423 - val_loss: 0.0181\n",
      "Epoch 18/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0420 - val_loss: 0.0176\n",
      "Epoch 19/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0397 - val_loss: 0.0178\n",
      "Epoch 20/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0384 - val_loss: 0.0171\n",
      "Epoch 21/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0373 - val_loss: 0.0168\n",
      "Epoch 22/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0352 - val_loss: 0.0174\n",
      "Epoch 23/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0356 - val_loss: 0.0170\n",
      "Epoch 24/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0339 - val_loss: 0.0167\n",
      "Epoch 25/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0319 - val_loss: 0.0166\n",
      "Epoch 26/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0326 - val_loss: 0.0167\n",
      "Epoch 27/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0311 - val_loss: 0.0169\n",
      "Epoch 28/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0298 - val_loss: 0.0163\n",
      "Epoch 29/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0298 - val_loss: 0.0162\n",
      "Epoch 30/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0294 - val_loss: 0.0166\n",
      "Epoch 31/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0292 - val_loss: 0.0164\n",
      "Epoch 32/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0292 - val_loss: 0.0162\n",
      "Epoch 33/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0285 - val_loss: 0.0162\n",
      "Epoch 34/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0275 - val_loss: 0.0161\n",
      "Epoch 35/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0279 - val_loss: 0.0162\n",
      "Epoch 36/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.0160\n",
      "Epoch 37/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.0160\n",
      "Epoch 38/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.0160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0267 - val_loss: 0.0164\n",
      "Epoch 40/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0264 - val_loss: 0.0161\n",
      "Epoch 41/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0261 - val_loss: 0.0160\n",
      "Epoch 42/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0266 - val_loss: 0.0158\n",
      "Epoch 43/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0258 - val_loss: 0.0162\n",
      "Epoch 44/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0257 - val_loss: 0.0158\n",
      "Epoch 45/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0256 - val_loss: 0.0157\n",
      "Epoch 46/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0244 - val_loss: 0.0156\n",
      "Epoch 47/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.0158\n",
      "Epoch 48/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.0156\n",
      "Epoch 49/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0244 - val_loss: 0.0152\n",
      "Epoch 50/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.0169\n",
      "Epoch 51/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0245 - val_loss: 0.0149\n",
      "Epoch 52/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.0145\n",
      "Epoch 53/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0231 - val_loss: 0.0148\n",
      "Epoch 54/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0230 - val_loss: 0.0142\n",
      "Epoch 55/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.0142\n",
      "Epoch 56/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0232 - val_loss: 0.0144\n",
      "Epoch 57/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.0138\n",
      "Epoch 58/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.0137\n",
      "Epoch 59/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.0139\n",
      "Epoch 60/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.0137\n",
      "Epoch 61/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.0135\n",
      "Epoch 62/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0135\n",
      "Epoch 63/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0212 - val_loss: 0.0135\n",
      "Epoch 64/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0134\n",
      "Epoch 65/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.0134\n",
      "Epoch 66/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0215 - val_loss: 0.0138\n",
      "Epoch 67/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.0134\n",
      "Epoch 68/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0208 - val_loss: 0.0133\n",
      "Epoch 69/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0133\n",
      "Epoch 70/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0132\n",
      "Epoch 71/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0135\n",
      "Epoch 72/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.0141\n",
      "Epoch 73/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0138\n",
      "Epoch 74/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0201 - val_loss: 0.0134\n",
      "Epoch 75/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0199 - val_loss: 0.0134\n",
      "Epoch 76/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0133\n",
      "Epoch 77/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0133\n",
      "Epoch 78/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0135\n",
      "Epoch 79/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0135\n",
      "Epoch 80/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.0135\n",
      "Epoch 81/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0132\n",
      "Epoch 82/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0134\n",
      "Epoch 83/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0137\n",
      "Epoch 84/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0135\n",
      "Epoch 85/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0134\n",
      "Epoch 86/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0136\n",
      "Epoch 87/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0195 - val_loss: 0.0135\n",
      "Epoch 88/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0133\n",
      "Epoch 89/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0132\n",
      "Epoch 90/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0132\n",
      "Epoch 91/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0133\n",
      "Epoch 92/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0130\n",
      "Epoch 93/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0189 - val_loss: 0.0132\n",
      "Epoch 94/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0131\n",
      "Epoch 95/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0133\n",
      "Epoch 96/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0134\n",
      "Epoch 97/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0186 - val_loss: 0.0131\n",
      "Epoch 98/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0133\n",
      "Epoch 99/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0132\n",
      "Epoch 100/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0183 - val_loss: 0.0132\n",
      "Epoch 101/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0130\n",
      "Epoch 102/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0133\n",
      "Epoch 103/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0131\n",
      "Epoch 104/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0129\n",
      "Epoch 105/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0131\n",
      "Epoch 106/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0176 - val_loss: 0.0130\n",
      "Epoch 107/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0174 - val_loss: 0.0128\n",
      "Epoch 108/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0129\n",
      "Epoch 109/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0129\n",
      "Epoch 110/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0134\n",
      "Epoch 111/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0128\n",
      "Epoch 112/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0132\n",
      "Epoch 113/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0130\n",
      "Epoch 114/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0127\n",
      "Epoch 115/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0127\n",
      "Epoch 116/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0125\n",
      "Epoch 117/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0125\n",
      "Epoch 118/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0130\n",
      "Epoch 119/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0123\n",
      "Epoch 120/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0123\n",
      "Epoch 121/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0122\n",
      "Epoch 122/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0120\n",
      "Epoch 123/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0118\n",
      "Epoch 124/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0116\n",
      "Epoch 125/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0117\n",
      "Epoch 126/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0116\n",
      "Epoch 127/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0110\n",
      "Epoch 128/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0107\n",
      "Epoch 129/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0106\n",
      "Epoch 130/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0118\n",
      "Epoch 131/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0106\n",
      "Epoch 132/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0105\n",
      "Epoch 133/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0103\n",
      "Epoch 134/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0101\n",
      "Epoch 135/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0101\n",
      "Epoch 136/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0099\n",
      "Epoch 137/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0098\n",
      "Epoch 138/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0099\n",
      "Epoch 139/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0099\n",
      "Epoch 140/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0100\n",
      "Epoch 141/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0099\n",
      "Epoch 142/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0097\n",
      "Epoch 143/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0096\n",
      "Epoch 144/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0097\n",
      "Epoch 145/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0096\n",
      "Epoch 146/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0095\n",
      "Epoch 147/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0095\n",
      "Epoch 148/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0097\n",
      "Epoch 149/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0130 - val_loss: 0.0094\n",
      "Epoch 150/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0094\n",
      "Epoch 151/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0096\n",
      "Epoch 152/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.0094\n",
      "Epoch 153/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0098\n",
      "Epoch 154/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.0093\n",
      "Epoch 155/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0092\n",
      "Epoch 156/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0093\n",
      "Epoch 157/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0093\n",
      "Epoch 158/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0090\n",
      "Epoch 159/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.0088\n",
      "Epoch 160/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0090\n",
      "Epoch 161/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0088\n",
      "Epoch 162/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0100\n",
      "Epoch 163/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0087\n",
      "Epoch 164/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0090\n",
      "Epoch 165/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0087\n",
      "Epoch 166/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0086\n",
      "Epoch 167/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0088\n",
      "Epoch 168/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0086\n",
      "Epoch 169/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0085\n",
      "Epoch 170/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0092\n",
      "Epoch 171/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0083\n",
      "Epoch 172/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0082\n",
      "Epoch 173/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0085\n",
      "Epoch 174/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0084\n",
      "Epoch 175/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0082\n",
      "Epoch 176/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0081\n",
      "Epoch 177/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0082\n",
      "Epoch 178/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0085\n",
      "Epoch 179/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0089\n",
      "Epoch 180/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0082\n",
      "Epoch 181/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0080\n",
      "Epoch 182/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0083\n",
      "Epoch 183/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0080\n",
      "Epoch 184/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0080\n",
      "Epoch 185/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0083\n",
      "Epoch 186/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0080\n",
      "Epoch 187/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0080\n",
      "Epoch 188/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0079\n",
      "Epoch 189/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0080\n",
      "Epoch 190/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0082\n",
      "Epoch 191/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0080\n",
      "Epoch 192/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0079\n",
      "Epoch 193/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0080\n",
      "Epoch 194/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0080\n",
      "Epoch 195/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0078\n",
      "Epoch 196/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0079\n",
      "Epoch 197/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0079\n",
      "Epoch 198/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0080\n",
      "Epoch 199/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0082\n",
      "Epoch 200/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0077\n",
      "Epoch 201/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0078\n",
      "Epoch 202/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0081\n",
      "Epoch 203/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0077\n",
      "Epoch 204/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0076\n",
      "Epoch 205/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0083\n",
      "Epoch 206/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0079\n",
      "Epoch 207/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0078\n",
      "Epoch 208/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0078\n",
      "Epoch 209/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0077\n",
      "Epoch 210/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0076\n",
      "Epoch 211/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0075\n",
      "Epoch 212/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0076\n",
      "Epoch 213/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0075\n",
      "Epoch 214/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0075\n",
      "Epoch 215/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0079\n",
      "Epoch 216/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0081\n",
      "Epoch 217/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0076\n",
      "Epoch 218/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0076\n",
      "Epoch 219/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0091\n",
      "Epoch 220/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0076\n",
      "Epoch 221/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0075\n",
      "Epoch 222/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0077\n",
      "Epoch 223/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0077\n",
      "Epoch 224/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0076\n",
      "Epoch 225/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0075\n",
      "Epoch 226/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0077\n",
      "Epoch 227/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0076\n",
      "Epoch 228/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0076\n",
      "Epoch 229/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0075\n",
      "Epoch 230/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0078\n",
      "Epoch 231/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0076\n",
      "Epoch 232/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0076\n",
      "Epoch 233/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0077\n",
      "Epoch 234/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0074\n",
      "Epoch 235/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0076\n",
      "Epoch 236/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0076\n",
      "Epoch 237/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0095\n",
      "Epoch 238/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0077\n",
      "Epoch 239/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0075\n",
      "Epoch 240/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0076\n",
      "Epoch 241/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0079\n",
      "Epoch 242/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0075\n",
      "Epoch 243/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 244/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0075\n",
      "Epoch 245/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0078\n",
      "Epoch 246/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0074\n",
      "Epoch 247/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0075\n",
      "Epoch 248/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0074\n",
      "Epoch 249/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0074\n",
      "Epoch 250/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0076\n",
      "Epoch 251/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0074\n",
      "Epoch 252/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0077\n",
      "Epoch 253/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0075\n",
      "Epoch 254/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0077\n",
      "Epoch 255/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0073\n",
      "Epoch 256/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0077\n",
      "Epoch 257/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0077\n",
      "Epoch 258/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0074\n",
      "Epoch 259/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0079\n",
      "Epoch 260/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0075\n",
      "Epoch 261/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0077\n",
      "Epoch 262/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0077\n",
      "Epoch 263/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0076\n",
      "Epoch 264/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0076\n",
      "Epoch 265/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0075\n",
      "Epoch 266/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0078\n",
      "Epoch 267/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0074\n",
      "Epoch 268/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0081\n",
      "Epoch 269/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0075\n",
      "Epoch 270/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0074\n",
      "Epoch 271/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0077\n",
      "Epoch 272/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0074\n",
      "Epoch 273/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0074\n",
      "Epoch 274/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0078\n",
      "Epoch 275/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0074\n",
      "Epoch 276/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0077\n",
      "Epoch 277/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0076\n",
      "Epoch 278/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0075\n",
      "Epoch 279/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0075\n",
      "Epoch 280/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0075\n",
      "Epoch 281/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0074\n",
      "Epoch 282/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0074\n",
      "Epoch 283/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0073\n",
      "Epoch 284/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0073\n",
      "Epoch 285/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0080\n",
      "Epoch 286/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0073\n",
      "Epoch 287/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0076\n",
      "Epoch 288/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0073\n",
      "Epoch 289/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0073\n",
      "Epoch 290/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0079\n",
      "Epoch 291/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0072\n",
      "Epoch 292/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0082\n",
      "Epoch 293/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0073\n",
      "Epoch 294/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0078\n",
      "Epoch 295/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0073\n",
      "Epoch 296/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0072\n",
      "Epoch 297/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0078\n",
      "Epoch 298/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0072\n",
      "Epoch 299/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0073\n",
      "Epoch 300/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0073\n",
      "Epoch 301/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0074\n",
      "Epoch 302/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0082\n",
      "Epoch 303/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0072\n",
      "Epoch 304/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0076\n",
      "Epoch 305/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0073\n",
      "Epoch 306/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0072\n",
      "Epoch 307/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0077\n",
      "Epoch 308/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0073\n",
      "Epoch 309/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0080\n",
      "Epoch 310/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0074\n",
      "Epoch 311/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0071\n",
      "Epoch 312/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0071\n",
      "Epoch 313/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0073\n",
      "Epoch 314/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0076\n",
      "Epoch 315/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0077\n",
      "Epoch 316/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0072\n",
      "Epoch 317/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0071\n",
      "Epoch 318/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0072\n",
      "Epoch 319/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0076\n",
      "Epoch 320/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0074\n",
      "Epoch 321/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0074\n",
      "Epoch 322/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0073\n",
      "Epoch 323/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0075\n",
      "Epoch 324/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0072\n",
      "Epoch 325/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0074\n",
      "Epoch 326/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0073\n",
      "Epoch 327/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0071\n",
      "Epoch 328/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0074\n",
      "Epoch 329/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0077\n",
      "Epoch 330/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0073\n",
      "Epoch 331/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0081\n",
      "Epoch 332/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0081\n",
      "Epoch 333/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0072\n",
      "Epoch 334/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0071\n",
      "Epoch 335/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0074\n",
      "Epoch 336/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0071\n",
      "Epoch 337/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0074\n",
      "Epoch 338/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0075\n",
      "Epoch 339/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0072\n",
      "Epoch 340/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0074\n",
      "Epoch 341/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0075\n",
      "Epoch 342/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0072\n",
      "Epoch 343/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0074\n",
      "Epoch 344/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0072\n",
      "Epoch 345/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0071\n",
      "Epoch 346/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0076\n",
      "Epoch 347/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0075\n",
      "Epoch 348/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0071\n",
      "Epoch 349/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0070\n",
      "Epoch 350/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0070\n",
      "Epoch 351/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0073\n",
      "Epoch 352/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0071\n",
      "Epoch 353/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0070\n",
      "Epoch 354/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0079\n",
      "Epoch 355/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0074\n",
      "Epoch 356/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0088\n",
      "Epoch 357/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0071\n",
      "Epoch 358/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0072\n",
      "Epoch 359/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0076\n",
      "Epoch 360/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0073\n",
      "Epoch 361/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0075\n",
      "Epoch 362/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0073\n",
      "Epoch 363/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0072\n",
      "Epoch 364/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0073\n",
      "Epoch 365/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0074\n",
      "Epoch 366/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0073\n",
      "Epoch 367/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0072\n",
      "Epoch 368/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0071\n",
      "Epoch 369/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0071\n",
      "Epoch 370/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0071\n",
      "Epoch 371/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0081\n",
      "Epoch 372/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0075\n",
      "Epoch 373/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0073\n",
      "Epoch 374/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0071\n",
      "Epoch 375/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0073\n",
      "Epoch 376/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0072\n",
      "Epoch 377/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0072\n",
      "Epoch 378/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0074\n",
      "Epoch 379/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0073\n",
      "Epoch 380/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0071\n",
      "Epoch 381/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0071\n",
      "Epoch 382/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0071\n",
      "Epoch 383/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0071\n",
      "Epoch 384/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0073\n",
      "Epoch 385/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0078\n",
      "Epoch 386/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0069\n",
      "Epoch 387/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0082\n",
      "Epoch 388/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0069\n",
      "Epoch 389/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0070\n",
      "Epoch 390/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0071\n",
      "Epoch 391/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0073\n",
      "Epoch 392/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0071\n",
      "Epoch 393/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0070\n",
      "Epoch 394/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0073\n",
      "Epoch 395/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0071\n",
      "Epoch 396/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0073\n",
      "Epoch 397/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0070\n",
      "Epoch 398/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0070\n",
      "Epoch 399/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0071\n",
      "Epoch 400/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0071\n",
      "Epoch 401/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 402/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0070\n",
      "Epoch 403/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0080\n",
      "Epoch 404/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0072\n",
      "Epoch 405/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0071\n",
      "Epoch 406/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0069\n",
      "Epoch 407/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0073\n",
      "Epoch 408/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0080\n",
      "Epoch 409/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0069\n",
      "Epoch 410/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0074\n",
      "Epoch 411/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0069\n",
      "Epoch 412/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0071\n",
      "Epoch 413/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0071\n",
      "Epoch 414/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0072\n",
      "Epoch 415/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0078\n",
      "Epoch 416/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0075\n",
      "Epoch 417/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0075\n",
      "Epoch 418/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0072\n",
      "Epoch 419/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0070\n",
      "Epoch 420/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0069\n",
      "Epoch 421/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0071\n",
      "Epoch 422/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0075\n",
      "Epoch 423/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0071\n",
      "Epoch 424/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0072\n",
      "Epoch 425/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0073\n",
      "Epoch 426/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0072\n",
      "Epoch 427/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0075\n",
      "Epoch 428/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0072\n",
      "Epoch 429/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0070\n",
      "Epoch 430/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0070\n",
      "Epoch 431/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0072\n",
      "Epoch 432/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0070\n",
      "Epoch 433/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0070\n",
      "Epoch 434/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0072\n",
      "Epoch 435/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0068\n",
      "Epoch 436/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0070\n",
      "Epoch 437/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0077\n",
      "Epoch 438/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0070\n",
      "Epoch 439/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0079\n",
      "Epoch 440/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0071\n",
      "Epoch 441/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0071\n",
      "Epoch 442/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0071\n",
      "Epoch 443/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0070\n",
      "Epoch 444/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0070\n",
      "Epoch 445/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0079\n",
      "Epoch 446/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0075\n",
      "Epoch 447/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0072\n",
      "Epoch 448/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0069\n",
      "Epoch 449/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0071\n",
      "Epoch 450/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0073\n",
      "Epoch 451/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0070\n",
      "Epoch 452/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0069\n",
      "Epoch 453/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0073\n",
      "Epoch 454/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0071\n",
      "Epoch 455/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0070\n",
      "Epoch 456/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0071\n",
      "Epoch 457/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0071\n",
      "Epoch 458/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0071\n",
      "Epoch 459/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0071\n",
      "Epoch 460/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0071\n",
      "Epoch 461/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0071\n",
      "Epoch 462/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0071\n",
      "Epoch 463/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0071\n",
      "Epoch 464/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0071\n",
      "Epoch 465/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0070\n",
      "Epoch 466/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0069\n",
      "Epoch 467/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0068\n",
      "Epoch 468/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0068\n",
      "Epoch 469/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0074\n",
      "Epoch 470/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0068\n",
      "Epoch 471/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0070\n",
      "Epoch 472/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0075\n",
      "Epoch 473/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0068\n",
      "Epoch 474/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0071\n",
      "Epoch 475/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 476/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0080\n",
      "Epoch 477/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0072\n",
      "Epoch 478/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0070\n",
      "Epoch 479/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0070\n",
      "Epoch 480/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0068\n",
      "Epoch 481/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0068\n",
      "Epoch 482/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0068\n",
      "Epoch 483/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0076\n",
      "Epoch 484/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0071\n",
      "Epoch 485/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0071\n",
      "Epoch 486/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0070\n",
      "Epoch 487/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0077\n",
      "Epoch 488/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0105\n",
      "Epoch 489/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0074\n",
      "Epoch 490/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0070\n",
      "Epoch 491/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0073\n",
      "Epoch 492/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0072\n",
      "Epoch 493/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 494/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0072\n",
      "Epoch 495/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0076\n",
      "Epoch 496/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0072\n",
      "Epoch 497/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0071\n",
      "Epoch 498/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0071\n",
      "Epoch 499/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0069\n",
      "Epoch 500/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0070\n",
      "Epoch 501/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0067\n",
      "Epoch 502/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0080\n",
      "Epoch 503/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0079\n",
      "Epoch 504/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0070\n",
      "Epoch 505/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0073\n",
      "Epoch 506/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 507/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 508/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0076\n",
      "Epoch 509/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0073\n",
      "Epoch 510/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 511/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0071\n",
      "Epoch 512/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0068\n",
      "Epoch 513/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 514/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0070\n",
      "Epoch 515/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0070\n",
      "Epoch 516/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 517/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0071\n",
      "Epoch 518/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0069\n",
      "Epoch 519/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0074\n",
      "Epoch 520/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0070\n",
      "Epoch 521/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0073\n",
      "Epoch 522/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 523/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0069\n",
      "Epoch 524/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0071\n",
      "Epoch 525/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0072\n",
      "Epoch 526/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0071\n",
      "Epoch 527/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 528/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0068\n",
      "Epoch 529/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0069\n",
      "Epoch 530/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0076\n",
      "Epoch 531/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0070\n",
      "Epoch 532/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0070\n",
      "Epoch 533/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0068\n",
      "Epoch 534/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0074\n",
      "Epoch 535/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0074\n",
      "Epoch 536/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0076\n",
      "Epoch 537/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0071\n",
      "Epoch 538/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0070\n",
      "Epoch 539/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0072\n",
      "Epoch 540/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0070\n",
      "Epoch 541/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0071\n",
      "Epoch 542/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0068\n",
      "Epoch 543/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0075\n",
      "Epoch 544/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0072\n",
      "Epoch 545/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0073\n",
      "Epoch 546/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0069\n",
      "Epoch 547/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0071\n",
      "Epoch 548/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0071\n",
      "Epoch 549/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0073\n",
      "Epoch 550/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0071\n",
      "Epoch 551/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0072\n",
      "Epoch 552/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0068\n",
      "Epoch 553/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0071\n",
      "Epoch 554/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0073\n",
      "Epoch 555/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0073\n",
      "Epoch 556/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 557/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0075\n",
      "Epoch 558/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0069\n",
      "Epoch 559/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0072\n",
      "Epoch 560/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0070\n",
      "Epoch 561/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 562/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0068\n",
      "Epoch 563/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0068\n",
      "Epoch 564/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0069\n",
      "Epoch 565/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0070\n",
      "Epoch 566/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0081\n",
      "Epoch 567/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0070\n",
      "Epoch 568/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0068\n",
      "Epoch 569/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0070\n",
      "Epoch 570/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0070\n",
      "Epoch 571/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0069\n",
      "Epoch 572/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0070\n",
      "Epoch 573/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0069\n",
      "Epoch 574/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0070\n",
      "Epoch 575/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0069\n",
      "Epoch 576/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0084\n",
      "Epoch 577/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0070\n",
      "Epoch 578/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0070\n",
      "Epoch 579/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0075\n",
      "Epoch 580/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0067\n",
      "Epoch 581/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0067\n",
      "Epoch 582/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0069\n",
      "Epoch 583/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0075\n",
      "Epoch 584/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0068\n",
      "Epoch 585/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0068\n",
      "Epoch 586/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 587/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 588/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 589/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0071\n",
      "Epoch 590/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0068\n",
      "Epoch 591/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0068\n",
      "Epoch 592/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0070\n",
      "Epoch 593/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0069\n",
      "Epoch 594/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0068\n",
      "Epoch 595/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 596/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0066\n",
      "Epoch 597/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0075\n",
      "Epoch 598/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0087 - val_loss: 0.0083\n",
      "Epoch 599/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0068\n",
      "Epoch 600/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0069\n",
      "Epoch 601/10000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0090 - val_loss: 0.0069\n",
      "Epoch 602/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0068\n",
      "Epoch 603/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0070\n",
      "Epoch 604/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 605/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0076\n",
      "Epoch 606/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 607/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0068\n",
      "Epoch 608/10000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0068\n",
      "Epoch 609/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0072\n",
      "Epoch 610/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0079\n",
      "Epoch 611/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0067\n",
      "Epoch 612/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0073\n",
      "Epoch 613/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 614/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0076\n",
      "Epoch 615/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0068\n",
      "Epoch 616/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0075\n",
      "Epoch 617/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0068\n",
      "Epoch 618/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 619/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0077\n",
      "Epoch 620/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0070\n",
      "Epoch 621/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0068\n",
      "Epoch 622/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0069\n",
      "Epoch 623/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0068\n",
      "Epoch 624/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0077\n",
      "Epoch 625/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0068\n",
      "Epoch 626/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0069\n",
      "Epoch 627/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0069\n",
      "Epoch 628/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 629/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 630/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0067\n",
      "Epoch 631/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0070\n",
      "Epoch 632/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0070\n",
      "Epoch 633/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 634/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0068\n",
      "Epoch 635/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0075\n",
      "Epoch 636/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0068\n",
      "Epoch 637/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0074\n",
      "Epoch 638/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 639/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0068\n",
      "Epoch 640/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 641/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0071\n",
      "Epoch 642/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0068\n",
      "Epoch 643/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0069\n",
      "Epoch 644/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0068\n",
      "Epoch 645/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 646/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0069\n",
      "Epoch 647/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0074\n",
      "Epoch 648/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0069\n",
      "Epoch 649/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0072\n",
      "Epoch 650/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0071\n",
      "Epoch 651/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0068\n",
      "Epoch 652/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0073\n",
      "Epoch 653/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0070\n",
      "Epoch 654/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0070\n",
      "Epoch 655/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0069\n",
      "Epoch 656/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0068\n",
      "Epoch 657/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0070\n",
      "Epoch 658/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0078\n",
      "Epoch 659/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0067\n",
      "Epoch 660/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0070\n",
      "Epoch 661/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0069\n",
      "Epoch 662/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0070\n",
      "Epoch 663/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0068\n",
      "Epoch 664/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0070\n",
      "Epoch 665/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0068\n",
      "Epoch 666/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0068\n",
      "Epoch 667/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0069\n",
      "Epoch 668/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0066\n",
      "Epoch 669/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0069\n",
      "Epoch 670/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 671/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0067\n",
      "Epoch 672/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0073\n",
      "Epoch 673/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0069\n",
      "Epoch 674/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0076\n",
      "Epoch 675/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 676/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0068\n",
      "Epoch 677/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0066\n",
      "Epoch 678/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0071\n",
      "Epoch 679/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 680/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 681/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0068\n",
      "Epoch 682/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0070\n",
      "Epoch 683/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0069\n",
      "Epoch 684/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 685/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0074\n",
      "Epoch 686/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0066\n",
      "Epoch 687/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0072\n",
      "Epoch 688/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0067\n",
      "Epoch 689/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0066\n",
      "Epoch 690/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 691/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0068\n",
      "Epoch 692/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0066\n",
      "Epoch 693/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0068\n",
      "Epoch 694/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0070\n",
      "Epoch 695/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0082\n",
      "Epoch 696/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0071\n",
      "Epoch 697/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 698/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 699/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 700/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0068\n",
      "Epoch 701/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0070\n",
      "Epoch 702/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0068\n",
      "Epoch 703/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0071\n",
      "Epoch 704/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 705/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0067\n",
      "Epoch 706/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0068\n",
      "Epoch 707/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0067\n",
      "Epoch 708/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 709/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0071\n",
      "Epoch 710/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 711/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0070\n",
      "Epoch 712/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0066\n",
      "Epoch 713/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0069\n",
      "Epoch 714/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0066\n",
      "Epoch 715/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0065\n",
      "Epoch 716/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0068\n",
      "Epoch 717/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0067\n",
      "Epoch 718/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 719/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0068\n",
      "Epoch 720/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0068\n",
      "Epoch 721/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0066\n",
      "Epoch 722/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0069\n",
      "Epoch 723/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0066\n",
      "Epoch 724/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0068\n",
      "Epoch 725/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0070\n",
      "Epoch 726/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0071\n",
      "Epoch 727/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0069\n",
      "Epoch 728/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0073\n",
      "Epoch 729/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0068\n",
      "Epoch 730/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 731/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0070\n",
      "Epoch 732/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 733/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0070\n",
      "Epoch 734/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0084\n",
      "Epoch 735/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0068\n",
      "Epoch 736/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0067\n",
      "Epoch 737/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0069\n",
      "Epoch 738/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0072\n",
      "Epoch 739/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0068\n",
      "Epoch 740/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0067\n",
      "Epoch 741/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 742/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0070\n",
      "Epoch 743/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0071\n",
      "Epoch 744/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0067\n",
      "Epoch 745/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 746/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0073\n",
      "Epoch 747/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0065\n",
      "Epoch 748/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0071\n",
      "Epoch 749/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0070\n",
      "Epoch 750/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0068\n",
      "Epoch 751/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0070\n",
      "Epoch 752/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0069\n",
      "Epoch 753/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0071\n",
      "Epoch 754/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0073\n",
      "Epoch 755/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0074\n",
      "Epoch 756/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0071\n",
      "Epoch 757/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0082\n",
      "Epoch 758/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0070\n",
      "Epoch 759/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0069\n",
      "Epoch 760/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 761/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0070\n",
      "Epoch 762/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0069\n",
      "Epoch 763/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0068\n",
      "Epoch 764/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0067\n",
      "Epoch 765/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0075\n",
      "Epoch 766/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0071\n",
      "Epoch 767/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 768/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0067\n",
      "Epoch 769/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 770/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0066\n",
      "Epoch 771/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0072\n",
      "Epoch 772/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0072\n",
      "Epoch 773/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0068\n",
      "Epoch 774/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0065\n",
      "Epoch 775/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0068\n",
      "Epoch 776/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 777/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0067\n",
      "Epoch 778/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0067\n",
      "Epoch 779/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 780/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0067\n",
      "Epoch 781/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0089\n",
      "Epoch 782/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0069\n",
      "Epoch 783/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0068\n",
      "Epoch 784/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0069\n",
      "Epoch 785/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0069\n",
      "Epoch 786/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0067\n",
      "Epoch 787/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0067\n",
      "Epoch 788/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0069\n",
      "Epoch 789/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 790/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0078\n",
      "Epoch 791/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0071\n",
      "Epoch 792/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0069\n",
      "Epoch 793/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 794/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0065\n",
      "Epoch 795/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0067\n",
      "Epoch 796/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0074\n",
      "Epoch 797/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0068\n",
      "Epoch 798/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 799/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 800/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0067\n",
      "Epoch 801/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0067\n",
      "Epoch 802/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0079\n",
      "Epoch 803/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0068\n",
      "Epoch 804/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0077\n",
      "Epoch 805/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0069\n",
      "Epoch 806/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0068\n",
      "Epoch 807/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0067\n",
      "Epoch 808/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 809/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0068\n",
      "Epoch 810/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0067\n",
      "Epoch 811/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 812/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0067\n",
      "Epoch 813/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 814/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0078\n",
      "Epoch 815/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0070\n",
      "Epoch 00815: early stopping\n",
      "Epoch 1/10000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.7325 - val_loss: 0.3996\n",
      "Epoch 2/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2589 - val_loss: 0.0722\n",
      "Epoch 3/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1044 - val_loss: 0.0379\n",
      "Epoch 4/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0346\n",
      "Epoch 5/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0813 - val_loss: 0.0330\n",
      "Epoch 6/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0773 - val_loss: 0.0333\n",
      "Epoch 7/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0744 - val_loss: 0.0311\n",
      "Epoch 8/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0706 - val_loss: 0.0296\n",
      "Epoch 9/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0663 - val_loss: 0.0285\n",
      "Epoch 10/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0623 - val_loss: 0.0265\n",
      "Epoch 11/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0594 - val_loss: 0.0234\n",
      "Epoch 12/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0548 - val_loss: 0.0218\n",
      "Epoch 13/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0523 - val_loss: 0.0216\n",
      "Epoch 14/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0194\n",
      "Epoch 15/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0472 - val_loss: 0.0190\n",
      "Epoch 16/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0446 - val_loss: 0.0180\n",
      "Epoch 17/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0439 - val_loss: 0.0184\n",
      "Epoch 18/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0414 - val_loss: 0.0178\n",
      "Epoch 19/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.0174\n",
      "Epoch 20/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0391 - val_loss: 0.0181\n",
      "Epoch 21/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0377 - val_loss: 0.0184\n",
      "Epoch 22/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0354 - val_loss: 0.0171\n",
      "Epoch 23/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0353 - val_loss: 0.0171\n",
      "Epoch 24/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0346 - val_loss: 0.0173\n",
      "Epoch 25/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0335 - val_loss: 0.0177\n",
      "Epoch 26/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0323 - val_loss: 0.0170\n",
      "Epoch 27/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0310 - val_loss: 0.0168\n",
      "Epoch 28/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0308 - val_loss: 0.0171\n",
      "Epoch 29/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0310 - val_loss: 0.0168\n",
      "Epoch 30/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0296 - val_loss: 0.0168\n",
      "Epoch 31/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0289 - val_loss: 0.0171\n",
      "Epoch 32/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0297 - val_loss: 0.0173\n",
      "Epoch 33/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0285 - val_loss: 0.0172\n",
      "Epoch 34/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0277 - val_loss: 0.0163\n",
      "Epoch 35/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0277 - val_loss: 0.0170\n",
      "Epoch 36/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0274 - val_loss: 0.0166\n",
      "Epoch 37/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0164\n",
      "Epoch 38/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0267 - val_loss: 0.0163\n",
      "Epoch 39/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0263 - val_loss: 0.0164\n",
      "Epoch 40/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0261 - val_loss: 0.0163\n",
      "Epoch 41/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0261 - val_loss: 0.0161\n",
      "Epoch 42/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0256 - val_loss: 0.0163\n",
      "Epoch 43/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.0166\n",
      "Epoch 44/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0257 - val_loss: 0.0164\n",
      "Epoch 45/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0249 - val_loss: 0.0165\n",
      "Epoch 46/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0253 - val_loss: 0.0163\n",
      "Epoch 47/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0249 - val_loss: 0.0160\n",
      "Epoch 48/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0246 - val_loss: 0.0162\n",
      "Epoch 49/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0246 - val_loss: 0.0176\n",
      "Epoch 50/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0245 - val_loss: 0.0162\n",
      "Epoch 51/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0243 - val_loss: 0.0163\n",
      "Epoch 52/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.0164\n",
      "Epoch 53/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.0160\n",
      "Epoch 54/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.0160\n",
      "Epoch 55/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0237 - val_loss: 0.0158\n",
      "Epoch 56/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.0159\n",
      "Epoch 57/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0239 - val_loss: 0.0169\n",
      "Epoch 58/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.0170\n",
      "Epoch 59/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.0160\n",
      "Epoch 60/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.0160\n",
      "Epoch 61/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0233 - val_loss: 0.0159\n",
      "Epoch 62/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.0158\n",
      "Epoch 63/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.0159\n",
      "Epoch 64/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.0164\n",
      "Epoch 65/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0229 - val_loss: 0.0160\n",
      "Epoch 66/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0228 - val_loss: 0.0169\n",
      "Epoch 67/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0234 - val_loss: 0.0158\n",
      "Epoch 68/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.0158\n",
      "Epoch 69/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.0163\n",
      "Epoch 70/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.0158\n",
      "Epoch 71/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.0159\n",
      "Epoch 72/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.0158\n",
      "Epoch 73/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0221 - val_loss: 0.0161\n",
      "Epoch 74/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.0157\n",
      "Epoch 75/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.0157\n",
      "Epoch 76/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.0162\n",
      "Epoch 77/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0221 - val_loss: 0.0158\n",
      "Epoch 78/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0220 - val_loss: 0.0157\n",
      "Epoch 79/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0217 - val_loss: 0.0158\n",
      "Epoch 80/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0216 - val_loss: 0.0158\n",
      "Epoch 81/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0217 - val_loss: 0.0158\n",
      "Epoch 82/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0212 - val_loss: 0.0158\n",
      "Epoch 83/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0218 - val_loss: 0.0157\n",
      "Epoch 84/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0217 - val_loss: 0.0158\n",
      "Epoch 85/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0213 - val_loss: 0.0157\n",
      "Epoch 86/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.0161\n",
      "Epoch 87/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0157\n",
      "Epoch 88/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0157\n",
      "Epoch 89/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0210 - val_loss: 0.0159\n",
      "Epoch 90/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0157\n",
      "Epoch 91/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0205 - val_loss: 0.0158\n",
      "Epoch 92/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0157\n",
      "Epoch 93/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0157\n",
      "Epoch 94/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0207 - val_loss: 0.0158\n",
      "Epoch 95/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0206 - val_loss: 0.0159\n",
      "Epoch 96/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0160\n",
      "Epoch 97/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0201 - val_loss: 0.0158\n",
      "Epoch 98/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0203 - val_loss: 0.0157\n",
      "Epoch 99/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0158\n",
      "Epoch 100/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0154\n",
      "Epoch 101/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0200 - val_loss: 0.0156\n",
      "Epoch 102/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0202 - val_loss: 0.0157\n",
      "Epoch 103/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0155\n",
      "Epoch 104/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0156\n",
      "Epoch 105/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0155\n",
      "Epoch 106/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0199 - val_loss: 0.0154\n",
      "Epoch 107/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0156\n",
      "Epoch 108/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.0162\n",
      "Epoch 109/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0157\n",
      "Epoch 110/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0155\n",
      "Epoch 111/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0158\n",
      "Epoch 112/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0199 - val_loss: 0.0156\n",
      "Epoch 113/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0153\n",
      "Epoch 114/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0156\n",
      "Epoch 115/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0195 - val_loss: 0.0155\n",
      "Epoch 116/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0194 - val_loss: 0.0156\n",
      "Epoch 117/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0160\n",
      "Epoch 118/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0193 - val_loss: 0.0157\n",
      "Epoch 119/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0154\n",
      "Epoch 120/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0156\n",
      "Epoch 121/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0187 - val_loss: 0.0156\n",
      "Epoch 122/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0155\n",
      "Epoch 123/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0153\n",
      "Epoch 124/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0159\n",
      "Epoch 125/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0156\n",
      "Epoch 126/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0155\n",
      "Epoch 127/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0153\n",
      "Epoch 128/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0152\n",
      "Epoch 129/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0152\n",
      "Epoch 130/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0152\n",
      "Epoch 131/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0154\n",
      "Epoch 132/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0153\n",
      "Epoch 133/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0152\n",
      "Epoch 134/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0152\n",
      "Epoch 135/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0155\n",
      "Epoch 136/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0154\n",
      "Epoch 137/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0152\n",
      "Epoch 138/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0152\n",
      "Epoch 139/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0152\n",
      "Epoch 140/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0156\n",
      "Epoch 141/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0150\n",
      "Epoch 142/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0174 - val_loss: 0.0149\n",
      "Epoch 143/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0147\n",
      "Epoch 144/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0153\n",
      "Epoch 145/10000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0171 - val_loss: 0.0153\n",
      "Epoch 146/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0140\n",
      "Epoch 147/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0137\n",
      "Epoch 148/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0132\n",
      "Epoch 149/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0130\n",
      "Epoch 150/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0131\n",
      "Epoch 151/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0128\n",
      "Epoch 152/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0124\n",
      "Epoch 153/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0126\n",
      "Epoch 154/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0133\n",
      "Epoch 155/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0131\n",
      "Epoch 156/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0127\n",
      "Epoch 157/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0124\n",
      "Epoch 158/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0124\n",
      "Epoch 159/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0123\n",
      "Epoch 160/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0124\n",
      "Epoch 161/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0129\n",
      "Epoch 162/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0124\n",
      "Epoch 163/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0124\n",
      "Epoch 164/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0126\n",
      "Epoch 165/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0123\n",
      "Epoch 166/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0119\n",
      "Epoch 167/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0119\n",
      "Epoch 168/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0118\n",
      "Epoch 169/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0117\n",
      "Epoch 170/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.0116\n",
      "Epoch 171/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0117\n",
      "Epoch 172/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0117\n",
      "Epoch 173/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0113\n",
      "Epoch 174/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0113\n",
      "Epoch 175/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0117\n",
      "Epoch 176/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0106\n",
      "Epoch 177/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0115\n",
      "Epoch 178/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.0109\n",
      "Epoch 179/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.0106\n",
      "Epoch 180/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.0109\n",
      "Epoch 181/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.0101\n",
      "Epoch 182/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.0107\n",
      "Epoch 183/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0101\n",
      "Epoch 184/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.0097\n",
      "Epoch 185/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0108\n",
      "Epoch 186/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0103\n",
      "Epoch 187/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0101\n",
      "Epoch 188/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0097\n",
      "Epoch 189/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0100\n",
      "Epoch 190/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0100\n",
      "Epoch 191/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0097\n",
      "Epoch 192/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0096\n",
      "Epoch 193/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0096\n",
      "Epoch 194/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0095\n",
      "Epoch 195/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0100\n",
      "Epoch 196/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0097\n",
      "Epoch 197/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0100\n",
      "Epoch 198/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0095\n",
      "Epoch 199/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0093\n",
      "Epoch 200/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0094\n",
      "Epoch 201/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0094\n",
      "Epoch 202/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.0094\n",
      "Epoch 203/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.0094\n",
      "Epoch 204/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.0093\n",
      "Epoch 205/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0093\n",
      "Epoch 206/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0093\n",
      "Epoch 207/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0092\n",
      "Epoch 208/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0094\n",
      "Epoch 209/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.0093\n",
      "Epoch 210/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0095\n",
      "Epoch 211/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0092\n",
      "Epoch 212/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0096\n",
      "Epoch 213/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0094\n",
      "Epoch 214/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0094\n",
      "Epoch 215/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0093\n",
      "Epoch 216/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0096\n",
      "Epoch 217/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0092\n",
      "Epoch 218/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0092\n",
      "Epoch 219/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0098\n",
      "Epoch 220/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0091\n",
      "Epoch 221/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0100\n",
      "Epoch 222/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.0106\n",
      "Epoch 223/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0094\n",
      "Epoch 224/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0091\n",
      "Epoch 225/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0093\n",
      "Epoch 226/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0093\n",
      "Epoch 227/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0091\n",
      "Epoch 228/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0092\n",
      "Epoch 229/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0099\n",
      "Epoch 230/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0092\n",
      "Epoch 231/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0091\n",
      "Epoch 232/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0091\n",
      "Epoch 233/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0092\n",
      "Epoch 234/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0092\n",
      "Epoch 235/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0093\n",
      "Epoch 236/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0092\n",
      "Epoch 237/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0092\n",
      "Epoch 238/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0091\n",
      "Epoch 239/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0093\n",
      "Epoch 240/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0091\n",
      "Epoch 241/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0094\n",
      "Epoch 242/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0091\n",
      "Epoch 243/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0096\n",
      "Epoch 244/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0090\n",
      "Epoch 245/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0093\n",
      "Epoch 246/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 247/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0092\n",
      "Epoch 248/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0091\n",
      "Epoch 249/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0091\n",
      "Epoch 250/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0091\n",
      "Epoch 251/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0092\n",
      "Epoch 252/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0096\n",
      "Epoch 253/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.0093\n",
      "Epoch 254/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0090\n",
      "Epoch 255/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0096\n",
      "Epoch 256/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0091\n",
      "Epoch 257/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0092\n",
      "Epoch 258/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0092\n",
      "Epoch 259/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0093\n",
      "Epoch 260/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0098\n",
      "Epoch 261/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0091\n",
      "Epoch 262/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0094\n",
      "Epoch 263/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0094\n",
      "Epoch 264/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0091\n",
      "Epoch 265/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0094\n",
      "Epoch 266/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0092\n",
      "Epoch 267/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0094\n",
      "Epoch 268/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0091\n",
      "Epoch 269/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0091\n",
      "Epoch 270/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0092\n",
      "Epoch 271/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0091\n",
      "Epoch 272/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0092\n",
      "Epoch 273/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0090\n",
      "Epoch 274/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0091\n",
      "Epoch 275/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0093\n",
      "Epoch 276/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0092\n",
      "Epoch 277/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0091\n",
      "Epoch 278/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0091\n",
      "Epoch 279/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0090\n",
      "Epoch 280/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0090\n",
      "Epoch 281/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0089\n",
      "Epoch 282/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0093\n",
      "Epoch 283/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0091\n",
      "Epoch 284/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0092\n",
      "Epoch 285/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0093\n",
      "Epoch 286/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0095\n",
      "Epoch 287/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0091\n",
      "Epoch 288/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0091\n",
      "Epoch 289/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0091\n",
      "Epoch 290/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0117\n",
      "Epoch 291/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0091\n",
      "Epoch 292/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0090\n",
      "Epoch 293/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0091\n",
      "Epoch 294/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0092\n",
      "Epoch 295/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0090\n",
      "Epoch 296/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0093\n",
      "Epoch 297/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0091\n",
      "Epoch 298/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0090\n",
      "Epoch 299/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0091\n",
      "Epoch 300/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0090\n",
      "Epoch 301/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0091\n",
      "Epoch 302/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0093\n",
      "Epoch 303/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0089\n",
      "Epoch 304/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0089\n",
      "Epoch 305/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0089\n",
      "Epoch 306/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0088\n",
      "Epoch 307/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0089\n",
      "Epoch 308/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0088\n",
      "Epoch 309/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0092\n",
      "Epoch 310/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0092\n",
      "Epoch 311/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0090\n",
      "Epoch 312/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0092\n",
      "Epoch 313/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0089\n",
      "Epoch 314/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0090\n",
      "Epoch 315/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0088\n",
      "Epoch 316/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0090\n",
      "Epoch 317/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0089\n",
      "Epoch 318/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0087\n",
      "Epoch 319/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0089\n",
      "Epoch 320/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0093\n",
      "Epoch 321/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0088\n",
      "Epoch 322/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0092\n",
      "Epoch 323/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0089\n",
      "Epoch 324/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0088\n",
      "Epoch 325/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0089\n",
      "Epoch 326/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0089\n",
      "Epoch 327/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 328/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0088\n",
      "Epoch 329/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0088\n",
      "Epoch 330/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0088\n",
      "Epoch 331/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0092\n",
      "Epoch 332/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0088\n",
      "Epoch 333/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0091\n",
      "Epoch 334/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0091\n",
      "Epoch 335/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0088\n",
      "Epoch 336/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0089\n",
      "Epoch 337/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0090\n",
      "Epoch 338/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0088\n",
      "Epoch 339/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0088\n",
      "Epoch 340/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0087\n",
      "Epoch 341/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0089\n",
      "Epoch 342/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0086\n",
      "Epoch 343/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0097\n",
      "Epoch 344/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0086\n",
      "Epoch 345/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0085\n",
      "Epoch 346/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0085\n",
      "Epoch 347/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0088\n",
      "Epoch 348/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0085\n",
      "Epoch 349/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0084\n",
      "Epoch 350/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0089\n",
      "Epoch 351/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0084\n",
      "Epoch 352/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 353/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0083\n",
      "Epoch 354/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 355/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0081\n",
      "Epoch 356/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 357/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0080\n",
      "Epoch 358/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0084\n",
      "Epoch 359/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0083\n",
      "Epoch 360/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0080\n",
      "Epoch 361/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0078\n",
      "Epoch 362/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0080\n",
      "Epoch 363/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0082\n",
      "Epoch 364/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0080\n",
      "Epoch 365/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0080\n",
      "Epoch 366/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0080\n",
      "Epoch 367/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0080\n",
      "Epoch 368/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0079\n",
      "Epoch 369/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0081\n",
      "Epoch 370/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0085\n",
      "Epoch 371/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0078\n",
      "Epoch 372/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0079\n",
      "Epoch 373/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0077\n",
      "Epoch 374/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0078\n",
      "Epoch 375/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0085\n",
      "Epoch 376/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0095\n",
      "Epoch 377/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0083\n",
      "Epoch 378/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0079\n",
      "Epoch 379/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0079\n",
      "Epoch 380/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0078\n",
      "Epoch 381/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0078\n",
      "Epoch 382/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0081\n",
      "Epoch 383/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0082\n",
      "Epoch 384/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 385/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0078\n",
      "Epoch 386/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0079\n",
      "Epoch 387/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0079\n",
      "Epoch 388/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0081\n",
      "Epoch 389/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0077\n",
      "Epoch 390/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0079\n",
      "Epoch 391/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0083\n",
      "Epoch 392/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0077\n",
      "Epoch 393/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0076\n",
      "Epoch 394/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0079\n",
      "Epoch 395/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0081\n",
      "Epoch 396/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0076\n",
      "Epoch 397/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0079\n",
      "Epoch 398/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0076\n",
      "Epoch 399/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0075\n",
      "Epoch 400/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0082\n",
      "Epoch 401/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0078\n",
      "Epoch 402/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0077\n",
      "Epoch 403/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0078\n",
      "Epoch 404/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0083\n",
      "Epoch 405/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0076\n",
      "Epoch 406/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0080\n",
      "Epoch 407/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0076\n",
      "Epoch 408/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0078\n",
      "Epoch 409/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0084\n",
      "Epoch 410/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0077\n",
      "Epoch 411/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0075\n",
      "Epoch 412/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0078\n",
      "Epoch 413/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0076\n",
      "Epoch 414/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0078\n",
      "Epoch 415/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0079\n",
      "Epoch 416/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0081\n",
      "Epoch 417/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0077\n",
      "Epoch 418/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0077\n",
      "Epoch 419/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0076\n",
      "Epoch 420/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0075\n",
      "Epoch 421/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0076\n",
      "Epoch 422/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0077\n",
      "Epoch 423/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0076\n",
      "Epoch 424/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0078\n",
      "Epoch 425/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0085\n",
      "Epoch 426/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0079\n",
      "Epoch 427/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0077\n",
      "Epoch 428/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0077\n",
      "Epoch 429/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0076\n",
      "Epoch 430/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0075\n",
      "Epoch 431/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0086\n",
      "Epoch 432/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0075\n",
      "Epoch 433/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0074\n",
      "Epoch 434/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0074\n",
      "Epoch 435/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0075\n",
      "Epoch 436/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0077\n",
      "Epoch 437/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0076\n",
      "Epoch 438/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0076\n",
      "Epoch 439/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0074\n",
      "Epoch 440/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0073\n",
      "Epoch 441/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0076\n",
      "Epoch 442/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0075\n",
      "Epoch 443/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0076\n",
      "Epoch 444/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0074\n",
      "Epoch 445/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0075\n",
      "Epoch 446/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0074\n",
      "Epoch 447/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0080\n",
      "Epoch 448/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0074\n",
      "Epoch 449/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0079\n",
      "Epoch 450/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0074\n",
      "Epoch 451/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0083\n",
      "Epoch 452/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0074\n",
      "Epoch 453/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0084\n",
      "Epoch 454/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0077\n",
      "Epoch 455/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0076\n",
      "Epoch 456/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0074\n",
      "Epoch 457/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0074\n",
      "Epoch 458/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0074\n",
      "Epoch 459/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0080\n",
      "Epoch 460/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0085\n",
      "Epoch 461/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0074\n",
      "Epoch 462/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0076\n",
      "Epoch 463/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0081\n",
      "Epoch 464/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0078\n",
      "Epoch 465/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0078\n",
      "Epoch 466/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0077\n",
      "Epoch 467/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0077\n",
      "Epoch 468/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0074\n",
      "Epoch 469/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0074\n",
      "Epoch 470/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0087\n",
      "Epoch 471/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0076\n",
      "Epoch 472/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0079\n",
      "Epoch 473/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0074\n",
      "Epoch 474/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0078\n",
      "Epoch 475/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0080\n",
      "Epoch 476/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0081\n",
      "Epoch 477/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0078\n",
      "Epoch 478/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0076\n",
      "Epoch 479/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0077\n",
      "Epoch 480/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0076\n",
      "Epoch 481/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0074\n",
      "Epoch 482/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0077\n",
      "Epoch 483/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0074\n",
      "Epoch 484/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0074\n",
      "Epoch 485/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0074\n",
      "Epoch 486/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0076\n",
      "Epoch 487/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0073\n",
      "Epoch 488/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0074\n",
      "Epoch 489/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0074\n",
      "Epoch 490/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0077\n",
      "Epoch 491/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0080\n",
      "Epoch 492/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0073\n",
      "Epoch 493/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0072\n",
      "Epoch 494/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0074\n",
      "Epoch 495/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0081\n",
      "Epoch 496/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0083\n",
      "Epoch 497/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0078\n",
      "Epoch 498/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0074\n",
      "Epoch 499/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0076\n",
      "Epoch 500/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0079\n",
      "Epoch 501/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0089\n",
      "Epoch 502/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0087\n",
      "Epoch 503/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0075\n",
      "Epoch 504/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0074\n",
      "Epoch 505/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0087\n",
      "Epoch 506/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0075\n",
      "Epoch 507/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0074\n",
      "Epoch 508/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0072\n",
      "Epoch 509/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0073\n",
      "Epoch 510/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0074\n",
      "Epoch 511/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0076\n",
      "Epoch 512/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0076\n",
      "Epoch 513/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0071\n",
      "Epoch 514/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0078\n",
      "Epoch 515/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0081\n",
      "Epoch 516/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0081\n",
      "Epoch 517/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0072\n",
      "Epoch 518/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0075\n",
      "Epoch 519/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0072\n",
      "Epoch 520/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0076\n",
      "Epoch 521/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0072\n",
      "Epoch 522/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0077\n",
      "Epoch 523/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0078\n",
      "Epoch 524/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0075\n",
      "Epoch 525/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0075\n",
      "Epoch 526/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0074\n",
      "Epoch 527/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0073\n",
      "Epoch 528/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0073\n",
      "Epoch 529/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0098\n",
      "Epoch 530/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0075\n",
      "Epoch 531/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0074\n",
      "Epoch 532/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0085\n",
      "Epoch 533/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0077\n",
      "Epoch 534/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0074\n",
      "Epoch 535/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0072\n",
      "Epoch 536/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0073\n",
      "Epoch 537/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0072\n",
      "Epoch 538/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0072\n",
      "Epoch 539/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0072\n",
      "Epoch 540/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0074\n",
      "Epoch 541/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0077\n",
      "Epoch 542/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0076\n",
      "Epoch 543/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0071\n",
      "Epoch 544/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0072\n",
      "Epoch 545/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0085\n",
      "Epoch 546/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0073\n",
      "Epoch 547/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0073\n",
      "Epoch 548/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0071\n",
      "Epoch 549/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0074\n",
      "Epoch 550/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0074\n",
      "Epoch 551/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0091\n",
      "Epoch 552/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0073\n",
      "Epoch 553/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0070\n",
      "Epoch 554/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0072\n",
      "Epoch 555/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0073\n",
      "Epoch 556/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0075\n",
      "Epoch 557/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0080\n",
      "Epoch 558/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0072\n",
      "Epoch 559/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0072\n",
      "Epoch 560/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0071\n",
      "Epoch 561/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0072\n",
      "Epoch 562/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0072\n",
      "Epoch 563/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0072\n",
      "Epoch 564/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0072\n",
      "Epoch 565/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0074\n",
      "Epoch 566/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0074\n",
      "Epoch 567/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0071\n",
      "Epoch 568/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0070\n",
      "Epoch 569/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0075\n",
      "Epoch 570/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0074\n",
      "Epoch 571/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0072\n",
      "Epoch 572/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0077\n",
      "Epoch 573/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0070\n",
      "Epoch 574/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0070\n",
      "Epoch 575/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0071\n",
      "Epoch 576/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0070\n",
      "Epoch 577/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0070\n",
      "Epoch 578/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0071\n",
      "Epoch 579/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0070\n",
      "Epoch 580/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0070\n",
      "Epoch 581/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0072\n",
      "Epoch 582/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0068\n",
      "Epoch 583/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0068\n",
      "Epoch 584/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 585/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0073\n",
      "Epoch 586/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0072\n",
      "Epoch 587/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0073\n",
      "Epoch 588/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0071\n",
      "Epoch 589/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0071\n",
      "Epoch 590/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 591/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0066\n",
      "Epoch 592/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0068\n",
      "Epoch 593/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0067\n",
      "Epoch 594/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0066\n",
      "Epoch 595/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0065\n",
      "Epoch 596/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0068\n",
      "Epoch 597/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0068\n",
      "Epoch 598/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0066\n",
      "Epoch 599/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0068\n",
      "Epoch 600/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0066\n",
      "Epoch 601/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0079\n",
      "Epoch 602/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0068\n",
      "Epoch 603/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0071\n",
      "Epoch 604/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0081\n",
      "Epoch 605/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0066\n",
      "Epoch 606/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0066\n",
      "Epoch 607/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0066\n",
      "Epoch 608/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0068\n",
      "Epoch 609/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0070\n",
      "Epoch 610/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0066\n",
      "Epoch 611/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0068\n",
      "Epoch 612/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0077\n",
      "Epoch 613/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0069\n",
      "Epoch 614/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 615/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 616/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0066\n",
      "Epoch 617/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0073\n",
      "Epoch 618/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0082\n",
      "Epoch 619/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0066\n",
      "Epoch 620/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0066\n",
      "Epoch 621/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0065\n",
      "Epoch 622/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0066\n",
      "Epoch 623/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0064\n",
      "Epoch 624/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0066\n",
      "Epoch 625/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0065\n",
      "Epoch 626/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0074\n",
      "Epoch 627/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0068\n",
      "Epoch 628/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0065\n",
      "Epoch 629/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 630/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0064\n",
      "Epoch 631/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0083\n",
      "Epoch 632/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0072\n",
      "Epoch 633/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0071\n",
      "Epoch 634/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0068\n",
      "Epoch 635/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0069\n",
      "Epoch 636/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0072\n",
      "Epoch 637/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0065\n",
      "Epoch 638/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0063\n",
      "Epoch 639/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0065\n",
      "Epoch 640/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 641/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0065\n",
      "Epoch 642/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 643/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0067\n",
      "Epoch 644/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0066\n",
      "Epoch 645/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0063\n",
      "Epoch 646/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0065\n",
      "Epoch 647/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 648/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 649/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0065\n",
      "Epoch 650/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0070\n",
      "Epoch 651/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0064\n",
      "Epoch 652/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0070\n",
      "Epoch 653/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0064\n",
      "Epoch 654/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0066\n",
      "Epoch 655/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0065\n",
      "Epoch 656/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0064\n",
      "Epoch 657/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0063\n",
      "Epoch 658/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0064\n",
      "Epoch 659/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0067\n",
      "Epoch 660/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0065\n",
      "Epoch 661/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0065\n",
      "Epoch 662/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0067\n",
      "Epoch 663/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0064\n",
      "Epoch 664/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 665/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0063\n",
      "Epoch 666/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0063\n",
      "Epoch 667/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0063\n",
      "Epoch 668/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0064\n",
      "Epoch 669/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0065\n",
      "Epoch 670/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0065\n",
      "Epoch 671/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0068\n",
      "Epoch 672/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0068\n",
      "Epoch 673/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0072\n",
      "Epoch 674/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0067\n",
      "Epoch 675/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0071\n",
      "Epoch 676/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0063\n",
      "Epoch 677/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0073\n",
      "Epoch 678/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0066\n",
      "Epoch 679/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0064\n",
      "Epoch 680/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0062\n",
      "Epoch 681/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0065\n",
      "Epoch 682/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0064\n",
      "Epoch 683/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 684/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0063\n",
      "Epoch 685/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0062\n",
      "Epoch 686/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0076\n",
      "Epoch 687/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0063\n",
      "Epoch 688/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0063\n",
      "Epoch 689/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0070\n",
      "Epoch 690/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0062\n",
      "Epoch 691/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0063\n",
      "Epoch 692/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0066\n",
      "Epoch 693/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 694/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0062\n",
      "Epoch 695/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0064\n",
      "Epoch 696/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 697/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0074\n",
      "Epoch 698/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0064\n",
      "Epoch 699/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0067\n",
      "Epoch 700/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0065\n",
      "Epoch 701/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0065\n",
      "Epoch 702/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0072\n",
      "Epoch 703/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0063\n",
      "Epoch 704/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0070\n",
      "Epoch 705/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0062\n",
      "Epoch 706/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0073\n",
      "Epoch 707/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0067\n",
      "Epoch 708/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0064\n",
      "Epoch 709/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0063\n",
      "Epoch 710/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0063\n",
      "Epoch 711/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0063\n",
      "Epoch 712/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0067\n",
      "Epoch 713/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0062\n",
      "Epoch 714/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0063\n",
      "Epoch 715/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0074\n",
      "Epoch 716/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0063\n",
      "Epoch 717/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0067\n",
      "Epoch 718/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0067\n",
      "Epoch 719/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0065\n",
      "Epoch 720/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0064\n",
      "Epoch 721/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0069\n",
      "Epoch 722/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 723/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0068\n",
      "Epoch 724/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0066\n",
      "Epoch 725/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0066\n",
      "Epoch 726/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0064\n",
      "Epoch 727/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0073\n",
      "Epoch 728/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0064\n",
      "Epoch 729/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0065\n",
      "Epoch 730/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 731/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0077\n",
      "Epoch 732/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0065\n",
      "Epoch 733/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0063\n",
      "Epoch 734/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0063\n",
      "Epoch 735/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0065\n",
      "Epoch 736/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0065\n",
      "Epoch 737/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0063\n",
      "Epoch 738/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0063\n",
      "Epoch 739/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0063\n",
      "Epoch 740/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0064\n",
      "Epoch 741/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0066\n",
      "Epoch 742/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0063\n",
      "Epoch 743/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0063\n",
      "Epoch 744/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0078\n",
      "Epoch 745/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0063\n",
      "Epoch 746/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0073\n",
      "Epoch 747/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0063\n",
      "Epoch 748/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0073\n",
      "Epoch 749/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0063\n",
      "Epoch 750/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0061\n",
      "Epoch 751/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0070\n",
      "Epoch 752/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0064\n",
      "Epoch 753/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0063\n",
      "Epoch 754/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0064\n",
      "Epoch 755/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.0067\n",
      "Epoch 756/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.0062\n",
      "Epoch 757/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0066\n",
      "Epoch 758/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0064\n",
      "Epoch 759/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0064\n",
      "Epoch 760/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0079\n",
      "Epoch 761/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0064\n",
      "Epoch 762/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0063\n",
      "Epoch 763/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0063\n",
      "Epoch 764/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0064\n",
      "Epoch 765/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0063\n",
      "Epoch 766/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0064\n",
      "Epoch 767/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0064\n",
      "Epoch 768/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0064\n",
      "Epoch 769/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0070\n",
      "Epoch 770/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0062\n",
      "Epoch 771/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0065\n",
      "Epoch 772/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0062\n",
      "Epoch 773/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0062\n",
      "Epoch 774/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0062\n",
      "Epoch 775/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0063\n",
      "Epoch 776/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0063\n",
      "Epoch 777/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0063\n",
      "Epoch 778/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0062\n",
      "Epoch 779/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0066\n",
      "Epoch 780/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0064\n",
      "Epoch 781/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0063\n",
      "Epoch 782/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0069\n",
      "Epoch 783/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0065\n",
      "Epoch 784/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0064\n",
      "Epoch 785/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0063\n",
      "Epoch 786/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0061\n",
      "Epoch 787/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0062\n",
      "Epoch 788/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0069\n",
      "Epoch 789/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0063\n",
      "Epoch 790/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0062\n",
      "Epoch 791/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0061\n",
      "Epoch 792/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0063\n",
      "Epoch 793/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0064\n",
      "Epoch 794/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0064\n",
      "Epoch 795/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0065\n",
      "Epoch 796/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0063\n",
      "Epoch 797/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0070\n",
      "Epoch 798/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0075\n",
      "Epoch 799/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0067\n",
      "Epoch 800/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0067\n",
      "Epoch 801/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0065\n",
      "Epoch 802/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0063\n",
      "Epoch 803/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0061\n",
      "Epoch 804/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0061\n",
      "Epoch 805/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0069\n",
      "Epoch 806/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0063\n",
      "Epoch 807/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0062\n",
      "Epoch 808/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0064\n",
      "Epoch 809/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0062\n",
      "Epoch 810/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0067\n",
      "Epoch 811/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0068\n",
      "Epoch 812/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0067\n",
      "Epoch 813/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0066\n",
      "Epoch 814/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0063\n",
      "Epoch 815/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0065\n",
      "Epoch 816/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0080\n",
      "Epoch 817/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0063\n",
      "Epoch 818/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 819/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0064\n",
      "Epoch 820/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0065\n",
      "Epoch 821/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0063\n",
      "Epoch 822/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0065\n",
      "Epoch 823/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0063\n",
      "Epoch 824/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 825/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0063\n",
      "Epoch 826/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0065\n",
      "Epoch 827/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0064\n",
      "Epoch 828/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0065\n",
      "Epoch 829/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0066\n",
      "Epoch 830/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0060\n",
      "Epoch 831/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0061\n",
      "Epoch 832/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0062\n",
      "Epoch 833/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0060\n",
      "Epoch 834/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0061\n",
      "Epoch 835/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 836/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0067\n",
      "Epoch 837/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0064\n",
      "Epoch 838/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0063\n",
      "Epoch 839/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0062\n",
      "Epoch 840/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 841/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0062\n",
      "Epoch 842/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0065\n",
      "Epoch 843/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0068\n",
      "Epoch 844/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0062\n",
      "Epoch 845/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0062\n",
      "Epoch 846/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0070\n",
      "Epoch 847/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0064\n",
      "Epoch 848/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0062\n",
      "Epoch 849/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0063\n",
      "Epoch 850/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0062\n",
      "Epoch 851/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0065\n",
      "Epoch 852/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0061\n",
      "Epoch 853/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0063\n",
      "Epoch 854/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0061\n",
      "Epoch 855/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0067\n",
      "Epoch 856/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0063\n",
      "Epoch 857/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 858/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0063\n",
      "Epoch 859/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0062\n",
      "Epoch 860/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 861/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0079\n",
      "Epoch 862/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0064\n",
      "Epoch 863/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0062\n",
      "Epoch 864/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0061\n",
      "Epoch 865/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0061\n",
      "Epoch 866/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0065\n",
      "Epoch 867/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0061\n",
      "Epoch 868/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0065\n",
      "Epoch 869/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0065\n",
      "Epoch 870/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0061\n",
      "Epoch 871/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0062\n",
      "Epoch 872/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0071\n",
      "Epoch 873/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0063\n",
      "Epoch 874/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0061\n",
      "Epoch 875/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0063\n",
      "Epoch 876/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 877/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0061\n",
      "Epoch 878/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0061\n",
      "Epoch 879/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0063\n",
      "Epoch 880/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0061\n",
      "Epoch 881/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0064\n",
      "Epoch 882/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0068\n",
      "Epoch 883/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0063\n",
      "Epoch 884/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0061\n",
      "Epoch 885/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0062\n",
      "Epoch 886/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0071\n",
      "Epoch 887/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0062\n",
      "Epoch 888/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0069\n",
      "Epoch 889/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0064\n",
      "Epoch 890/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0062\n",
      "Epoch 891/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0063\n",
      "Epoch 892/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0068\n",
      "Epoch 893/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 894/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0061\n",
      "Epoch 895/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0070\n",
      "Epoch 896/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0064\n",
      "Epoch 897/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 898/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0065\n",
      "Epoch 899/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0064\n",
      "Epoch 900/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0067\n",
      "Epoch 901/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0065\n",
      "Epoch 902/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0062\n",
      "Epoch 903/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0063\n",
      "Epoch 904/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0062\n",
      "Epoch 905/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0066\n",
      "Epoch 906/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0066\n",
      "Epoch 907/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0062\n",
      "Epoch 908/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0062\n",
      "Epoch 909/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0069\n",
      "Epoch 910/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0061\n",
      "Epoch 911/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0061\n",
      "Epoch 912/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0062\n",
      "Epoch 913/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0068\n",
      "Epoch 914/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0065\n",
      "Epoch 915/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0062\n",
      "Epoch 916/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0060\n",
      "Epoch 917/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0067\n",
      "Epoch 918/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0061\n",
      "Epoch 919/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0068\n",
      "Epoch 920/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0068\n",
      "Epoch 921/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0065\n",
      "Epoch 922/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0067\n",
      "Epoch 923/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0067\n",
      "Epoch 924/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0063\n",
      "Epoch 925/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0070\n",
      "Epoch 926/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0079\n",
      "Epoch 927/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0065\n",
      "Epoch 928/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0062\n",
      "Epoch 929/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0063\n",
      "Epoch 930/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0061\n",
      "Epoch 931/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0064\n",
      "Epoch 932/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0061\n",
      "Epoch 933/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0067\n",
      "Epoch 00933: early stopping\n",
      "Epoch 1/10000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.6676 - val_loss: 0.3221\n",
      "Epoch 2/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2252 - val_loss: 0.0670\n",
      "Epoch 3/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1033 - val_loss: 0.0360\n",
      "Epoch 4/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0341\n",
      "Epoch 5/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0819 - val_loss: 0.0330\n",
      "Epoch 6/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0761 - val_loss: 0.0327\n",
      "Epoch 7/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0757 - val_loss: 0.0335\n",
      "Epoch 8/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0697 - val_loss: 0.0322\n",
      "Epoch 9/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0660 - val_loss: 0.0311\n",
      "Epoch 10/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0626 - val_loss: 0.0275\n",
      "Epoch 11/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0252\n",
      "Epoch 12/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0546 - val_loss: 0.0215\n",
      "Epoch 13/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.0209\n",
      "Epoch 14/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0483 - val_loss: 0.0188\n",
      "Epoch 15/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0461 - val_loss: 0.0186\n",
      "Epoch 16/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0440 - val_loss: 0.0177\n",
      "Epoch 17/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0421 - val_loss: 0.0177\n",
      "Epoch 18/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0410 - val_loss: 0.0182\n",
      "Epoch 19/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0393 - val_loss: 0.0175\n",
      "Epoch 20/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0374 - val_loss: 0.0171\n",
      "Epoch 21/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0374 - val_loss: 0.0178\n",
      "Epoch 22/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0352 - val_loss: 0.0176\n",
      "Epoch 23/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0348 - val_loss: 0.0170\n",
      "Epoch 24/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0342 - val_loss: 0.0171\n",
      "Epoch 25/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0332 - val_loss: 0.0174\n",
      "Epoch 26/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0329 - val_loss: 0.0173\n",
      "Epoch 27/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0322 - val_loss: 0.0170\n",
      "Epoch 28/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0307 - val_loss: 0.0166\n",
      "Epoch 29/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0311 - val_loss: 0.0174\n",
      "Epoch 30/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0296 - val_loss: 0.0169\n",
      "Epoch 31/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0293 - val_loss: 0.0166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0290 - val_loss: 0.0170\n",
      "Epoch 33/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0287 - val_loss: 0.0167\n",
      "Epoch 34/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0286 - val_loss: 0.0164\n",
      "Epoch 35/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0287 - val_loss: 0.0167\n",
      "Epoch 36/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0270 - val_loss: 0.0168\n",
      "Epoch 37/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.0166\n",
      "Epoch 38/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.0167\n",
      "Epoch 39/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.0173\n",
      "Epoch 40/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0165\n",
      "Epoch 41/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0263 - val_loss: 0.0166\n",
      "Epoch 42/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.0165\n",
      "Epoch 43/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0266 - val_loss: 0.0164\n",
      "Epoch 44/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0251 - val_loss: 0.0164\n",
      "Epoch 45/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0261 - val_loss: 0.0167\n",
      "Epoch 46/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.0165\n",
      "Epoch 47/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0252 - val_loss: 0.0163\n",
      "Epoch 48/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.0161\n",
      "Epoch 49/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.0164\n",
      "Epoch 50/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0249 - val_loss: 0.0162\n",
      "Epoch 51/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0246 - val_loss: 0.0162\n",
      "Epoch 52/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0245 - val_loss: 0.0163\n",
      "Epoch 53/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.0160\n",
      "Epoch 54/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0237 - val_loss: 0.0162\n",
      "Epoch 55/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0239 - val_loss: 0.0160\n",
      "Epoch 56/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.0159\n",
      "Epoch 57/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0236 - val_loss: 0.0159\n",
      "Epoch 58/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0233 - val_loss: 0.0160\n",
      "Epoch 59/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.0169\n",
      "Epoch 60/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0243 - val_loss: 0.0159\n",
      "Epoch 61/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.0163\n",
      "Epoch 62/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0230 - val_loss: 0.0157\n",
      "Epoch 63/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.0157\n",
      "Epoch 64/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.0153\n",
      "Epoch 65/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0225 - val_loss: 0.0154\n",
      "Epoch 66/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0230 - val_loss: 0.0154\n",
      "Epoch 67/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0220 - val_loss: 0.0153\n",
      "Epoch 68/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0220 - val_loss: 0.0153\n",
      "Epoch 69/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0219 - val_loss: 0.0147\n",
      "Epoch 70/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0215 - val_loss: 0.0146\n",
      "Epoch 71/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.0139\n",
      "Epoch 72/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0143\n",
      "Epoch 73/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0138\n",
      "Epoch 74/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0205 - val_loss: 0.0137\n",
      "Epoch 75/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0206 - val_loss: 0.0135\n",
      "Epoch 76/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0135\n",
      "Epoch 77/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0135\n",
      "Epoch 78/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0197 - val_loss: 0.0134\n",
      "Epoch 79/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0143\n",
      "Epoch 80/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0135\n",
      "Epoch 81/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0200 - val_loss: 0.0136\n",
      "Epoch 82/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0202 - val_loss: 0.0134\n",
      "Epoch 83/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0134\n",
      "Epoch 84/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0198 - val_loss: 0.0152\n",
      "Epoch 85/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0206 - val_loss: 0.0134\n",
      "Epoch 86/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0134\n",
      "Epoch 87/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0133\n",
      "Epoch 88/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0133\n",
      "Epoch 89/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0190 - val_loss: 0.0133\n",
      "Epoch 90/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0136\n",
      "Epoch 91/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0135\n",
      "Epoch 92/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0192 - val_loss: 0.0134\n",
      "Epoch 93/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0188 - val_loss: 0.0132\n",
      "Epoch 94/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0189 - val_loss: 0.0133\n",
      "Epoch 95/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0133\n",
      "Epoch 96/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0187 - val_loss: 0.0131\n",
      "Epoch 97/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0185 - val_loss: 0.0130\n",
      "Epoch 98/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0183 - val_loss: 0.0133\n",
      "Epoch 99/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.0132\n",
      "Epoch 100/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0132\n",
      "Epoch 101/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0130\n",
      "Epoch 102/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0132\n",
      "Epoch 103/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0132\n",
      "Epoch 104/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0177 - val_loss: 0.0135\n",
      "Epoch 105/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0183 - val_loss: 0.0131\n",
      "Epoch 106/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0179 - val_loss: 0.0131\n",
      "Epoch 107/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0132\n",
      "Epoch 108/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0129\n",
      "Epoch 109/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0176 - val_loss: 0.0129\n",
      "Epoch 110/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0129\n",
      "Epoch 111/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0130\n",
      "Epoch 112/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0134\n",
      "Epoch 113/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0130\n",
      "Epoch 114/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0131\n",
      "Epoch 115/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0132\n",
      "Epoch 116/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0130\n",
      "Epoch 117/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0128\n",
      "Epoch 118/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0129\n",
      "Epoch 119/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0129\n",
      "Epoch 120/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0130\n",
      "Epoch 121/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0170 - val_loss: 0.0130\n",
      "Epoch 122/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0126\n",
      "Epoch 123/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0132\n",
      "Epoch 124/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0129\n",
      "Epoch 125/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0130\n",
      "Epoch 126/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0126\n",
      "Epoch 127/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0126\n",
      "Epoch 128/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0126\n",
      "Epoch 129/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0135\n",
      "Epoch 130/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0127\n",
      "Epoch 131/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0127\n",
      "Epoch 132/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0128\n",
      "Epoch 133/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0125\n",
      "Epoch 134/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0123\n",
      "Epoch 135/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0124\n",
      "Epoch 136/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0124\n",
      "Epoch 137/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0121\n",
      "Epoch 138/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0127\n",
      "Epoch 139/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0123\n",
      "Epoch 140/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0119\n",
      "Epoch 141/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0121\n",
      "Epoch 142/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0119\n",
      "Epoch 143/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0115\n",
      "Epoch 144/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0142 - val_loss: 0.0111\n",
      "Epoch 145/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0110\n",
      "Epoch 146/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0106\n",
      "Epoch 147/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0136 - val_loss: 0.0109\n",
      "Epoch 148/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0102\n",
      "Epoch 149/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 150/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0130 - val_loss: 0.0099\n",
      "Epoch 151/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.0102\n",
      "Epoch 152/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.0097\n",
      "Epoch 153/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0100\n",
      "Epoch 154/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.0094\n",
      "Epoch 155/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0093\n",
      "Epoch 156/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0097\n",
      "Epoch 157/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0103\n",
      "Epoch 158/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0101\n",
      "Epoch 159/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0090\n",
      "Epoch 160/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0089\n",
      "Epoch 161/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0091\n",
      "Epoch 162/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.0088\n",
      "Epoch 163/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0090\n",
      "Epoch 164/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0088\n",
      "Epoch 165/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0086\n",
      "Epoch 166/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.0091\n",
      "Epoch 167/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0086\n",
      "Epoch 168/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0088\n",
      "Epoch 169/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0089\n",
      "Epoch 170/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0086\n",
      "Epoch 171/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0085\n",
      "Epoch 172/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0087\n",
      "Epoch 173/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0084\n",
      "Epoch 174/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0082\n",
      "Epoch 175/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0082\n",
      "Epoch 176/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0086\n",
      "Epoch 177/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0084\n",
      "Epoch 178/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0082\n",
      "Epoch 179/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.0084\n",
      "Epoch 180/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0081\n",
      "Epoch 181/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0080\n",
      "Epoch 182/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.0089\n",
      "Epoch 183/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0082\n",
      "Epoch 184/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0089\n",
      "Epoch 185/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0080\n",
      "Epoch 186/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0086\n",
      "Epoch 187/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0087\n",
      "Epoch 188/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0081\n",
      "Epoch 189/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.0086\n",
      "Epoch 190/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0080\n",
      "Epoch 191/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0080\n",
      "Epoch 192/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0079\n",
      "Epoch 193/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0078\n",
      "Epoch 194/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0078\n",
      "Epoch 195/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0077\n",
      "Epoch 196/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0097\n",
      "Epoch 197/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.0084\n",
      "Epoch 198/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0081\n",
      "Epoch 199/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0078\n",
      "Epoch 200/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0077\n",
      "Epoch 201/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0079\n",
      "Epoch 202/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0077\n",
      "Epoch 203/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0081\n",
      "Epoch 204/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0077\n",
      "Epoch 205/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0077\n",
      "Epoch 206/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0085\n",
      "Epoch 207/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0077\n",
      "Epoch 208/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0077\n",
      "Epoch 209/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0086\n",
      "Epoch 210/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0080\n",
      "Epoch 211/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0077\n",
      "Epoch 212/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0076\n",
      "Epoch 213/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.0076\n",
      "Epoch 214/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.0078\n",
      "Epoch 215/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.0079\n",
      "Epoch 216/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.0075\n",
      "Epoch 217/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.0075\n",
      "Epoch 218/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.0075\n",
      "Epoch 219/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.0075\n",
      "Epoch 220/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.0076\n",
      "Epoch 221/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.0074\n",
      "Epoch 222/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0073\n",
      "Epoch 223/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0074\n",
      "Epoch 224/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0073\n",
      "Epoch 225/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0074\n",
      "Epoch 226/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0073\n",
      "Epoch 227/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0072\n",
      "Epoch 228/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0070\n",
      "Epoch 229/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0071\n",
      "Epoch 230/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0071\n",
      "Epoch 231/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0073\n",
      "Epoch 232/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0072\n",
      "Epoch 233/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0070\n",
      "Epoch 234/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0069\n",
      "Epoch 235/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0071\n",
      "Epoch 236/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0071\n",
      "Epoch 237/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0069\n",
      "Epoch 238/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0071\n",
      "Epoch 239/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0069\n",
      "Epoch 240/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0071\n",
      "Epoch 241/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0072\n",
      "Epoch 242/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0069\n",
      "Epoch 243/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0071\n",
      "Epoch 244/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0074\n",
      "Epoch 245/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0070\n",
      "Epoch 246/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0075\n",
      "Epoch 247/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0072\n",
      "Epoch 248/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0070\n",
      "Epoch 249/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0072\n",
      "Epoch 250/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0069\n",
      "Epoch 251/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0068\n",
      "Epoch 252/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0074\n",
      "Epoch 253/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0074\n",
      "Epoch 254/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0071\n",
      "Epoch 255/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0070\n",
      "Epoch 256/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0069\n",
      "Epoch 257/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0068\n",
      "Epoch 258/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0069\n",
      "Epoch 259/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0070\n",
      "Epoch 260/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0068\n",
      "Epoch 261/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0070\n",
      "Epoch 262/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0072\n",
      "Epoch 263/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0068\n",
      "Epoch 264/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0067\n",
      "Epoch 265/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0069\n",
      "Epoch 266/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0068\n",
      "Epoch 267/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0069\n",
      "Epoch 268/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0071\n",
      "Epoch 269/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0071\n",
      "Epoch 270/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0070\n",
      "Epoch 271/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0074\n",
      "Epoch 272/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0067\n",
      "Epoch 273/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0067\n",
      "Epoch 274/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0067\n",
      "Epoch 275/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0068\n",
      "Epoch 276/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0071\n",
      "Epoch 277/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0070\n",
      "Epoch 278/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0067\n",
      "Epoch 279/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0069\n",
      "Epoch 280/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0069\n",
      "Epoch 281/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0069\n",
      "Epoch 282/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0069\n",
      "Epoch 283/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0072\n",
      "Epoch 284/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0077\n",
      "Epoch 285/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0067\n",
      "Epoch 286/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0067\n",
      "Epoch 287/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0069\n",
      "Epoch 288/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0070\n",
      "Epoch 289/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0072\n",
      "Epoch 290/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0066\n",
      "Epoch 291/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0070\n",
      "Epoch 292/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0065\n",
      "Epoch 293/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0067\n",
      "Epoch 294/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0073\n",
      "Epoch 295/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0071\n",
      "Epoch 296/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0067\n",
      "Epoch 297/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0075\n",
      "Epoch 298/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0072\n",
      "Epoch 299/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0068\n",
      "Epoch 300/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0068\n",
      "Epoch 301/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0067\n",
      "Epoch 302/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0066\n",
      "Epoch 303/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0066\n",
      "Epoch 304/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0068\n",
      "Epoch 305/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0067\n",
      "Epoch 306/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0068\n",
      "Epoch 307/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0071\n",
      "Epoch 308/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0071\n",
      "Epoch 309/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0066\n",
      "Epoch 310/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0066\n",
      "Epoch 311/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0066\n",
      "Epoch 312/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 313/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0072\n",
      "Epoch 314/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0066\n",
      "Epoch 315/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0082\n",
      "Epoch 316/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0067\n",
      "Epoch 317/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0067\n",
      "Epoch 318/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0076\n",
      "Epoch 319/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0072\n",
      "Epoch 320/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0067\n",
      "Epoch 321/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0069\n",
      "Epoch 322/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0067\n",
      "Epoch 323/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0066\n",
      "Epoch 324/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0066\n",
      "Epoch 325/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0067\n",
      "Epoch 326/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0069\n",
      "Epoch 327/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0067\n",
      "Epoch 328/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0069\n",
      "Epoch 329/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0066\n",
      "Epoch 330/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0064\n",
      "Epoch 331/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0066\n",
      "Epoch 332/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0073\n",
      "Epoch 333/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0066\n",
      "Epoch 334/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0067\n",
      "Epoch 335/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0067\n",
      "Epoch 336/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0064\n",
      "Epoch 337/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0078\n",
      "Epoch 338/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0066\n",
      "Epoch 339/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0067\n",
      "Epoch 340/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0069\n",
      "Epoch 341/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0071\n",
      "Epoch 342/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0079\n",
      "Epoch 343/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0068\n",
      "Epoch 344/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0066\n",
      "Epoch 345/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0067\n",
      "Epoch 346/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0087 - val_loss: 0.0065\n",
      "Epoch 347/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0087 - val_loss: 0.0066\n",
      "Epoch 348/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0065\n",
      "Epoch 349/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0064\n",
      "Epoch 350/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0071\n",
      "Epoch 351/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0065\n",
      "Epoch 352/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0065\n",
      "Epoch 353/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0068\n",
      "Epoch 354/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0068\n",
      "Epoch 355/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0069\n",
      "Epoch 356/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0066\n",
      "Epoch 357/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0067\n",
      "Epoch 358/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0072\n",
      "Epoch 359/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0066\n",
      "Epoch 360/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0066\n",
      "Epoch 361/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0066\n",
      "Epoch 362/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0064\n",
      "Epoch 363/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0066\n",
      "Epoch 364/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 365/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0069\n",
      "Epoch 366/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0067\n",
      "Epoch 367/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0068\n",
      "Epoch 368/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0068\n",
      "Epoch 369/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0066\n",
      "Epoch 370/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0071\n",
      "Epoch 371/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0066\n",
      "Epoch 372/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0068\n",
      "Epoch 373/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0065\n",
      "Epoch 374/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0065\n",
      "Epoch 375/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0068\n",
      "Epoch 376/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0077\n",
      "Epoch 377/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0067\n",
      "Epoch 378/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0065\n",
      "Epoch 379/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0064\n",
      "Epoch 380/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 381/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0064\n",
      "Epoch 382/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 383/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0064\n",
      "Epoch 384/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0067\n",
      "Epoch 385/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0066\n",
      "Epoch 386/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0066\n",
      "Epoch 387/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0064\n",
      "Epoch 388/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0066\n",
      "Epoch 389/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0064\n",
      "Epoch 390/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0066\n",
      "Epoch 391/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0065\n",
      "Epoch 392/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0063\n",
      "Epoch 393/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0063\n",
      "Epoch 394/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0064\n",
      "Epoch 395/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0067\n",
      "Epoch 396/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0063\n",
      "Epoch 397/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0069\n",
      "Epoch 398/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0064\n",
      "Epoch 399/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0067\n",
      "Epoch 400/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0063\n",
      "Epoch 401/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0076\n",
      "Epoch 402/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0065\n",
      "Epoch 403/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0070\n",
      "Epoch 404/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0066\n",
      "Epoch 405/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0065\n",
      "Epoch 406/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0065\n",
      "Epoch 407/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0067\n",
      "Epoch 408/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0073\n",
      "Epoch 409/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0066\n",
      "Epoch 410/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0066\n",
      "Epoch 411/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0066\n",
      "Epoch 412/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0072\n",
      "Epoch 413/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0065\n",
      "Epoch 414/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0063\n",
      "Epoch 415/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0070\n",
      "Epoch 416/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0071\n",
      "Epoch 417/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 418/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 419/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0071\n",
      "Epoch 420/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0064\n",
      "Epoch 421/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0065\n",
      "Epoch 422/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 423/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0068\n",
      "Epoch 424/10000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0063\n",
      "Epoch 425/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0064\n",
      "Epoch 426/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0064\n",
      "Epoch 427/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 428/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0065\n",
      "Epoch 429/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0063\n",
      "Epoch 430/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0070\n",
      "Epoch 431/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 432/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0071\n",
      "Epoch 433/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0065\n",
      "Epoch 434/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0063\n",
      "Epoch 435/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0071\n",
      "Epoch 436/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0064\n",
      "Epoch 437/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0063\n",
      "Epoch 438/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0065\n",
      "Epoch 439/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0064\n",
      "Epoch 440/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0063\n",
      "Epoch 441/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 442/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0065\n",
      "Epoch 443/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0070\n",
      "Epoch 444/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0064\n",
      "Epoch 445/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0064\n",
      "Epoch 446/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0069\n",
      "Epoch 447/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0064\n",
      "Epoch 448/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0063\n",
      "Epoch 449/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0063\n",
      "Epoch 450/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0063\n",
      "Epoch 451/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0065\n",
      "Epoch 452/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0063\n",
      "Epoch 453/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0072\n",
      "Epoch 454/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0065\n",
      "Epoch 455/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0065\n",
      "Epoch 456/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0063\n",
      "Epoch 457/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0064\n",
      "Epoch 458/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0062\n",
      "Epoch 459/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0061\n",
      "Epoch 460/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0064\n",
      "Epoch 461/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0066\n",
      "Epoch 462/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 463/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0065\n",
      "Epoch 464/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0065\n",
      "Epoch 465/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0064\n",
      "Epoch 466/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0065\n",
      "Epoch 467/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0065\n",
      "Epoch 468/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0063\n",
      "Epoch 469/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0065\n",
      "Epoch 470/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0064\n",
      "Epoch 471/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0065\n",
      "Epoch 472/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0065\n",
      "Epoch 473/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0064\n",
      "Epoch 474/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0066\n",
      "Epoch 475/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0063\n",
      "Epoch 476/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0064\n",
      "Epoch 477/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0075\n",
      "Epoch 478/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0069\n",
      "Epoch 479/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0064\n",
      "Epoch 480/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0069\n",
      "Epoch 481/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 482/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 483/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0067\n",
      "Epoch 484/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0065\n",
      "Epoch 485/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0068\n",
      "Epoch 486/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0062\n",
      "Epoch 487/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0064\n",
      "Epoch 488/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0062\n",
      "Epoch 489/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0062\n",
      "Epoch 490/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0064\n",
      "Epoch 491/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0066\n",
      "Epoch 492/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0065\n",
      "Epoch 493/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0064\n",
      "Epoch 494/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0065\n",
      "Epoch 495/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0065\n",
      "Epoch 496/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0062\n",
      "Epoch 497/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0064\n",
      "Epoch 498/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0063\n",
      "Epoch 499/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 500/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0066\n",
      "Epoch 501/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0063\n",
      "Epoch 502/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0064\n",
      "Epoch 503/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0062\n",
      "Epoch 504/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0061\n",
      "Epoch 505/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0063\n",
      "Epoch 506/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 507/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0062\n",
      "Epoch 508/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0064\n",
      "Epoch 509/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0066\n",
      "Epoch 510/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0062\n",
      "Epoch 511/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0062\n",
      "Epoch 512/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0069\n",
      "Epoch 513/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0071\n",
      "Epoch 514/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0062\n",
      "Epoch 515/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0067\n",
      "Epoch 516/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0065\n",
      "Epoch 517/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.0069\n",
      "Epoch 518/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0063\n",
      "Epoch 519/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0061\n",
      "Epoch 520/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0065\n",
      "Epoch 521/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0063\n",
      "Epoch 522/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0062\n",
      "Epoch 523/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0073\n",
      "Epoch 524/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0065\n",
      "Epoch 525/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0069\n",
      "Epoch 526/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0064\n",
      "Epoch 527/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 528/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0085\n",
      "Epoch 529/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0064\n",
      "Epoch 530/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0061\n",
      "Epoch 531/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0061\n",
      "Epoch 532/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0062\n",
      "Epoch 533/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0063\n",
      "Epoch 534/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0067\n",
      "Epoch 535/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0076\n",
      "Epoch 536/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0066\n",
      "Epoch 537/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 538/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0062\n",
      "Epoch 539/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0069\n",
      "Epoch 540/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0065\n",
      "Epoch 541/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0065\n",
      "Epoch 542/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0068\n",
      "Epoch 543/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0064\n",
      "Epoch 544/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0065\n",
      "Epoch 545/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0064\n",
      "Epoch 546/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0061\n",
      "Epoch 547/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 548/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0061\n",
      "Epoch 549/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0064\n",
      "Epoch 550/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 551/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0061\n",
      "Epoch 552/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 553/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0061\n",
      "Epoch 554/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 555/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0061\n",
      "Epoch 556/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0062\n",
      "Epoch 557/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0062\n",
      "Epoch 558/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0061\n",
      "Epoch 559/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0062\n",
      "Epoch 560/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0063\n",
      "Epoch 561/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0061\n",
      "Epoch 562/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0069\n",
      "Epoch 563/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0063\n",
      "Epoch 564/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0063\n",
      "Epoch 565/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0063\n",
      "Epoch 566/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0061\n",
      "Epoch 567/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 568/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0064\n",
      "Epoch 569/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0068\n",
      "Epoch 570/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0064\n",
      "Epoch 571/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0065\n",
      "Epoch 572/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0062\n",
      "Epoch 573/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 574/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0062\n",
      "Epoch 575/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0063\n",
      "Epoch 576/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0062\n",
      "Epoch 577/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0060\n",
      "Epoch 578/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0061\n",
      "Epoch 579/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0061\n",
      "Epoch 580/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0063\n",
      "Epoch 581/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0062\n",
      "Epoch 582/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0071\n",
      "Epoch 583/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0064\n",
      "Epoch 584/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0062\n",
      "Epoch 585/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0063\n",
      "Epoch 586/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0065\n",
      "Epoch 587/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0065\n",
      "Epoch 588/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0065\n",
      "Epoch 589/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0062\n",
      "Epoch 590/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0066\n",
      "Epoch 591/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0060\n",
      "Epoch 592/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0064\n",
      "Epoch 593/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0065\n",
      "Epoch 594/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0061\n",
      "Epoch 595/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0065\n",
      "Epoch 596/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0077\n",
      "Epoch 597/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0062\n",
      "Epoch 598/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0065\n",
      "Epoch 599/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0061\n",
      "Epoch 600/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0065\n",
      "Epoch 601/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0061\n",
      "Epoch 602/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 603/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0070\n",
      "Epoch 604/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0067\n",
      "Epoch 605/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0063\n",
      "Epoch 606/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 607/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0064\n",
      "Epoch 608/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0063\n",
      "Epoch 609/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0069\n",
      "Epoch 610/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0064\n",
      "Epoch 611/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0062\n",
      "Epoch 612/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0064\n",
      "Epoch 613/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0067\n",
      "Epoch 614/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 615/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0062\n",
      "Epoch 616/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0061\n",
      "Epoch 617/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0064\n",
      "Epoch 618/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0064\n",
      "Epoch 619/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0063\n",
      "Epoch 620/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0070\n",
      "Epoch 621/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0069\n",
      "Epoch 622/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0061\n",
      "Epoch 623/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0064\n",
      "Epoch 624/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 625/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0063\n",
      "Epoch 626/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0061\n",
      "Epoch 627/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0061\n",
      "Epoch 628/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0061\n",
      "Epoch 629/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0061\n",
      "Epoch 630/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0061\n",
      "Epoch 631/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 632/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 633/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0060\n",
      "Epoch 634/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0061\n",
      "Epoch 635/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0064\n",
      "Epoch 636/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0065\n",
      "Epoch 637/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0061\n",
      "Epoch 638/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0082\n",
      "Epoch 639/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0067\n",
      "Epoch 640/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0064\n",
      "Epoch 641/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0063\n",
      "Epoch 642/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0063\n",
      "Epoch 643/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0065\n",
      "Epoch 644/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0064\n",
      "Epoch 645/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0063\n",
      "Epoch 646/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0060\n",
      "Epoch 647/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0061\n",
      "Epoch 648/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 649/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0063\n",
      "Epoch 650/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0066\n",
      "Epoch 651/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0061\n",
      "Epoch 652/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0063\n",
      "Epoch 653/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0060\n",
      "Epoch 654/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0064\n",
      "Epoch 655/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0065\n",
      "Epoch 656/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0064\n",
      "Epoch 657/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0059\n",
      "Epoch 658/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0075\n",
      "Epoch 659/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0067\n",
      "Epoch 660/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0063\n",
      "Epoch 661/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0067\n",
      "Epoch 662/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 663/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0062\n",
      "Epoch 664/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0061\n",
      "Epoch 665/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0061\n",
      "Epoch 666/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0061\n",
      "Epoch 667/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0062\n",
      "Epoch 668/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0063\n",
      "Epoch 669/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0066\n",
      "Epoch 670/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0061\n",
      "Epoch 671/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0071\n",
      "Epoch 672/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0060\n",
      "Epoch 673/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0066\n",
      "Epoch 674/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0065\n",
      "Epoch 675/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0065\n",
      "Epoch 676/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0075\n",
      "Epoch 677/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0061\n",
      "Epoch 678/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0061\n",
      "Epoch 679/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0065\n",
      "Epoch 680/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0063\n",
      "Epoch 681/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0066\n",
      "Epoch 682/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0066\n",
      "Epoch 683/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0060\n",
      "Epoch 684/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0060\n",
      "Epoch 685/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0060\n",
      "Epoch 686/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0062\n",
      "Epoch 687/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 688/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0060\n",
      "Epoch 689/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0060\n",
      "Epoch 690/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0060\n",
      "Epoch 691/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0065\n",
      "Epoch 692/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0061\n",
      "Epoch 693/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0061\n",
      "Epoch 694/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0061\n",
      "Epoch 695/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0068\n",
      "Epoch 696/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0069\n",
      "Epoch 697/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0064\n",
      "Epoch 698/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0074\n",
      "Epoch 699/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0063\n",
      "Epoch 700/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0063\n",
      "Epoch 701/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0059\n",
      "Epoch 702/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0059\n",
      "Epoch 703/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0064\n",
      "Epoch 704/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0065\n",
      "Epoch 705/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0070\n",
      "Epoch 706/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0060\n",
      "Epoch 707/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0061\n",
      "Epoch 708/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0067\n",
      "Epoch 709/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0062\n",
      "Epoch 710/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0061\n",
      "Epoch 711/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0063\n",
      "Epoch 712/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0061\n",
      "Epoch 713/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0064\n",
      "Epoch 714/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0066\n",
      "Epoch 715/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0061\n",
      "Epoch 716/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0063\n",
      "Epoch 717/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0062\n",
      "Epoch 718/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0061\n",
      "Epoch 719/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0069\n",
      "Epoch 720/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0061\n",
      "Epoch 721/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 722/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0063\n",
      "Epoch 723/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0065\n",
      "Epoch 724/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0065\n",
      "Epoch 725/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0061\n",
      "Epoch 726/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0061\n",
      "Epoch 727/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0061\n",
      "Epoch 728/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0063\n",
      "Epoch 729/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0062\n",
      "Epoch 730/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0060\n",
      "Epoch 731/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0069\n",
      "Epoch 732/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0058\n",
      "Epoch 733/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0060\n",
      "Epoch 734/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0060\n",
      "Epoch 735/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0060\n",
      "Epoch 736/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0062\n",
      "Epoch 737/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0063\n",
      "Epoch 738/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0066\n",
      "Epoch 739/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 740/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0062\n",
      "Epoch 741/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0066\n",
      "Epoch 742/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0060\n",
      "Epoch 743/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0060\n",
      "Epoch 744/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0061\n",
      "Epoch 745/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0064\n",
      "Epoch 746/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0061\n",
      "Epoch 747/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0061\n",
      "Epoch 748/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0059\n",
      "Epoch 749/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0064\n",
      "Epoch 750/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0062\n",
      "Epoch 751/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0064\n",
      "Epoch 752/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0064\n",
      "Epoch 753/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0063\n",
      "Epoch 754/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0060\n",
      "Epoch 755/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0065\n",
      "Epoch 756/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0060\n",
      "Epoch 757/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0059\n",
      "Epoch 758/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0062\n",
      "Epoch 759/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0060\n",
      "Epoch 760/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0072\n",
      "Epoch 761/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0061\n",
      "Epoch 762/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0063\n",
      "Epoch 763/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0062\n",
      "Epoch 764/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0061\n",
      "Epoch 765/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0061\n",
      "Epoch 766/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0061\n",
      "Epoch 767/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0087\n",
      "Epoch 768/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0062\n",
      "Epoch 769/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0061\n",
      "Epoch 770/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0074\n",
      "Epoch 771/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0064\n",
      "Epoch 772/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0061\n",
      "Epoch 773/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0063\n",
      "Epoch 774/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0059\n",
      "Epoch 775/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0059\n",
      "Epoch 776/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0059\n",
      "Epoch 777/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0091\n",
      "Epoch 778/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0064\n",
      "Epoch 779/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0061\n",
      "Epoch 780/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0061\n",
      "Epoch 781/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0061\n",
      "Epoch 782/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0066\n",
      "Epoch 783/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0061\n",
      "Epoch 784/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0065\n",
      "Epoch 785/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0062\n",
      "Epoch 786/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 787/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0059\n",
      "Epoch 788/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0060\n",
      "Epoch 789/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0060\n",
      "Epoch 790/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0060\n",
      "Epoch 791/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0060\n",
      "Epoch 792/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0059\n",
      "Epoch 793/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0061\n",
      "Epoch 794/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0060\n",
      "Epoch 795/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0059\n",
      "Epoch 796/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0058\n",
      "Epoch 797/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0061\n",
      "Epoch 798/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0059\n",
      "Epoch 799/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0061\n",
      "Epoch 800/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0066\n",
      "Epoch 801/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0060\n",
      "Epoch 802/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0061\n",
      "Epoch 803/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0060\n",
      "Epoch 804/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0063\n",
      "Epoch 805/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0060\n",
      "Epoch 806/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0063\n",
      "Epoch 807/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0058\n",
      "Epoch 808/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0059\n",
      "Epoch 809/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0062\n",
      "Epoch 810/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0059\n",
      "Epoch 811/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0060\n",
      "Epoch 812/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0060\n",
      "Epoch 813/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0062\n",
      "Epoch 814/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0060\n",
      "Epoch 815/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0065\n",
      "Epoch 816/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0060\n",
      "Epoch 817/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0060\n",
      "Epoch 818/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0065\n",
      "Epoch 819/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0060\n",
      "Epoch 820/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0060\n",
      "Epoch 821/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0061\n",
      "Epoch 822/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 823/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0060\n",
      "Epoch 824/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0060\n",
      "Epoch 825/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0069\n",
      "Epoch 826/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0072\n",
      "Epoch 827/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0061\n",
      "Epoch 828/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0064\n",
      "Epoch 829/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0060\n",
      "Epoch 830/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0060\n",
      "Epoch 831/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0062\n",
      "Epoch 832/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0071\n",
      "Epoch 833/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0071\n",
      "Epoch 834/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0067\n",
      "Epoch 835/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0062\n",
      "Epoch 836/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0062\n",
      "Epoch 837/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0061\n",
      "Epoch 838/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0061\n",
      "Epoch 839/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0061\n",
      "Epoch 840/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0076\n",
      "Epoch 841/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0066\n",
      "Epoch 842/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0062\n",
      "Epoch 843/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0063\n",
      "Epoch 844/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0060\n",
      "Epoch 845/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0062\n",
      "Epoch 846/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0060\n",
      "Epoch 847/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0061\n",
      "Epoch 848/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0059\n",
      "Epoch 849/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0066\n",
      "Epoch 850/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0065\n",
      "Epoch 851/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0066\n",
      "Epoch 852/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0060\n",
      "Epoch 853/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0061\n",
      "Epoch 854/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0060\n",
      "Epoch 855/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0062\n",
      "Epoch 856/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0064\n",
      "Epoch 857/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0061\n",
      "Epoch 858/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0063\n",
      "Epoch 859/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0064\n",
      "Epoch 860/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0062\n",
      "Epoch 861/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0065\n",
      "Epoch 862/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0061\n",
      "Epoch 863/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0074\n",
      "Epoch 864/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0065\n",
      "Epoch 865/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0060\n",
      "Epoch 866/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0059\n",
      "Epoch 867/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0061\n",
      "Epoch 868/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0065\n",
      "Epoch 869/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0065\n",
      "Epoch 870/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0063\n",
      "Epoch 871/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0067\n",
      "Epoch 872/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0067\n",
      "Epoch 873/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0061\n",
      "Epoch 874/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0061\n",
      "Epoch 875/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0064\n",
      "Epoch 876/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0070\n",
      "Epoch 877/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 878/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0060\n",
      "Epoch 879/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0063\n",
      "Epoch 880/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0063\n",
      "Epoch 881/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0062\n",
      "Epoch 882/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0061\n",
      "Epoch 883/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0060\n",
      "Epoch 884/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0059\n",
      "Epoch 885/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0059\n",
      "Epoch 886/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0067\n",
      "Epoch 887/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0060\n",
      "Epoch 888/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0059\n",
      "Epoch 889/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0059\n",
      "Epoch 890/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0063\n",
      "Epoch 891/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0062\n",
      "Epoch 892/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0058\n",
      "Epoch 893/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0060\n",
      "Epoch 894/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0079\n",
      "Epoch 895/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0064\n",
      "Epoch 896/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0060\n",
      "Epoch 00896: early stopping\n",
      "Epoch 1/10000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.6811 - val_loss: 0.2060\n",
      "Epoch 2/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1613 - val_loss: 0.0416\n",
      "Epoch 3/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0980 - val_loss: 0.0327\n",
      "Epoch 4/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0863 - val_loss: 0.0321\n",
      "Epoch 5/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0363\n",
      "Epoch 6/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0738 - val_loss: 0.0368\n",
      "Epoch 7/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.0318\n",
      "Epoch 8/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0629 - val_loss: 0.0318\n",
      "Epoch 9/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0603 - val_loss: 0.0326\n",
      "Epoch 10/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0565 - val_loss: 0.0320\n",
      "Epoch 11/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0531 - val_loss: 0.0331\n",
      "Epoch 12/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0501 - val_loss: 0.0315\n",
      "Epoch 13/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0467 - val_loss: 0.0303\n",
      "Epoch 14/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0438 - val_loss: 0.0291\n",
      "Epoch 15/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0410 - val_loss: 0.0267\n",
      "Epoch 16/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0378 - val_loss: 0.0224\n",
      "Epoch 17/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0327 - val_loss: 0.0188\n",
      "Epoch 18/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0310 - val_loss: 0.0167\n",
      "Epoch 19/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0295 - val_loss: 0.0161\n",
      "Epoch 20/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.0166\n",
      "Epoch 21/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.0159\n",
      "Epoch 22/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0266 - val_loss: 0.0160\n",
      "Epoch 23/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0258 - val_loss: 0.0161\n",
      "Epoch 24/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.0157\n",
      "Epoch 25/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.0156\n",
      "Epoch 26/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.0156\n",
      "Epoch 27/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0246 - val_loss: 0.0157\n",
      "Epoch 28/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.0178\n",
      "Epoch 29/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0249 - val_loss: 0.0154\n",
      "Epoch 30/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0236 - val_loss: 0.0154\n",
      "Epoch 31/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.0154\n",
      "Epoch 32/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.0163\n",
      "Epoch 33/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.0159\n",
      "Epoch 34/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0226 - val_loss: 0.0153\n",
      "Epoch 35/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.0154\n",
      "Epoch 36/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0152\n",
      "Epoch 37/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.0154\n",
      "Epoch 38/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.0154\n",
      "Epoch 39/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.0155\n",
      "Epoch 40/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.0153\n",
      "Epoch 41/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.0154\n",
      "Epoch 42/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0155\n",
      "Epoch 43/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0158\n",
      "Epoch 44/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0151\n",
      "Epoch 45/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0152\n",
      "Epoch 46/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0158\n",
      "Epoch 47/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0152\n",
      "Epoch 48/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.0151\n",
      "Epoch 49/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0151\n",
      "Epoch 50/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0201 - val_loss: 0.0157\n",
      "Epoch 51/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0174\n",
      "Epoch 52/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0151\n",
      "Epoch 53/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0154\n",
      "Epoch 54/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0152\n",
      "Epoch 55/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0157\n",
      "Epoch 56/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0161\n",
      "Epoch 57/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0151\n",
      "Epoch 58/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0155\n",
      "Epoch 59/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0153\n",
      "Epoch 60/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0150\n",
      "Epoch 61/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0192 - val_loss: 0.0150\n",
      "Epoch 62/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0155\n",
      "Epoch 63/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0151\n",
      "Epoch 64/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0151\n",
      "Epoch 65/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0151\n",
      "Epoch 66/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0154\n",
      "Epoch 67/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0153\n",
      "Epoch 68/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0159\n",
      "Epoch 69/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0151\n",
      "Epoch 70/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0150\n",
      "Epoch 71/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0152\n",
      "Epoch 72/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0153\n",
      "Epoch 73/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0152\n",
      "Epoch 74/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0150\n",
      "Epoch 75/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0151\n",
      "Epoch 76/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0151\n",
      "Epoch 77/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0160\n",
      "Epoch 78/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0152\n",
      "Epoch 79/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0156\n",
      "Epoch 80/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0151\n",
      "Epoch 81/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0155\n",
      "Epoch 82/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0152\n",
      "Epoch 83/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0151\n",
      "Epoch 84/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0158\n",
      "Epoch 85/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0150\n",
      "Epoch 86/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0155\n",
      "Epoch 87/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0155\n",
      "Epoch 88/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0151\n",
      "Epoch 89/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0154\n",
      "Epoch 90/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0151\n",
      "Epoch 91/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0151\n",
      "Epoch 92/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0153\n",
      "Epoch 93/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0150\n",
      "Epoch 94/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0151\n",
      "Epoch 95/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0152\n",
      "Epoch 96/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0150\n",
      "Epoch 97/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0154\n",
      "Epoch 98/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0152\n",
      "Epoch 99/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0151\n",
      "Epoch 100/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.0164\n",
      "Epoch 101/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0159\n",
      "Epoch 102/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0151\n",
      "Epoch 103/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0151\n",
      "Epoch 104/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0153\n",
      "Epoch 105/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0151\n",
      "Epoch 106/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0152\n",
      "Epoch 107/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0154\n",
      "Epoch 108/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0150\n",
      "Epoch 109/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0154\n",
      "Epoch 110/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0151\n",
      "Epoch 111/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0149\n",
      "Epoch 112/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0150\n",
      "Epoch 113/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0150\n",
      "Epoch 114/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0151\n",
      "Epoch 115/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0155\n",
      "Epoch 116/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0151\n",
      "Epoch 117/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0154\n",
      "Epoch 118/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0152\n",
      "Epoch 119/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0151\n",
      "Epoch 120/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0158\n",
      "Epoch 121/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0157\n",
      "Epoch 122/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0158\n",
      "Epoch 123/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0150\n",
      "Epoch 124/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0151\n",
      "Epoch 125/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0150\n",
      "Epoch 126/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0152\n",
      "Epoch 127/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0159\n",
      "Epoch 128/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0150\n",
      "Epoch 129/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0152\n",
      "Epoch 130/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0150\n",
      "Epoch 131/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0150\n",
      "Epoch 132/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0150\n",
      "Epoch 133/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0151\n",
      "Epoch 134/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0151\n",
      "Epoch 135/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0151\n",
      "Epoch 136/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0153\n",
      "Epoch 137/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0150\n",
      "Epoch 138/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0150\n",
      "Epoch 139/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0151\n",
      "Epoch 140/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0159\n",
      "Epoch 141/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0150\n",
      "Epoch 142/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0151\n",
      "Epoch 143/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0149\n",
      "Epoch 144/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0149\n",
      "Epoch 145/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0151\n",
      "Epoch 146/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0156\n",
      "Epoch 147/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0152\n",
      "Epoch 148/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0151\n",
      "Epoch 149/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0151\n",
      "Epoch 150/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0150\n",
      "Epoch 151/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0150\n",
      "Epoch 152/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0169\n",
      "Epoch 153/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0150\n",
      "Epoch 154/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0153\n",
      "Epoch 155/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0157\n",
      "Epoch 156/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0197\n",
      "Epoch 157/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0152\n",
      "Epoch 158/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0151\n",
      "Epoch 159/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0152\n",
      "Epoch 160/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0150\n",
      "Epoch 161/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0153\n",
      "Epoch 162/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0153\n",
      "Epoch 163/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0155\n",
      "Epoch 164/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0151\n",
      "Epoch 165/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0151\n",
      "Epoch 167/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0151\n",
      "Epoch 168/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0149\n",
      "Epoch 169/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0154\n",
      "Epoch 170/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0150\n",
      "Epoch 171/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0155\n",
      "Epoch 172/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0149\n",
      "Epoch 173/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0151\n",
      "Epoch 174/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0155\n",
      "Epoch 175/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0149\n",
      "Epoch 176/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0154\n",
      "Epoch 177/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0155\n",
      "Epoch 178/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0151\n",
      "Epoch 179/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0149\n",
      "Epoch 180/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0149\n",
      "Epoch 181/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0154\n",
      "Epoch 182/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0149\n",
      "Epoch 183/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0152\n",
      "Epoch 184/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0149\n",
      "Epoch 185/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0150\n",
      "Epoch 186/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0149\n",
      "Epoch 187/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0156\n",
      "Epoch 188/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0150\n",
      "Epoch 189/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0157\n",
      "Epoch 190/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0149\n",
      "Epoch 191/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0162\n",
      "Epoch 192/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0152\n",
      "Epoch 193/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0149\n",
      "Epoch 194/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0150\n",
      "Epoch 195/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0149\n",
      "Epoch 196/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0149\n",
      "Epoch 197/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0153\n",
      "Epoch 198/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0149\n",
      "Epoch 199/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0150\n",
      "Epoch 200/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0150\n",
      "Epoch 201/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0151\n",
      "Epoch 202/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0149\n",
      "Epoch 203/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0153\n",
      "Epoch 204/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0150\n",
      "Epoch 205/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0149\n",
      "Epoch 206/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0148\n",
      "Epoch 207/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0167\n",
      "Epoch 208/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0154\n",
      "Epoch 209/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0155\n",
      "Epoch 210/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0150\n",
      "Epoch 211/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.0155\n",
      "Epoch 212/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.0153\n",
      "Epoch 213/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0150\n",
      "Epoch 214/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.0149\n",
      "Epoch 215/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.0155\n",
      "Epoch 216/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.0150\n",
      "Epoch 217/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0152\n",
      "Epoch 218/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0156\n",
      "Epoch 219/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0149\n",
      "Epoch 220/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0149\n",
      "Epoch 221/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0152\n",
      "Epoch 222/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0151\n",
      "Epoch 223/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0155\n",
      "Epoch 224/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0151\n",
      "Epoch 225/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0149\n",
      "Epoch 226/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0151\n",
      "Epoch 227/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0149\n",
      "Epoch 228/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0152\n",
      "Epoch 229/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0148\n",
      "Epoch 230/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0147\n",
      "Epoch 231/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0149\n",
      "Epoch 232/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0149\n",
      "Epoch 233/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0147\n",
      "Epoch 234/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0150\n",
      "Epoch 235/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0152\n",
      "Epoch 236/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0148\n",
      "Epoch 237/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0152\n",
      "Epoch 238/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0147\n",
      "Epoch 239/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0149\n",
      "Epoch 240/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 241/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0152\n",
      "Epoch 242/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0147\n",
      "Epoch 243/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 244/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0146\n",
      "Epoch 245/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0149\n",
      "Epoch 246/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0170\n",
      "Epoch 247/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0147\n",
      "Epoch 248/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0147\n",
      "Epoch 249/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0149\n",
      "Epoch 250/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0146\n",
      "Epoch 251/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0147\n",
      "Epoch 252/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.0145\n",
      "Epoch 253/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.0150\n",
      "Epoch 254/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0145\n",
      "Epoch 255/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 256/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0147\n",
      "Epoch 257/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0146\n",
      "Epoch 258/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0145\n",
      "Epoch 259/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0145\n",
      "Epoch 260/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0150\n",
      "Epoch 261/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0144\n",
      "Epoch 262/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0145 - val_loss: 0.0149\n",
      "Epoch 263/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0148\n",
      "Epoch 264/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0146\n",
      "Epoch 265/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0148\n",
      "Epoch 266/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0150\n",
      "Epoch 267/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0145\n",
      "Epoch 268/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0162\n",
      "Epoch 269/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0146\n",
      "Epoch 270/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0147\n",
      "Epoch 271/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0146\n",
      "Epoch 272/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0145\n",
      "Epoch 273/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0145 - val_loss: 0.0144\n",
      "Epoch 274/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0144\n",
      "Epoch 275/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0147\n",
      "Epoch 276/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0151\n",
      "Epoch 277/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0152\n",
      "Epoch 278/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0146\n",
      "Epoch 279/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0163\n",
      "Epoch 280/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0144\n",
      "Epoch 281/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0153\n",
      "Epoch 282/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0145\n",
      "Epoch 283/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0145\n",
      "Epoch 284/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0145\n",
      "Epoch 285/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0145\n",
      "Epoch 286/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0150\n",
      "Epoch 287/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0146\n",
      "Epoch 288/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0150\n",
      "Epoch 289/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0145 - val_loss: 0.0156\n",
      "Epoch 290/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0144\n",
      "Epoch 291/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0145\n",
      "Epoch 292/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0143\n",
      "Epoch 293/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0144\n",
      "Epoch 294/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0143\n",
      "Epoch 295/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0156\n",
      "Epoch 296/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0144\n",
      "Epoch 297/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0143\n",
      "Epoch 298/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0147\n",
      "Epoch 299/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0146\n",
      "Epoch 300/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0149\n",
      "Epoch 301/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0146\n",
      "Epoch 302/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0144\n",
      "Epoch 303/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0143\n",
      "Epoch 304/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0145\n",
      "Epoch 305/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0147\n",
      "Epoch 306/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0154\n",
      "Epoch 307/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0144\n",
      "Epoch 308/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0152\n",
      "Epoch 309/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0144\n",
      "Epoch 310/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0144\n",
      "Epoch 311/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0146\n",
      "Epoch 312/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0159\n",
      "Epoch 313/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0146\n",
      "Epoch 314/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0143\n",
      "Epoch 315/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0146\n",
      "Epoch 316/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.0143\n",
      "Epoch 317/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0144\n",
      "Epoch 318/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0148\n",
      "Epoch 319/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0143\n",
      "Epoch 320/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0149\n",
      "Epoch 321/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0143\n",
      "Epoch 322/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0148\n",
      "Epoch 323/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0150\n",
      "Epoch 324/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0143\n",
      "Epoch 325/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0143\n",
      "Epoch 326/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0143\n",
      "Epoch 327/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0142\n",
      "Epoch 328/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0149\n",
      "Epoch 329/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0143\n",
      "Epoch 330/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0143\n",
      "Epoch 331/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0143 - val_loss: 0.0144\n",
      "Epoch 332/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0142\n",
      "Epoch 333/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0146\n",
      "Epoch 334/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0179\n",
      "Epoch 335/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0144\n",
      "Epoch 336/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0146\n",
      "Epoch 337/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0143 - val_loss: 0.0146\n",
      "Epoch 338/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0144\n",
      "Epoch 339/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0146\n",
      "Epoch 340/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0143\n",
      "Epoch 341/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0142\n",
      "Epoch 342/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0143\n",
      "Epoch 343/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0144\n",
      "Epoch 344/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0144\n",
      "Epoch 345/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0144\n",
      "Epoch 346/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0143\n",
      "Epoch 347/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0143 - val_loss: 0.0143\n",
      "Epoch 348/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0142\n",
      "Epoch 349/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0142\n",
      "Epoch 350/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0145\n",
      "Epoch 351/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0144\n",
      "Epoch 352/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0142\n",
      "Epoch 353/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0164\n",
      "Epoch 354/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0147\n",
      "Epoch 355/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0143\n",
      "Epoch 356/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0143\n",
      "Epoch 357/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0151\n",
      "Epoch 358/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0144\n",
      "Epoch 359/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0143\n",
      "Epoch 360/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0142 - val_loss: 0.0144\n",
      "Epoch 361/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0142\n",
      "Epoch 362/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0143\n",
      "Epoch 363/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0147\n",
      "Epoch 364/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0149\n",
      "Epoch 365/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0147\n",
      "Epoch 366/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0141\n",
      "Epoch 367/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0142\n",
      "Epoch 368/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0143\n",
      "Epoch 369/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0145\n",
      "Epoch 370/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0144\n",
      "Epoch 371/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.0143\n",
      "Epoch 372/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0144\n",
      "Epoch 373/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0142\n",
      "Epoch 374/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0145\n",
      "Epoch 375/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0141\n",
      "Epoch 376/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0143\n",
      "Epoch 377/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0144\n",
      "Epoch 378/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0142\n",
      "Epoch 379/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0142\n",
      "Epoch 380/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0141\n",
      "Epoch 381/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0142\n",
      "Epoch 382/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 383/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0146\n",
      "Epoch 384/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0152\n",
      "Epoch 385/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0141\n",
      "Epoch 386/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0144\n",
      "Epoch 387/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0141\n",
      "Epoch 388/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0148\n",
      "Epoch 389/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0141\n",
      "Epoch 390/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0141\n",
      "Epoch 391/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0147\n",
      "Epoch 392/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0143\n",
      "Epoch 393/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0143\n",
      "Epoch 394/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.0141\n",
      "Epoch 395/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0146\n",
      "Epoch 396/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 397/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0146\n",
      "Epoch 398/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0145\n",
      "Epoch 399/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0146\n",
      "Epoch 400/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0142\n",
      "Epoch 401/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0147\n",
      "Epoch 402/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0141\n",
      "Epoch 403/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0145\n",
      "Epoch 404/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0142\n",
      "Epoch 405/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0147\n",
      "Epoch 406/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0141\n",
      "Epoch 407/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0140\n",
      "Epoch 408/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0141\n",
      "Epoch 409/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.0141\n",
      "Epoch 410/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 411/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0146\n",
      "Epoch 412/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0141\n",
      "Epoch 413/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0153\n",
      "Epoch 414/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0141\n",
      "Epoch 415/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0142\n",
      "Epoch 416/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0141\n",
      "Epoch 417/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0140\n",
      "Epoch 418/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0142\n",
      "Epoch 419/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0151\n",
      "Epoch 420/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0141\n",
      "Epoch 421/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0147\n",
      "Epoch 422/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0140\n",
      "Epoch 423/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 424/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0144\n",
      "Epoch 425/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0140\n",
      "Epoch 426/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0142\n",
      "Epoch 427/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 428/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0156\n",
      "Epoch 429/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0141\n",
      "Epoch 430/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0142\n",
      "Epoch 431/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0141\n",
      "Epoch 432/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0140\n",
      "Epoch 433/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 434/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0141\n",
      "Epoch 435/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0142\n",
      "Epoch 436/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 437/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0142\n",
      "Epoch 438/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 439/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0140\n",
      "Epoch 440/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0141\n",
      "Epoch 441/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0144\n",
      "Epoch 442/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0142\n",
      "Epoch 443/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0142\n",
      "Epoch 444/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0141\n",
      "Epoch 445/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 446/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0142\n",
      "Epoch 447/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 448/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 449/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 450/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0143\n",
      "Epoch 451/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0153\n",
      "Epoch 452/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0143\n",
      "Epoch 453/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.0141\n",
      "Epoch 454/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 455/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0145\n",
      "Epoch 456/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0140\n",
      "Epoch 457/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0145\n",
      "Epoch 458/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 459/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0139\n",
      "Epoch 460/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 461/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0140\n",
      "Epoch 462/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 463/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0140\n",
      "Epoch 464/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0154\n",
      "Epoch 465/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0141\n",
      "Epoch 466/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0153\n",
      "Epoch 467/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0143\n",
      "Epoch 468/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0146\n",
      "Epoch 469/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0141\n",
      "Epoch 470/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0143\n",
      "Epoch 471/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0148\n",
      "Epoch 472/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0142\n",
      "Epoch 473/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0141\n",
      "Epoch 474/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0140\n",
      "Epoch 475/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0143\n",
      "Epoch 476/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.0144\n",
      "Epoch 477/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 478/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0142\n",
      "Epoch 479/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 480/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 481/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0144\n",
      "Epoch 482/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0147\n",
      "Epoch 483/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0143 - val_loss: 0.0141\n",
      "Epoch 484/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0142\n",
      "Epoch 485/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0147\n",
      "Epoch 486/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0141\n",
      "Epoch 487/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0142\n",
      "Epoch 488/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 489/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0146\n",
      "Epoch 490/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0143\n",
      "Epoch 491/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 492/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0144\n",
      "Epoch 493/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0141\n",
      "Epoch 494/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0141\n",
      "Epoch 495/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0139\n",
      "Epoch 496/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0143\n",
      "Epoch 497/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 498/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0141\n",
      "Epoch 499/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 500/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 501/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0141\n",
      "Epoch 502/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0145\n",
      "Epoch 503/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0148\n",
      "Epoch 504/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0145\n",
      "Epoch 505/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0140\n",
      "Epoch 506/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 507/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0141\n",
      "Epoch 508/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0142\n",
      "Epoch 509/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0142\n",
      "Epoch 510/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0144\n",
      "Epoch 511/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0140\n",
      "Epoch 512/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 513/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 514/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0143\n",
      "Epoch 515/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0140\n",
      "Epoch 516/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0140\n",
      "Epoch 517/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0145\n",
      "Epoch 518/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 519/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 520/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 521/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0150\n",
      "Epoch 522/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0142\n",
      "Epoch 523/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0139\n",
      "Epoch 524/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0141\n",
      "Epoch 525/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0140\n",
      "Epoch 526/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0140\n",
      "Epoch 527/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 528/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0141\n",
      "Epoch 529/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0141\n",
      "Epoch 530/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 531/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0141\n",
      "Epoch 532/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0155\n",
      "Epoch 533/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.0141\n",
      "Epoch 534/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0141\n",
      "Epoch 535/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 536/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0139\n",
      "Epoch 537/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 538/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 539/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 540/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 541/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0139\n",
      "Epoch 542/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0143\n",
      "Epoch 543/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 544/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0146\n",
      "Epoch 545/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0142\n",
      "Epoch 546/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 547/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0150\n",
      "Epoch 548/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0141\n",
      "Epoch 549/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 550/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0144\n",
      "Epoch 551/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 552/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0144\n",
      "Epoch 553/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0139\n",
      "Epoch 554/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0139\n",
      "Epoch 555/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0139\n",
      "Epoch 556/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0148\n",
      "Epoch 557/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0141\n",
      "Epoch 558/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0140\n",
      "Epoch 559/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0140\n",
      "Epoch 560/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 561/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0144\n",
      "Epoch 562/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0141\n",
      "Epoch 563/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0145\n",
      "Epoch 564/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0139\n",
      "Epoch 565/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0143\n",
      "Epoch 566/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0139\n",
      "Epoch 567/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0150\n",
      "Epoch 568/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 569/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 570/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0142\n",
      "Epoch 571/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0141\n",
      "Epoch 572/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0143\n",
      "Epoch 573/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0140\n",
      "Epoch 574/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0174\n",
      "Epoch 575/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0146\n",
      "Epoch 576/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0142\n",
      "Epoch 577/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0142\n",
      "Epoch 578/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0141\n",
      "Epoch 579/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0143\n",
      "Epoch 580/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 581/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 582/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0145\n",
      "Epoch 583/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0141\n",
      "Epoch 584/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0139\n",
      "Epoch 585/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0157\n",
      "Epoch 586/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0140\n",
      "Epoch 587/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0139\n",
      "Epoch 588/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0140\n",
      "Epoch 589/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0145\n",
      "Epoch 590/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0159\n",
      "Epoch 591/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 592/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.0141\n",
      "Epoch 593/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0141\n",
      "Epoch 594/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 595/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0139\n",
      "Epoch 596/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0143\n",
      "Epoch 597/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 598/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0143\n",
      "Epoch 599/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0142\n",
      "Epoch 600/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0143\n",
      "Epoch 601/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0149\n",
      "Epoch 602/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0141\n",
      "Epoch 603/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.0142\n",
      "Epoch 604/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0149\n",
      "Epoch 605/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0141\n",
      "Epoch 606/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0146\n",
      "Epoch 607/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 608/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0142\n",
      "Epoch 609/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0145\n",
      "Epoch 610/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 611/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0146\n",
      "Epoch 612/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0141\n",
      "Epoch 613/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0142\n",
      "Epoch 614/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0146\n",
      "Epoch 615/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0142\n",
      "Epoch 616/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0162\n",
      "Epoch 617/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0140\n",
      "Epoch 618/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 619/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 620/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0139\n",
      "Epoch 621/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0140\n",
      "Epoch 622/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 623/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0142\n",
      "Epoch 624/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0140\n",
      "Epoch 625/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0141\n",
      "Epoch 626/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0150\n",
      "Epoch 627/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 628/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0143\n",
      "Epoch 629/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0142\n",
      "Epoch 630/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0148\n",
      "Epoch 631/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0140\n",
      "Epoch 632/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 633/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0146\n",
      "Epoch 634/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0150\n",
      "Epoch 635/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0139\n",
      "Epoch 636/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0146\n",
      "Epoch 637/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 638/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0139\n",
      "Epoch 639/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0147\n",
      "Epoch 640/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 641/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0145\n",
      "Epoch 642/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0141\n",
      "Epoch 643/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0145\n",
      "Epoch 644/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0141\n",
      "Epoch 645/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0146\n",
      "Epoch 646/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0143\n",
      "Epoch 647/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0146\n",
      "Epoch 648/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0140\n",
      "Epoch 649/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 650/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0143\n",
      "Epoch 651/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0155\n",
      "Epoch 652/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0140\n",
      "Epoch 653/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.0140\n",
      "Epoch 654/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 655/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0143\n",
      "Epoch 656/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0141\n",
      "Epoch 657/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 658/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0139\n",
      "Epoch 659/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.0149\n",
      "Epoch 660/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0143\n",
      "Epoch 661/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0140\n",
      "Epoch 662/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0141\n",
      "Epoch 663/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0146\n",
      "Epoch 664/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0142\n",
      "Epoch 665/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 666/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 667/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 668/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0143\n",
      "Epoch 669/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 670/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 671/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0139\n",
      "Epoch 672/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0141\n",
      "Epoch 673/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0140\n",
      "Epoch 674/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0140\n",
      "Epoch 675/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0141\n",
      "Epoch 676/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0141\n",
      "Epoch 677/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0142\n",
      "Epoch 678/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0147\n",
      "Epoch 679/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0143\n",
      "Epoch 680/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0142\n",
      "Epoch 681/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0145\n",
      "Epoch 682/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0139\n",
      "Epoch 683/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0140\n",
      "Epoch 684/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0141\n",
      "Epoch 685/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0145\n",
      "Epoch 686/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0139\n",
      "Epoch 687/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 688/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0151\n",
      "Epoch 689/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0142\n",
      "Epoch 690/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 691/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 692/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0140\n",
      "Epoch 693/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0139\n",
      "Epoch 694/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 695/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0142\n",
      "Epoch 696/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.0139\n",
      "Epoch 697/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0139\n",
      "Epoch 698/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0141\n",
      "Epoch 699/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 700/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0142\n",
      "Epoch 701/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 702/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0142\n",
      "Epoch 703/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0139\n",
      "Epoch 704/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0139\n",
      "Epoch 705/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0143\n",
      "Epoch 706/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0147\n",
      "Epoch 707/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0143\n",
      "Epoch 708/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0145\n",
      "Epoch 709/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0139\n",
      "Epoch 710/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0139\n",
      "Epoch 711/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 712/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0139\n",
      "Epoch 713/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.0139\n",
      "Epoch 714/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0141\n",
      "Epoch 715/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0139\n",
      "Epoch 716/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.0162\n",
      "Epoch 717/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0140\n",
      "Epoch 718/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0140\n",
      "Epoch 719/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0146\n",
      "Epoch 720/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0141\n",
      "Epoch 721/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0140\n",
      "Epoch 722/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0139\n",
      "Epoch 723/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0140\n",
      "Epoch 724/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 725/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0140\n",
      "Epoch 726/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0140\n",
      "Epoch 727/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0142\n",
      "Epoch 728/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0144\n",
      "Epoch 729/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 730/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0139\n",
      "Epoch 731/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 732/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0141\n",
      "Epoch 733/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0153\n",
      "Epoch 734/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0145\n",
      "Epoch 735/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 736/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 737/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0143\n",
      "Epoch 738/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0142\n",
      "Epoch 739/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0140\n",
      "Epoch 740/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0147\n",
      "Epoch 741/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0151\n",
      "Epoch 742/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 743/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0146\n",
      "Epoch 744/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0145\n",
      "Epoch 745/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0139\n",
      "Epoch 746/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0142\n",
      "Epoch 747/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0139\n",
      "Epoch 748/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0140\n",
      "Epoch 749/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0141\n",
      "Epoch 750/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0144\n",
      "Epoch 751/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0144\n",
      "Epoch 752/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0146\n",
      "Epoch 753/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 754/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0143\n",
      "Epoch 755/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 756/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0154\n",
      "Epoch 757/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0142\n",
      "Epoch 758/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0146\n",
      "Epoch 759/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0142\n",
      "Epoch 760/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0140\n",
      "Epoch 761/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0144\n",
      "Epoch 762/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0140\n",
      "Epoch 763/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0142\n",
      "Epoch 764/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0142\n",
      "Epoch 765/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 766/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0142\n",
      "Epoch 767/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0143\n",
      "Epoch 768/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0139\n",
      "Epoch 769/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0139\n",
      "Epoch 770/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0139\n",
      "Epoch 771/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0141\n",
      "Epoch 772/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0141\n",
      "Epoch 773/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0141\n",
      "Epoch 774/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0143\n",
      "Epoch 775/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 776/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0147\n",
      "Epoch 777/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0139\n",
      "Epoch 778/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0143\n",
      "Epoch 779/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 780/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0147\n",
      "Epoch 781/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0143\n",
      "Epoch 782/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0150\n",
      "Epoch 783/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 784/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.0139\n",
      "Epoch 785/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0142\n",
      "Epoch 786/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0140\n",
      "Epoch 787/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0143\n",
      "Epoch 788/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0139\n",
      "Epoch 789/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0139\n",
      "Epoch 790/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0139\n",
      "Epoch 791/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0139\n",
      "Epoch 792/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0144\n",
      "Epoch 793/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0139\n",
      "Epoch 794/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0144\n",
      "Epoch 795/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0141\n",
      "Epoch 796/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0139\n",
      "Epoch 797/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0140\n",
      "Epoch 798/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0142\n",
      "Epoch 799/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0148\n",
      "Epoch 800/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0141\n",
      "Epoch 801/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0148\n",
      "Epoch 802/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0143\n",
      "Epoch 803/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 804/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0152\n",
      "Epoch 805/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0139\n",
      "Epoch 806/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0139\n",
      "Epoch 807/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0140\n",
      "Epoch 808/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0139\n",
      "Epoch 809/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 810/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0140\n",
      "Epoch 811/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0139\n",
      "Epoch 812/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0141\n",
      "Epoch 813/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0139\n",
      "Epoch 814/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0140\n",
      "Epoch 815/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0143\n",
      "Epoch 00815: early stopping\n",
      "Epoch 1/10000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5362 - val_loss: 0.1171\n",
      "Epoch 2/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1269 - val_loss: 0.0366\n",
      "Epoch 3/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0927 - val_loss: 0.0317\n",
      "Epoch 4/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0832 - val_loss: 0.0320\n",
      "Epoch 5/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0766 - val_loss: 0.0327\n",
      "Epoch 6/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0692 - val_loss: 0.0273\n",
      "Epoch 7/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0629 - val_loss: 0.0243\n",
      "Epoch 8/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0214\n",
      "Epoch 9/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0527 - val_loss: 0.0188\n",
      "Epoch 10/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.0185\n",
      "Epoch 11/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0453 - val_loss: 0.0169\n",
      "Epoch 12/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0418 - val_loss: 0.0169\n",
      "Epoch 13/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0387 - val_loss: 0.0181\n",
      "Epoch 14/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0370 - val_loss: 0.0163\n",
      "Epoch 15/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0340 - val_loss: 0.0183\n",
      "Epoch 16/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0332 - val_loss: 0.0162\n",
      "Epoch 17/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0312 - val_loss: 0.0160\n",
      "Epoch 18/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0300 - val_loss: 0.0165\n",
      "Epoch 19/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0290 - val_loss: 0.0156\n",
      "Epoch 20/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.0160\n",
      "Epoch 21/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0163\n",
      "Epoch 22/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0264 - val_loss: 0.0161\n",
      "Epoch 23/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0259 - val_loss: 0.0157\n",
      "Epoch 24/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0252 - val_loss: 0.0157\n",
      "Epoch 25/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.0152\n",
      "Epoch 26/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0244 - val_loss: 0.0156\n",
      "Epoch 27/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.0158\n",
      "Epoch 28/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0238 - val_loss: 0.0155\n",
      "Epoch 29/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0231 - val_loss: 0.0175\n",
      "Epoch 30/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.0154\n",
      "Epoch 31/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.0152\n",
      "Epoch 32/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.0158\n",
      "Epoch 33/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0219 - val_loss: 0.0156\n",
      "Epoch 34/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.0154\n",
      "Epoch 35/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.0156\n",
      "Epoch 36/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0215 - val_loss: 0.0156\n",
      "Epoch 37/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0215 - val_loss: 0.0170\n",
      "Epoch 38/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0221 - val_loss: 0.0149\n",
      "Epoch 39/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0149\n",
      "Epoch 40/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0154\n",
      "Epoch 41/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0208 - val_loss: 0.0145\n",
      "Epoch 42/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0203 - val_loss: 0.0147\n",
      "Epoch 43/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0142\n",
      "Epoch 44/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0140\n",
      "Epoch 45/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0143\n",
      "Epoch 46/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0137\n",
      "Epoch 47/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0131\n",
      "Epoch 48/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0190 - val_loss: 0.0129\n",
      "Epoch 49/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0186 - val_loss: 0.0127\n",
      "Epoch 50/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0128\n",
      "Epoch 51/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0127\n",
      "Epoch 52/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0131\n",
      "Epoch 53/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0125\n",
      "Epoch 54/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.0129\n",
      "Epoch 55/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0125\n",
      "Epoch 56/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0125\n",
      "Epoch 57/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0123\n",
      "Epoch 58/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0129\n",
      "Epoch 59/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0123\n",
      "Epoch 60/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0143\n",
      "Epoch 61/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0179 - val_loss: 0.0126\n",
      "Epoch 62/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0168\n",
      "Epoch 63/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0124\n",
      "Epoch 64/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0131\n",
      "Epoch 65/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0129\n",
      "Epoch 66/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0122\n",
      "Epoch 67/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0124\n",
      "Epoch 68/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0124\n",
      "Epoch 69/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0122\n",
      "Epoch 70/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0140\n",
      "Epoch 71/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0124\n",
      "Epoch 72/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0122\n",
      "Epoch 73/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0121\n",
      "Epoch 74/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0122\n",
      "Epoch 75/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0127\n",
      "Epoch 76/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0125\n",
      "Epoch 77/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0121\n",
      "Epoch 78/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0121\n",
      "Epoch 79/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0122\n",
      "Epoch 80/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0119\n",
      "Epoch 81/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0120\n",
      "Epoch 82/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0132\n",
      "Epoch 83/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0123\n",
      "Epoch 84/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0124\n",
      "Epoch 85/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0131\n",
      "Epoch 86/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0137\n",
      "Epoch 87/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0127\n",
      "Epoch 88/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0130\n",
      "Epoch 89/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0125\n",
      "Epoch 90/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0128\n",
      "Epoch 91/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0128\n",
      "Epoch 92/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0123\n",
      "Epoch 93/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0123\n",
      "Epoch 94/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0135\n",
      "Epoch 95/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0121\n",
      "Epoch 96/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0124\n",
      "Epoch 97/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0122\n",
      "Epoch 98/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0123\n",
      "Epoch 99/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.0122\n",
      "Epoch 100/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.0120\n",
      "Epoch 101/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.0121\n",
      "Epoch 102/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.0122\n",
      "Epoch 103/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.0123\n",
      "Epoch 104/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.0126\n",
      "Epoch 105/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.0127\n",
      "Epoch 106/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.0123\n",
      "Epoch 107/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0130\n",
      "Epoch 108/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0122\n",
      "Epoch 109/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.0122\n",
      "Epoch 110/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.0127\n",
      "Epoch 111/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.0125\n",
      "Epoch 112/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.0121\n",
      "Epoch 113/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.0130\n",
      "Epoch 114/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.0130\n",
      "Epoch 115/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.0125\n",
      "Epoch 116/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.0122\n",
      "Epoch 117/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.0121\n",
      "Epoch 118/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0144 - val_loss: 0.0120\n",
      "Epoch 119/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.0128\n",
      "Epoch 120/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.0120\n",
      "Epoch 121/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0122\n",
      "Epoch 122/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0135\n",
      "Epoch 123/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0120\n",
      "Epoch 124/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0120\n",
      "Epoch 125/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0125\n",
      "Epoch 126/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0121\n",
      "Epoch 127/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0121\n",
      "Epoch 128/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0119\n",
      "Epoch 129/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0121\n",
      "Epoch 130/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0142 - val_loss: 0.0120\n",
      "Epoch 131/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0122\n",
      "Epoch 132/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0120\n",
      "Epoch 133/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0142 - val_loss: 0.0118\n",
      "Epoch 134/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0122\n",
      "Epoch 135/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0119\n",
      "Epoch 136/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0118\n",
      "Epoch 137/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0121\n",
      "Epoch 138/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0125\n",
      "Epoch 139/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0121\n",
      "Epoch 140/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0120\n",
      "Epoch 141/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0120\n",
      "Epoch 142/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0137\n",
      "Epoch 143/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0121\n",
      "Epoch 144/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0120\n",
      "Epoch 145/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0142 - val_loss: 0.0132\n",
      "Epoch 146/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.0122\n",
      "Epoch 147/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0127\n",
      "Epoch 148/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.0123\n",
      "Epoch 149/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0121\n",
      "Epoch 150/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0120\n",
      "Epoch 151/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0136 - val_loss: 0.0121\n",
      "Epoch 152/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0121\n",
      "Epoch 153/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0121\n",
      "Epoch 154/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0122\n",
      "Epoch 155/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0120\n",
      "Epoch 156/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.0126\n",
      "Epoch 157/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0121\n",
      "Epoch 158/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0121\n",
      "Epoch 159/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0126\n",
      "Epoch 160/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0124\n",
      "Epoch 161/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0121\n",
      "Epoch 162/10000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0119\n",
      "Epoch 163/10000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0120\n",
      "Epoch 164/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0119\n",
      "Epoch 165/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.0133\n",
      "Epoch 166/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0120\n",
      "Epoch 167/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0119\n",
      "Epoch 168/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0126\n",
      "Epoch 169/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0126\n",
      "Epoch 170/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.0120\n",
      "Epoch 171/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0124\n",
      "Epoch 172/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0125\n",
      "Epoch 173/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0121\n",
      "Epoch 174/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0122\n",
      "Epoch 175/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0123\n",
      "Epoch 176/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.0120\n",
      "Epoch 177/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.0123\n",
      "Epoch 178/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0123\n",
      "Epoch 179/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.0130\n",
      "Epoch 180/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0120\n",
      "Epoch 181/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0142\n",
      "Epoch 182/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0130\n",
      "Epoch 183/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0121\n",
      "Epoch 184/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0122\n",
      "Epoch 185/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0122\n",
      "Epoch 186/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0119\n",
      "Epoch 187/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0123\n",
      "Epoch 188/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.0119\n",
      "Epoch 189/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0121\n",
      "Epoch 190/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0120\n",
      "Epoch 191/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0127\n",
      "Epoch 192/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0121\n",
      "Epoch 193/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0123\n",
      "Epoch 194/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0122\n",
      "Epoch 195/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0122\n",
      "Epoch 196/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.0120\n",
      "Epoch 197/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0122\n",
      "Epoch 198/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0122\n",
      "Epoch 199/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0121\n",
      "Epoch 200/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0128\n",
      "Epoch 201/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0124\n",
      "Epoch 202/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0121\n",
      "Epoch 203/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0126\n",
      "Epoch 204/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0124\n",
      "Epoch 205/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0121\n",
      "Epoch 206/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0122\n",
      "Epoch 207/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0135\n",
      "Epoch 208/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.0125\n",
      "Epoch 209/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0121\n",
      "Epoch 210/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0121\n",
      "Epoch 211/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0125\n",
      "Epoch 212/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0123\n",
      "Epoch 213/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0120\n",
      "Epoch 214/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0121\n",
      "Epoch 215/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.0122\n",
      "Epoch 216/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0119\n",
      "Epoch 217/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0121\n",
      "Epoch 218/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0121\n",
      "Epoch 219/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.0120\n",
      "Epoch 220/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0121\n",
      "Epoch 221/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0121\n",
      "Epoch 222/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0126\n",
      "Epoch 223/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.0121\n",
      "Epoch 224/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0121\n",
      "Epoch 225/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0119\n",
      "Epoch 226/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0130\n",
      "Epoch 227/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0120\n",
      "Epoch 228/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0120\n",
      "Epoch 229/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0120\n",
      "Epoch 230/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.0126\n",
      "Epoch 231/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0131\n",
      "Epoch 232/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0123\n",
      "Epoch 233/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.0121\n",
      "Epoch 234/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0121\n",
      "Epoch 235/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0118\n",
      "Epoch 236/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0122\n",
      "Epoch 00236: early stopping\n",
      "Epoch 1/10000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5737 - val_loss: 0.1411\n",
      "Epoch 2/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1366 - val_loss: 0.0357\n",
      "Epoch 3/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0939 - val_loss: 0.0319\n",
      "Epoch 4/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0834 - val_loss: 0.0296\n",
      "Epoch 5/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0761 - val_loss: 0.0291\n",
      "Epoch 6/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.0260\n",
      "Epoch 7/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0634 - val_loss: 0.0291\n",
      "Epoch 8/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0196\n",
      "Epoch 9/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0514 - val_loss: 0.0184\n",
      "Epoch 10/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.0190\n",
      "Epoch 11/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0443 - val_loss: 0.0178\n",
      "Epoch 12/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0415 - val_loss: 0.0161\n",
      "Epoch 13/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0373 - val_loss: 0.0160\n",
      "Epoch 14/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0348 - val_loss: 0.0165\n",
      "Epoch 15/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0330 - val_loss: 0.0169\n",
      "Epoch 16/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0314 - val_loss: 0.0165\n",
      "Epoch 17/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0308 - val_loss: 0.0159\n",
      "Epoch 18/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0289 - val_loss: 0.0163\n",
      "Epoch 19/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0283 - val_loss: 0.0157\n",
      "Epoch 20/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.0152\n",
      "Epoch 21/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.0154\n",
      "Epoch 22/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0256 - val_loss: 0.0155\n",
      "Epoch 23/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.0144\n",
      "Epoch 24/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0238 - val_loss: 0.0150\n",
      "Epoch 25/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.0139\n",
      "Epoch 26/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.0134\n",
      "Epoch 27/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0226 - val_loss: 0.0131\n",
      "Epoch 28/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0221 - val_loss: 0.0129\n",
      "Epoch 29/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.0123\n",
      "Epoch 30/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0210 - val_loss: 0.0125\n",
      "Epoch 31/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.0123\n",
      "Epoch 32/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0212 - val_loss: 0.0123\n",
      "Epoch 33/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0207 - val_loss: 0.0125\n",
      "Epoch 34/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0128\n",
      "Epoch 35/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0123\n",
      "Epoch 36/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0121\n",
      "Epoch 37/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0196 - val_loss: 0.0119\n",
      "Epoch 38/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0139\n",
      "Epoch 39/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0199 - val_loss: 0.0119\n",
      "Epoch 40/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0188 - val_loss: 0.0122\n",
      "Epoch 41/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0120\n",
      "Epoch 42/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0117\n",
      "Epoch 43/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0117\n",
      "Epoch 44/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0120\n",
      "Epoch 45/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0117\n",
      "Epoch 46/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0124\n",
      "Epoch 47/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0185 - val_loss: 0.0118\n",
      "Epoch 48/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0177 - val_loss: 0.0118\n",
      "Epoch 49/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0116\n",
      "Epoch 50/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0121\n",
      "Epoch 51/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0114\n",
      "Epoch 52/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.0118\n",
      "Epoch 53/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0117\n",
      "Epoch 54/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0114\n",
      "Epoch 55/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0133\n",
      "Epoch 56/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0108\n",
      "Epoch 57/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0109\n",
      "Epoch 58/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0103\n",
      "Epoch 59/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0113\n",
      "Epoch 60/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0098\n",
      "Epoch 61/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0103\n",
      "Epoch 62/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0097\n",
      "Epoch 63/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0095\n",
      "Epoch 64/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0095\n",
      "Epoch 65/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0096\n",
      "Epoch 66/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0099\n",
      "Epoch 67/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0091\n",
      "Epoch 68/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.0094\n",
      "Epoch 69/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0090\n",
      "Epoch 70/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0100\n",
      "Epoch 71/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0093\n",
      "Epoch 72/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0092\n",
      "Epoch 73/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0100\n",
      "Epoch 74/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.0105\n",
      "Epoch 75/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.0109\n",
      "Epoch 76/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0096\n",
      "Epoch 77/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.0091\n",
      "Epoch 78/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0090\n",
      "Epoch 79/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0096\n",
      "Epoch 80/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0090\n",
      "Epoch 81/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0090\n",
      "Epoch 82/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.0089\n",
      "Epoch 83/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.0088\n",
      "Epoch 84/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.0090\n",
      "Epoch 85/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0090\n",
      "Epoch 86/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0098\n",
      "Epoch 87/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0090\n",
      "Epoch 88/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.0093\n",
      "Epoch 89/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0088\n",
      "Epoch 90/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0088\n",
      "Epoch 91/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0092\n",
      "Epoch 92/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0091\n",
      "Epoch 93/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0116\n",
      "Epoch 94/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.0091\n",
      "Epoch 95/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0089\n",
      "Epoch 96/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0098\n",
      "Epoch 97/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0095\n",
      "Epoch 98/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0091\n",
      "Epoch 99/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0096\n",
      "Epoch 100/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.0088\n",
      "Epoch 101/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0093\n",
      "Epoch 102/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0095\n",
      "Epoch 103/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.0089\n",
      "Epoch 104/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0090\n",
      "Epoch 105/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.0096\n",
      "Epoch 106/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0093\n",
      "Epoch 107/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.0090\n",
      "Epoch 108/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.0089\n",
      "Epoch 109/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0088\n",
      "Epoch 110/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0104\n",
      "Epoch 111/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0088\n",
      "Epoch 112/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.0090\n",
      "Epoch 113/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0091\n",
      "Epoch 114/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.0096\n",
      "Epoch 115/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.0088\n",
      "Epoch 116/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0089\n",
      "Epoch 117/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0088\n",
      "Epoch 118/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.0091\n",
      "Epoch 119/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0091\n",
      "Epoch 120/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.0090\n",
      "Epoch 121/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0090\n",
      "Epoch 122/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0087\n",
      "Epoch 123/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0088\n",
      "Epoch 124/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0088\n",
      "Epoch 125/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0087\n",
      "Epoch 126/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0092\n",
      "Epoch 127/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0087\n",
      "Epoch 128/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0089\n",
      "Epoch 129/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 130/10000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0088\n",
      "Epoch 131/10000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.0089\n",
      "Epoch 132/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 133/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0086\n",
      "Epoch 134/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0092\n",
      "Epoch 135/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0086\n",
      "Epoch 136/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0090\n",
      "Epoch 137/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0090\n",
      "Epoch 138/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0088\n",
      "Epoch 139/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0094\n",
      "Epoch 140/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0087\n",
      "Epoch 141/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0088\n",
      "Epoch 142/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0092\n",
      "Epoch 143/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0086\n",
      "Epoch 144/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0088\n",
      "Epoch 145/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0088\n",
      "Epoch 146/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0087\n",
      "Epoch 147/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 148/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0087\n",
      "Epoch 149/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0090\n",
      "Epoch 150/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0114\n",
      "Epoch 151/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0098\n",
      "Epoch 152/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.0088\n",
      "Epoch 153/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.0088\n",
      "Epoch 154/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0089\n",
      "Epoch 155/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0086\n",
      "Epoch 156/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0086\n",
      "Epoch 157/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0092\n",
      "Epoch 158/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0089\n",
      "Epoch 159/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0095\n",
      "Epoch 160/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0089\n",
      "Epoch 161/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0087\n",
      "Epoch 162/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0087\n",
      "Epoch 163/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0087\n",
      "Epoch 164/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0089\n",
      "Epoch 165/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0111\n",
      "Epoch 166/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0108\n",
      "Epoch 167/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0090\n",
      "Epoch 168/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0091\n",
      "Epoch 169/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0086\n",
      "Epoch 170/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0087\n",
      "Epoch 171/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0091\n",
      "Epoch 172/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0091\n",
      "Epoch 173/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0088\n",
      "Epoch 174/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0087\n",
      "Epoch 175/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0088\n",
      "Epoch 176/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0105 - val_loss: 0.0090\n",
      "Epoch 177/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0104 - val_loss: 0.0089\n",
      "Epoch 178/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0103 - val_loss: 0.0094\n",
      "Epoch 179/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0092\n",
      "Epoch 180/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0091\n",
      "Epoch 181/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0086\n",
      "Epoch 182/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0084\n",
      "Epoch 183/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0089\n",
      "Epoch 184/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0088\n",
      "Epoch 185/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0085\n",
      "Epoch 186/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0109\n",
      "Epoch 187/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0093\n",
      "Epoch 188/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0086\n",
      "Epoch 189/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0085\n",
      "Epoch 190/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0090\n",
      "Epoch 191/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0089\n",
      "Epoch 192/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0087\n",
      "Epoch 193/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0086\n",
      "Epoch 194/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0092\n",
      "Epoch 195/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0084\n",
      "Epoch 196/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0089\n",
      "Epoch 197/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0085\n",
      "Epoch 198/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0085\n",
      "Epoch 199/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 200/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0086\n",
      "Epoch 201/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0087\n",
      "Epoch 202/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0087\n",
      "Epoch 203/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0093\n",
      "Epoch 204/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0084\n",
      "Epoch 205/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0088\n",
      "Epoch 206/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0086\n",
      "Epoch 207/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0087\n",
      "Epoch 208/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0083\n",
      "Epoch 209/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0084\n",
      "Epoch 210/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0083\n",
      "Epoch 211/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 212/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0089\n",
      "Epoch 213/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0089\n",
      "Epoch 214/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0083\n",
      "Epoch 215/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0105\n",
      "Epoch 216/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0085\n",
      "Epoch 217/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0086\n",
      "Epoch 218/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0084\n",
      "Epoch 219/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0083\n",
      "Epoch 220/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0086\n",
      "Epoch 221/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0085\n",
      "Epoch 222/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0083\n",
      "Epoch 223/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0095\n",
      "Epoch 224/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0083\n",
      "Epoch 225/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0086\n",
      "Epoch 226/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0086\n",
      "Epoch 227/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0082\n",
      "Epoch 228/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0083\n",
      "Epoch 229/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0083\n",
      "Epoch 230/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0083\n",
      "Epoch 231/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0085\n",
      "Epoch 232/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0086\n",
      "Epoch 233/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0081\n",
      "Epoch 234/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0085\n",
      "Epoch 235/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0083\n",
      "Epoch 236/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0084\n",
      "Epoch 237/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0083\n",
      "Epoch 238/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0080\n",
      "Epoch 239/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0084\n",
      "Epoch 240/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0081\n",
      "Epoch 241/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0080\n",
      "Epoch 242/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0081\n",
      "Epoch 243/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0081\n",
      "Epoch 244/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0095\n",
      "Epoch 245/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 246/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0081\n",
      "Epoch 247/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0081\n",
      "Epoch 248/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0080\n",
      "Epoch 249/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0084\n",
      "Epoch 250/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0083\n",
      "Epoch 251/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0081\n",
      "Epoch 252/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0081\n",
      "Epoch 253/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0083\n",
      "Epoch 254/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0080\n",
      "Epoch 255/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0080\n",
      "Epoch 256/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0084\n",
      "Epoch 257/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0093\n",
      "Epoch 258/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0091\n",
      "Epoch 259/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0082\n",
      "Epoch 260/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0083\n",
      "Epoch 261/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0081\n",
      "Epoch 262/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0080\n",
      "Epoch 263/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0084\n",
      "Epoch 264/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0080\n",
      "Epoch 265/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0109\n",
      "Epoch 266/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0089\n",
      "Epoch 267/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0082\n",
      "Epoch 268/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0082\n",
      "Epoch 269/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0082\n",
      "Epoch 270/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0082\n",
      "Epoch 271/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0082\n",
      "Epoch 272/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0082\n",
      "Epoch 273/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0086\n",
      "Epoch 274/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0088\n",
      "Epoch 275/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0081\n",
      "Epoch 276/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0083\n",
      "Epoch 277/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0080\n",
      "Epoch 278/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0082\n",
      "Epoch 279/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0084\n",
      "Epoch 280/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0090\n",
      "Epoch 281/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0084\n",
      "Epoch 282/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0081\n",
      "Epoch 283/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0079\n",
      "Epoch 284/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0080\n",
      "Epoch 285/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0082\n",
      "Epoch 286/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0079\n",
      "Epoch 287/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0080\n",
      "Epoch 288/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0080\n",
      "Epoch 289/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0097\n",
      "Epoch 290/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0083\n",
      "Epoch 291/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0088\n",
      "Epoch 292/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0079\n",
      "Epoch 293/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0090\n",
      "Epoch 294/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0080\n",
      "Epoch 295/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0080\n",
      "Epoch 296/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0091\n",
      "Epoch 297/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0080\n",
      "Epoch 298/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0079\n",
      "Epoch 299/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 300/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0081\n",
      "Epoch 301/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0082\n",
      "Epoch 302/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0084\n",
      "Epoch 303/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0087\n",
      "Epoch 304/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0080\n",
      "Epoch 305/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0079\n",
      "Epoch 306/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0078\n",
      "Epoch 307/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0080\n",
      "Epoch 308/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0079\n",
      "Epoch 309/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0078\n",
      "Epoch 310/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0079\n",
      "Epoch 311/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0079\n",
      "Epoch 312/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0077\n",
      "Epoch 313/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0081\n",
      "Epoch 314/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0090\n",
      "Epoch 315/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0080\n",
      "Epoch 316/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0080\n",
      "Epoch 317/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0077\n",
      "Epoch 318/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0076\n",
      "Epoch 319/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0077\n",
      "Epoch 320/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0083\n",
      "Epoch 321/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0082\n",
      "Epoch 322/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0079\n",
      "Epoch 323/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0086\n",
      "Epoch 324/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0086\n",
      "Epoch 325/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0077\n",
      "Epoch 326/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 327/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 328/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0076\n",
      "Epoch 329/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0094\n",
      "Epoch 330/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0076\n",
      "Epoch 331/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 332/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0076\n",
      "Epoch 333/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0082\n",
      "Epoch 334/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0077\n",
      "Epoch 335/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0077\n",
      "Epoch 336/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0075\n",
      "Epoch 337/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0078\n",
      "Epoch 338/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0074\n",
      "Epoch 339/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 340/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0074\n",
      "Epoch 341/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0077\n",
      "Epoch 342/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0078\n",
      "Epoch 343/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0074\n",
      "Epoch 344/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0081\n",
      "Epoch 345/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0074\n",
      "Epoch 346/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0076\n",
      "Epoch 347/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0079\n",
      "Epoch 348/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0078\n",
      "Epoch 349/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0076\n",
      "Epoch 350/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0075\n",
      "Epoch 351/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0075\n",
      "Epoch 352/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0073\n",
      "Epoch 353/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0077\n",
      "Epoch 354/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0074\n",
      "Epoch 355/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0075\n",
      "Epoch 356/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0074\n",
      "Epoch 357/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0074\n",
      "Epoch 358/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0079\n",
      "Epoch 359/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0073\n",
      "Epoch 360/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0078\n",
      "Epoch 361/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0075\n",
      "Epoch 362/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0080\n",
      "Epoch 363/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0077\n",
      "Epoch 364/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0114\n",
      "Epoch 365/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0082\n",
      "Epoch 366/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0075\n",
      "Epoch 367/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 368/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0074\n",
      "Epoch 369/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 370/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0074\n",
      "Epoch 371/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0074\n",
      "Epoch 372/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0076\n",
      "Epoch 373/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0074\n",
      "Epoch 374/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0074\n",
      "Epoch 375/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 376/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0073\n",
      "Epoch 377/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0073\n",
      "Epoch 378/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0072\n",
      "Epoch 379/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0074\n",
      "Epoch 380/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0078\n",
      "Epoch 381/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0075\n",
      "Epoch 382/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 383/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0077\n",
      "Epoch 384/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0076\n",
      "Epoch 385/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0092\n",
      "Epoch 386/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0074\n",
      "Epoch 387/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0080\n",
      "Epoch 388/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0076\n",
      "Epoch 389/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0074\n",
      "Epoch 390/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0079\n",
      "Epoch 391/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0074\n",
      "Epoch 392/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0073\n",
      "Epoch 393/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0075\n",
      "Epoch 394/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0074\n",
      "Epoch 395/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0074\n",
      "Epoch 396/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0081\n",
      "Epoch 397/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0074\n",
      "Epoch 398/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0075\n",
      "Epoch 399/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0075\n",
      "Epoch 400/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0078\n",
      "Epoch 401/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0090\n",
      "Epoch 402/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0077\n",
      "Epoch 403/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0076\n",
      "Epoch 404/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0079\n",
      "Epoch 405/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0076\n",
      "Epoch 406/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0074\n",
      "Epoch 407/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0072\n",
      "Epoch 408/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0073\n",
      "Epoch 409/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 410/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0078\n",
      "Epoch 411/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0072\n",
      "Epoch 412/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0074\n",
      "Epoch 413/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0074\n",
      "Epoch 414/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0075\n",
      "Epoch 415/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0077\n",
      "Epoch 416/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0079\n",
      "Epoch 417/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0076\n",
      "Epoch 418/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0074\n",
      "Epoch 419/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0073\n",
      "Epoch 420/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0076\n",
      "Epoch 421/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0080\n",
      "Epoch 422/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0073\n",
      "Epoch 423/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0076\n",
      "Epoch 424/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0075\n",
      "Epoch 425/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0080\n",
      "Epoch 426/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0090\n",
      "Epoch 427/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0075\n",
      "Epoch 428/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0074\n",
      "Epoch 429/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0072\n",
      "Epoch 430/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0075\n",
      "Epoch 431/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0074\n",
      "Epoch 432/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0072\n",
      "Epoch 433/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0077\n",
      "Epoch 434/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0078\n",
      "Epoch 435/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0086\n",
      "Epoch 436/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0078\n",
      "Epoch 437/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0074\n",
      "Epoch 438/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0074\n",
      "Epoch 439/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0073\n",
      "Epoch 440/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0072\n",
      "Epoch 441/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0074\n",
      "Epoch 442/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0074\n",
      "Epoch 443/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0075\n",
      "Epoch 444/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0076\n",
      "Epoch 445/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0081\n",
      "Epoch 446/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0075\n",
      "Epoch 447/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0076\n",
      "Epoch 448/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0123\n",
      "Epoch 449/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0096\n",
      "Epoch 450/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0075\n",
      "Epoch 451/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0073\n",
      "Epoch 452/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0074\n",
      "Epoch 453/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0076\n",
      "Epoch 454/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0088\n",
      "Epoch 455/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0076\n",
      "Epoch 456/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0112\n",
      "Epoch 457/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0077\n",
      "Epoch 458/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0075\n",
      "Epoch 459/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0073\n",
      "Epoch 460/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0074\n",
      "Epoch 461/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0072\n",
      "Epoch 462/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0079\n",
      "Epoch 463/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0072\n",
      "Epoch 464/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0074\n",
      "Epoch 465/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0077\n",
      "Epoch 466/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0072\n",
      "Epoch 467/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0073\n",
      "Epoch 468/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0072\n",
      "Epoch 469/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0073\n",
      "Epoch 470/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0073\n",
      "Epoch 471/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0071\n",
      "Epoch 472/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0079\n",
      "Epoch 473/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0073\n",
      "Epoch 474/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 475/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0077\n",
      "Epoch 476/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0076\n",
      "Epoch 477/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0078\n",
      "Epoch 478/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0077\n",
      "Epoch 479/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0073\n",
      "Epoch 480/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0073\n",
      "Epoch 481/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0079\n",
      "Epoch 482/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0072\n",
      "Epoch 483/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0076\n",
      "Epoch 484/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0072\n",
      "Epoch 485/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0088\n",
      "Epoch 486/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0080\n",
      "Epoch 487/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0072\n",
      "Epoch 488/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0075\n",
      "Epoch 489/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0073\n",
      "Epoch 490/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0073\n",
      "Epoch 491/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0092\n",
      "Epoch 492/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0080\n",
      "Epoch 493/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0074\n",
      "Epoch 494/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0074\n",
      "Epoch 495/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0076\n",
      "Epoch 496/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0073\n",
      "Epoch 497/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0080\n",
      "Epoch 498/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 499/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0073\n",
      "Epoch 500/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0071\n",
      "Epoch 501/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 502/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 503/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 504/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0073\n",
      "Epoch 505/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0073\n",
      "Epoch 506/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0072\n",
      "Epoch 507/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0109\n",
      "Epoch 508/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0079\n",
      "Epoch 509/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0076\n",
      "Epoch 510/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0072\n",
      "Epoch 511/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0080\n",
      "Epoch 512/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0077\n",
      "Epoch 513/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0076\n",
      "Epoch 514/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0073\n",
      "Epoch 515/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0071\n",
      "Epoch 516/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0074\n",
      "Epoch 517/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0071\n",
      "Epoch 518/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0080\n",
      "Epoch 519/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0072\n",
      "Epoch 520/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0071\n",
      "Epoch 521/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0074\n",
      "Epoch 522/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0076\n",
      "Epoch 523/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 524/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0072\n",
      "Epoch 525/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0079\n",
      "Epoch 526/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0079\n",
      "Epoch 527/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0075\n",
      "Epoch 528/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0074\n",
      "Epoch 529/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0084\n",
      "Epoch 530/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0075\n",
      "Epoch 531/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0072\n",
      "Epoch 532/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0076\n",
      "Epoch 533/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0077\n",
      "Epoch 534/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0073\n",
      "Epoch 535/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0073\n",
      "Epoch 536/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0071\n",
      "Epoch 537/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0072\n",
      "Epoch 538/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 539/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0074\n",
      "Epoch 540/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0073\n",
      "Epoch 541/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0071\n",
      "Epoch 542/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0073\n",
      "Epoch 543/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0071\n",
      "Epoch 544/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0073\n",
      "Epoch 545/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0071\n",
      "Epoch 546/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0071\n",
      "Epoch 547/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0072\n",
      "Epoch 548/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0083\n",
      "Epoch 549/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0080\n",
      "Epoch 550/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0079\n",
      "Epoch 551/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0073\n",
      "Epoch 552/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0074\n",
      "Epoch 553/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0084\n",
      "Epoch 554/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 555/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0075\n",
      "Epoch 556/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0072\n",
      "Epoch 557/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0080\n",
      "Epoch 558/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0073\n",
      "Epoch 559/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 560/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0076\n",
      "Epoch 561/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0076\n",
      "Epoch 562/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0082\n",
      "Epoch 563/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0077\n",
      "Epoch 564/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0073\n",
      "Epoch 565/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 566/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0074\n",
      "Epoch 567/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0091\n",
      "Epoch 568/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0073\n",
      "Epoch 569/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0076\n",
      "Epoch 570/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0073\n",
      "Epoch 571/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0072\n",
      "Epoch 00571: early stopping\n",
      "Epoch 1/10000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5570 - val_loss: 0.1079\n",
      "Epoch 2/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1242 - val_loss: 0.0353\n",
      "Epoch 3/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0933 - val_loss: 0.0311\n",
      "Epoch 4/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0826 - val_loss: 0.0281\n",
      "Epoch 5/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0742 - val_loss: 0.0255\n",
      "Epoch 6/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0690 - val_loss: 0.0222\n",
      "Epoch 7/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0620 - val_loss: 0.0197\n",
      "Epoch 8/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0566 - val_loss: 0.0190\n",
      "Epoch 9/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0528 - val_loss: 0.0179\n",
      "Epoch 10/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0170\n",
      "Epoch 11/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0442 - val_loss: 0.0168\n",
      "Epoch 12/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0412 - val_loss: 0.0173\n",
      "Epoch 13/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0386 - val_loss: 0.0162\n",
      "Epoch 14/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.0177\n",
      "Epoch 15/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - val_loss: 0.0162\n",
      "Epoch 16/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0328 - val_loss: 0.0161\n",
      "Epoch 17/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0308 - val_loss: 0.0161\n",
      "Epoch 18/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0293 - val_loss: 0.0156\n",
      "Epoch 19/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0280 - val_loss: 0.0167\n",
      "Epoch 20/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0159\n",
      "Epoch 21/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.0158\n",
      "Epoch 22/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.0154\n",
      "Epoch 23/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0252 - val_loss: 0.0154\n",
      "Epoch 24/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0246 - val_loss: 0.0155\n",
      "Epoch 25/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.0152\n",
      "Epoch 26/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0238 - val_loss: 0.0153\n",
      "Epoch 27/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.0150\n",
      "Epoch 28/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0230 - val_loss: 0.0145\n",
      "Epoch 29/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.0141\n",
      "Epoch 30/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.0138\n",
      "Epoch 31/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.0136\n",
      "Epoch 32/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.0131\n",
      "Epoch 33/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.0127\n",
      "Epoch 34/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0125\n",
      "Epoch 35/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0128\n",
      "Epoch 36/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0127\n",
      "Epoch 37/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0123\n",
      "Epoch 38/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0126\n",
      "Epoch 39/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0185 - val_loss: 0.0119\n",
      "Epoch 40/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0186 - val_loss: 0.0118\n",
      "Epoch 41/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0122\n",
      "Epoch 42/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0118\n",
      "Epoch 43/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0110\n",
      "Epoch 44/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0108\n",
      "Epoch 45/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0108\n",
      "Epoch 46/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0100\n",
      "Epoch 47/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0099\n",
      "Epoch 48/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0100\n",
      "Epoch 49/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0094\n",
      "Epoch 51/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0100\n",
      "Epoch 52/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0098\n",
      "Epoch 53/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0100\n",
      "Epoch 54/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0095\n",
      "Epoch 55/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0095\n",
      "Epoch 56/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0092\n",
      "Epoch 57/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0098\n",
      "Epoch 58/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0095\n",
      "Epoch 59/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0087\n",
      "Epoch 60/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0089\n",
      "Epoch 61/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0094\n",
      "Epoch 62/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0090\n",
      "Epoch 63/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0088\n",
      "Epoch 64/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0088\n",
      "Epoch 65/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0092\n",
      "Epoch 66/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0087\n",
      "Epoch 67/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0085\n",
      "Epoch 68/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0087\n",
      "Epoch 69/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0090\n",
      "Epoch 70/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0085\n",
      "Epoch 71/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0082\n",
      "Epoch 72/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0085\n",
      "Epoch 73/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0083\n",
      "Epoch 74/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0080\n",
      "Epoch 75/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.0084\n",
      "Epoch 76/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0079\n",
      "Epoch 77/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0096\n",
      "Epoch 78/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0075\n",
      "Epoch 79/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0076\n",
      "Epoch 80/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0077\n",
      "Epoch 81/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0077\n",
      "Epoch 82/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0078\n",
      "Epoch 83/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0078\n",
      "Epoch 84/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0075\n",
      "Epoch 85/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0074\n",
      "Epoch 86/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0074\n",
      "Epoch 87/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0075\n",
      "Epoch 88/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0086\n",
      "Epoch 89/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0075\n",
      "Epoch 90/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0073\n",
      "Epoch 91/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.0079\n",
      "Epoch 92/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.0073\n",
      "Epoch 93/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0072\n",
      "Epoch 94/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0071\n",
      "Epoch 95/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0074\n",
      "Epoch 96/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 97/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0075\n",
      "Epoch 98/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0074\n",
      "Epoch 99/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0074\n",
      "Epoch 100/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.0072\n",
      "Epoch 101/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0073\n",
      "Epoch 102/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0071\n",
      "Epoch 103/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0070\n",
      "Epoch 104/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0084\n",
      "Epoch 105/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0080\n",
      "Epoch 106/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0076\n",
      "Epoch 107/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0078\n",
      "Epoch 108/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0078\n",
      "Epoch 109/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0075\n",
      "Epoch 110/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0077\n",
      "Epoch 111/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0071\n",
      "Epoch 112/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0072\n",
      "Epoch 113/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0077\n",
      "Epoch 114/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0079\n",
      "Epoch 115/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0097\n",
      "Epoch 116/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0088\n",
      "Epoch 117/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0088\n",
      "Epoch 118/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0077\n",
      "Epoch 119/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0073\n",
      "Epoch 120/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0073\n",
      "Epoch 121/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0073\n",
      "Epoch 122/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0071\n",
      "Epoch 123/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0075\n",
      "Epoch 124/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0070\n",
      "Epoch 125/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0071\n",
      "Epoch 126/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0069\n",
      "Epoch 127/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0071\n",
      "Epoch 128/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0071\n",
      "Epoch 129/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0074\n",
      "Epoch 130/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0071\n",
      "Epoch 131/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0073\n",
      "Epoch 132/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0071\n",
      "Epoch 133/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0068\n",
      "Epoch 134/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0069\n",
      "Epoch 135/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0069\n",
      "Epoch 136/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0071\n",
      "Epoch 137/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0074\n",
      "Epoch 138/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0078\n",
      "Epoch 139/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0071\n",
      "Epoch 140/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0070\n",
      "Epoch 141/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.0068\n",
      "Epoch 142/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0104 - val_loss: 0.0073\n",
      "Epoch 143/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0077\n",
      "Epoch 144/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0071\n",
      "Epoch 145/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0070\n",
      "Epoch 146/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0074\n",
      "Epoch 147/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0068\n",
      "Epoch 148/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0072\n",
      "Epoch 149/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0068\n",
      "Epoch 150/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0071\n",
      "Epoch 151/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0070\n",
      "Epoch 152/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0077\n",
      "Epoch 153/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0073\n",
      "Epoch 154/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0078\n",
      "Epoch 155/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0072\n",
      "Epoch 156/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0070\n",
      "Epoch 157/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0069\n",
      "Epoch 158/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0069\n",
      "Epoch 159/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0070\n",
      "Epoch 160/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0082\n",
      "Epoch 161/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0068\n",
      "Epoch 162/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0071\n",
      "Epoch 163/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0071\n",
      "Epoch 164/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0069\n",
      "Epoch 165/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0072\n",
      "Epoch 166/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0069\n",
      "Epoch 167/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0074\n",
      "Epoch 168/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0068\n",
      "Epoch 169/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0067\n",
      "Epoch 170/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0077\n",
      "Epoch 171/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0074\n",
      "Epoch 172/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0069\n",
      "Epoch 173/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0069\n",
      "Epoch 174/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0072\n",
      "Epoch 175/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0071\n",
      "Epoch 176/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0074\n",
      "Epoch 177/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0070\n",
      "Epoch 178/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0071\n",
      "Epoch 179/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0069\n",
      "Epoch 180/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0080\n",
      "Epoch 181/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0072\n",
      "Epoch 182/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0088\n",
      "Epoch 183/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0079\n",
      "Epoch 184/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0069\n",
      "Epoch 185/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0069\n",
      "Epoch 186/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0070\n",
      "Epoch 187/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0069\n",
      "Epoch 188/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0074\n",
      "Epoch 189/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0073\n",
      "Epoch 190/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0123\n",
      "Epoch 191/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0070\n",
      "Epoch 192/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0078\n",
      "Epoch 193/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0070\n",
      "Epoch 194/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0078\n",
      "Epoch 195/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0069\n",
      "Epoch 196/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0070\n",
      "Epoch 197/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0069\n",
      "Epoch 198/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0070\n",
      "Epoch 199/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0068\n",
      "Epoch 200/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0069\n",
      "Epoch 201/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 202/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0068\n",
      "Epoch 203/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 204/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0068\n",
      "Epoch 205/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0070\n",
      "Epoch 206/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0069\n",
      "Epoch 207/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0069\n",
      "Epoch 208/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0070\n",
      "Epoch 209/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0073\n",
      "Epoch 210/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0071\n",
      "Epoch 211/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0070\n",
      "Epoch 212/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 213/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0080\n",
      "Epoch 214/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0070\n",
      "Epoch 215/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0076\n",
      "Epoch 216/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0067\n",
      "Epoch 217/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0074\n",
      "Epoch 218/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0071\n",
      "Epoch 219/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0068\n",
      "Epoch 220/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 221/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0069\n",
      "Epoch 222/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0070\n",
      "Epoch 223/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0068\n",
      "Epoch 224/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0074\n",
      "Epoch 225/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 226/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0067\n",
      "Epoch 227/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0067\n",
      "Epoch 228/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0072\n",
      "Epoch 229/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0069\n",
      "Epoch 230/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0070\n",
      "Epoch 231/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0070\n",
      "Epoch 232/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0073\n",
      "Epoch 233/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0069\n",
      "Epoch 234/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0081\n",
      "Epoch 235/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0073\n",
      "Epoch 236/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0070\n",
      "Epoch 237/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0066\n",
      "Epoch 238/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 239/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0069\n",
      "Epoch 240/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0071\n",
      "Epoch 241/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0072\n",
      "Epoch 242/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0068\n",
      "Epoch 243/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0071\n",
      "Epoch 244/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0068\n",
      "Epoch 245/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0069\n",
      "Epoch 246/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0067\n",
      "Epoch 247/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0070\n",
      "Epoch 248/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0067\n",
      "Epoch 249/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0067\n",
      "Epoch 250/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0068\n",
      "Epoch 251/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0068\n",
      "Epoch 252/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0070\n",
      "Epoch 253/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0069\n",
      "Epoch 254/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0068\n",
      "Epoch 255/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0074\n",
      "Epoch 256/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0068\n",
      "Epoch 257/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0072\n",
      "Epoch 258/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0071\n",
      "Epoch 259/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0069\n",
      "Epoch 260/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0068\n",
      "Epoch 261/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0071\n",
      "Epoch 262/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0067\n",
      "Epoch 263/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0068\n",
      "Epoch 264/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0068\n",
      "Epoch 265/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0067\n",
      "Epoch 266/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0068\n",
      "Epoch 267/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0076\n",
      "Epoch 268/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0082\n",
      "Epoch 269/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0068\n",
      "Epoch 270/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0067\n",
      "Epoch 271/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0066\n",
      "Epoch 272/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0071\n",
      "Epoch 273/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0070\n",
      "Epoch 274/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0066\n",
      "Epoch 275/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0065\n",
      "Epoch 276/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0070\n",
      "Epoch 277/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0072\n",
      "Epoch 278/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0066\n",
      "Epoch 279/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0071\n",
      "Epoch 280/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0072\n",
      "Epoch 281/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0073\n",
      "Epoch 282/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0066\n",
      "Epoch 283/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0069\n",
      "Epoch 284/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0065\n",
      "Epoch 285/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0069\n",
      "Epoch 286/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0071\n",
      "Epoch 287/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0065\n",
      "Epoch 288/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0071\n",
      "Epoch 289/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0075\n",
      "Epoch 290/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0083\n",
      "Epoch 291/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0073\n",
      "Epoch 292/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0067\n",
      "Epoch 293/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0080\n",
      "Epoch 294/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0067\n",
      "Epoch 295/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0066\n",
      "Epoch 296/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0068\n",
      "Epoch 297/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0068\n",
      "Epoch 298/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0068\n",
      "Epoch 299/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0066\n",
      "Epoch 300/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0071\n",
      "Epoch 301/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0069\n",
      "Epoch 302/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0074\n",
      "Epoch 303/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0065\n",
      "Epoch 304/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0066\n",
      "Epoch 305/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0065\n",
      "Epoch 306/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0071\n",
      "Epoch 307/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0080\n",
      "Epoch 308/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0066\n",
      "Epoch 309/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0068\n",
      "Epoch 310/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0065\n",
      "Epoch 311/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0067\n",
      "Epoch 312/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0070\n",
      "Epoch 313/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0065\n",
      "Epoch 314/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0067\n",
      "Epoch 315/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0064\n",
      "Epoch 316/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0068\n",
      "Epoch 317/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0063\n",
      "Epoch 318/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0071\n",
      "Epoch 319/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0064\n",
      "Epoch 320/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0068\n",
      "Epoch 321/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0066\n",
      "Epoch 322/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0064\n",
      "Epoch 323/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0065\n",
      "Epoch 324/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0074\n",
      "Epoch 325/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0066\n",
      "Epoch 326/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0072\n",
      "Epoch 327/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0085\n",
      "Epoch 328/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0066\n",
      "Epoch 329/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0073\n",
      "Epoch 330/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0065\n",
      "Epoch 331/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0066\n",
      "Epoch 332/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0064\n",
      "Epoch 333/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0066\n",
      "Epoch 334/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0065\n",
      "Epoch 335/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0065\n",
      "Epoch 336/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0064\n",
      "Epoch 337/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0069\n",
      "Epoch 338/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0078\n",
      "Epoch 339/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0075\n",
      "Epoch 340/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0074\n",
      "Epoch 341/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0067\n",
      "Epoch 342/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0065\n",
      "Epoch 343/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0065\n",
      "Epoch 344/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0066\n",
      "Epoch 345/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0065\n",
      "Epoch 346/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0076\n",
      "Epoch 347/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0063\n",
      "Epoch 348/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0066\n",
      "Epoch 349/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0065\n",
      "Epoch 350/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0064\n",
      "Epoch 351/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0063\n",
      "Epoch 352/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0066\n",
      "Epoch 353/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0063\n",
      "Epoch 354/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0062\n",
      "Epoch 355/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0064\n",
      "Epoch 356/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0065\n",
      "Epoch 357/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0069\n",
      "Epoch 358/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0067\n",
      "Epoch 359/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0063\n",
      "Epoch 360/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0062\n",
      "Epoch 361/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0062\n",
      "Epoch 362/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0064\n",
      "Epoch 363/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0065\n",
      "Epoch 364/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0063\n",
      "Epoch 365/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0070\n",
      "Epoch 366/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0064\n",
      "Epoch 367/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0064\n",
      "Epoch 368/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0067\n",
      "Epoch 369/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0063\n",
      "Epoch 370/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0067\n",
      "Epoch 371/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0067\n",
      "Epoch 372/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0063\n",
      "Epoch 373/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0074\n",
      "Epoch 374/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0063\n",
      "Epoch 375/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 376/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0077\n",
      "Epoch 377/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0062\n",
      "Epoch 378/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0066\n",
      "Epoch 379/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0063\n",
      "Epoch 380/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0067\n",
      "Epoch 381/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0092\n",
      "Epoch 382/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0061\n",
      "Epoch 383/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0066\n",
      "Epoch 384/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0063\n",
      "Epoch 385/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0062\n",
      "Epoch 386/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0063\n",
      "Epoch 387/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0066\n",
      "Epoch 388/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0063\n",
      "Epoch 389/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0066\n",
      "Epoch 390/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0065\n",
      "Epoch 391/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0066\n",
      "Epoch 392/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0065\n",
      "Epoch 393/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0062\n",
      "Epoch 394/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0061\n",
      "Epoch 395/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0066\n",
      "Epoch 396/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0074\n",
      "Epoch 397/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0061\n",
      "Epoch 398/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0061\n",
      "Epoch 399/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0063\n",
      "Epoch 400/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0061\n",
      "Epoch 401/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0062\n",
      "Epoch 402/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0065\n",
      "Epoch 403/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0061\n",
      "Epoch 404/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0061\n",
      "Epoch 405/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0064\n",
      "Epoch 406/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0061\n",
      "Epoch 407/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0062\n",
      "Epoch 408/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0064\n",
      "Epoch 409/10000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.006 - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0061\n",
      "Epoch 410/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 411/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0063\n",
      "Epoch 412/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0066\n",
      "Epoch 413/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0061\n",
      "Epoch 414/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0066\n",
      "Epoch 415/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0062\n",
      "Epoch 416/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0062\n",
      "Epoch 417/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0064\n",
      "Epoch 418/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0067\n",
      "Epoch 419/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0062\n",
      "Epoch 420/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0060\n",
      "Epoch 421/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0082\n",
      "Epoch 422/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0068\n",
      "Epoch 423/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0063\n",
      "Epoch 424/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0062\n",
      "Epoch 425/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0060\n",
      "Epoch 426/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0063\n",
      "Epoch 427/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0062\n",
      "Epoch 428/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0061\n",
      "Epoch 429/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0061\n",
      "Epoch 430/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0060\n",
      "Epoch 431/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0063\n",
      "Epoch 432/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0063\n",
      "Epoch 433/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0064\n",
      "Epoch 434/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0063\n",
      "Epoch 435/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0061\n",
      "Epoch 436/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0076\n",
      "Epoch 437/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0062\n",
      "Epoch 438/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0062\n",
      "Epoch 439/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0071\n",
      "Epoch 440/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0062\n",
      "Epoch 441/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0060\n",
      "Epoch 442/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0059\n",
      "Epoch 443/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0063\n",
      "Epoch 444/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0063\n",
      "Epoch 445/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0059\n",
      "Epoch 446/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0059\n",
      "Epoch 447/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0059\n",
      "Epoch 448/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0059\n",
      "Epoch 449/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0060\n",
      "Epoch 450/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0061\n",
      "Epoch 451/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0060\n",
      "Epoch 452/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0061\n",
      "Epoch 453/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0062\n",
      "Epoch 454/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0061\n",
      "Epoch 455/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0061\n",
      "Epoch 456/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0072\n",
      "Epoch 457/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0065\n",
      "Epoch 458/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0059\n",
      "Epoch 459/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0062\n",
      "Epoch 460/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0062\n",
      "Epoch 461/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0067\n",
      "Epoch 462/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0061\n",
      "Epoch 463/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0069\n",
      "Epoch 464/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0070\n",
      "Epoch 465/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0068\n",
      "Epoch 466/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0059\n",
      "Epoch 467/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0061\n",
      "Epoch 468/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0065\n",
      "Epoch 469/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0059\n",
      "Epoch 470/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0062\n",
      "Epoch 471/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0060\n",
      "Epoch 472/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0123\n",
      "Epoch 473/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0067\n",
      "Epoch 474/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0060\n",
      "Epoch 475/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0063\n",
      "Epoch 476/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0060\n",
      "Epoch 477/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0065\n",
      "Epoch 478/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0064\n",
      "Epoch 479/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0060\n",
      "Epoch 480/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0062\n",
      "Epoch 481/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0065\n",
      "Epoch 482/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0082\n",
      "Epoch 483/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0061\n",
      "Epoch 484/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0060\n",
      "Epoch 485/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0066\n",
      "Epoch 486/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0067\n",
      "Epoch 487/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0061\n",
      "Epoch 488/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0067\n",
      "Epoch 489/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0064\n",
      "Epoch 490/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0065\n",
      "Epoch 491/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0061\n",
      "Epoch 492/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0068\n",
      "Epoch 493/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0059\n",
      "Epoch 494/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0060\n",
      "Epoch 495/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0061\n",
      "Epoch 496/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0063\n",
      "Epoch 497/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0074\n",
      "Epoch 498/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0069\n",
      "Epoch 499/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0063\n",
      "Epoch 500/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0063\n",
      "Epoch 501/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0058\n",
      "Epoch 502/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0063\n",
      "Epoch 503/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0059\n",
      "Epoch 504/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0063\n",
      "Epoch 505/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0060\n",
      "Epoch 506/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0060\n",
      "Epoch 507/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0064\n",
      "Epoch 508/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 509/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0062\n",
      "Epoch 510/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0060\n",
      "Epoch 511/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0058\n",
      "Epoch 512/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 513/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0060\n",
      "Epoch 514/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0066\n",
      "Epoch 515/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0060\n",
      "Epoch 516/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0062\n",
      "Epoch 517/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0071\n",
      "Epoch 518/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0060\n",
      "Epoch 519/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0061\n",
      "Epoch 520/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0059\n",
      "Epoch 521/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0061\n",
      "Epoch 522/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0060\n",
      "Epoch 523/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0061\n",
      "Epoch 524/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0060\n",
      "Epoch 525/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0059\n",
      "Epoch 526/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0066\n",
      "Epoch 527/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0065\n",
      "Epoch 528/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0062\n",
      "Epoch 529/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0061\n",
      "Epoch 530/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0061\n",
      "Epoch 531/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0058\n",
      "Epoch 532/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0074\n",
      "Epoch 533/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0063\n",
      "Epoch 534/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0063\n",
      "Epoch 535/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0060\n",
      "Epoch 536/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0068\n",
      "Epoch 537/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0069\n",
      "Epoch 538/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0066\n",
      "Epoch 539/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0060\n",
      "Epoch 540/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0060\n",
      "Epoch 541/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0060\n",
      "Epoch 542/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0061\n",
      "Epoch 543/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0072\n",
      "Epoch 544/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0061\n",
      "Epoch 545/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0061\n",
      "Epoch 546/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0062\n",
      "Epoch 547/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0064\n",
      "Epoch 548/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 549/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0065\n",
      "Epoch 550/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0065\n",
      "Epoch 551/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0060\n",
      "Epoch 552/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0059\n",
      "Epoch 553/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0063\n",
      "Epoch 554/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0060\n",
      "Epoch 555/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0065\n",
      "Epoch 556/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0058\n",
      "Epoch 557/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0059\n",
      "Epoch 558/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0064\n",
      "Epoch 559/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0069\n",
      "Epoch 560/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0060\n",
      "Epoch 561/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0075\n",
      "Epoch 562/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0060\n",
      "Epoch 563/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0063\n",
      "Epoch 564/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0070\n",
      "Epoch 565/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0061\n",
      "Epoch 566/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0062\n",
      "Epoch 567/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0062\n",
      "Epoch 568/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0060\n",
      "Epoch 569/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0062\n",
      "Epoch 570/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0060\n",
      "Epoch 571/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0067\n",
      "Epoch 572/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0060\n",
      "Epoch 573/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0061\n",
      "Epoch 574/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0069\n",
      "Epoch 575/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0058\n",
      "Epoch 576/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0059\n",
      "Epoch 577/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0061\n",
      "Epoch 578/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0062\n",
      "Epoch 579/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0075\n",
      "Epoch 580/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0059\n",
      "Epoch 581/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0059\n",
      "Epoch 582/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0060\n",
      "Epoch 583/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0060\n",
      "Epoch 584/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0059\n",
      "Epoch 585/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0060\n",
      "Epoch 586/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0059\n",
      "Epoch 587/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0061\n",
      "Epoch 588/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0064\n",
      "Epoch 589/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0058\n",
      "Epoch 590/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0060\n",
      "Epoch 591/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0059\n",
      "Epoch 592/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0064\n",
      "Epoch 593/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0059\n",
      "Epoch 594/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 595/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0059\n",
      "Epoch 596/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0060\n",
      "Epoch 597/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0059\n",
      "Epoch 598/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0086\n",
      "Epoch 599/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0062\n",
      "Epoch 600/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0062\n",
      "Epoch 601/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0065\n",
      "Epoch 602/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0061\n",
      "Epoch 603/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0059\n",
      "Epoch 604/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0062\n",
      "Epoch 605/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0064\n",
      "Epoch 606/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0074\n",
      "Epoch 607/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0060\n",
      "Epoch 608/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0068\n",
      "Epoch 609/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0058\n",
      "Epoch 610/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0059\n",
      "Epoch 611/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0059\n",
      "Epoch 00611: early stopping\n",
      "Epoch 1/10000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4805 - val_loss: 0.0974\n",
      "Epoch 2/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1252 - val_loss: 0.0338\n",
      "Epoch 3/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0939 - val_loss: 0.0311\n",
      "Epoch 4/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0823 - val_loss: 0.0285\n",
      "Epoch 5/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0752 - val_loss: 0.0311\n",
      "Epoch 6/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0688 - val_loss: 0.0213\n",
      "Epoch 7/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0605 - val_loss: 0.0193\n",
      "Epoch 8/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0548 - val_loss: 0.0205\n",
      "Epoch 9/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0514 - val_loss: 0.0187\n",
      "Epoch 10/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0459 - val_loss: 0.0163\n",
      "Epoch 11/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0437 - val_loss: 0.0176\n",
      "Epoch 12/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0406 - val_loss: 0.0161\n",
      "Epoch 13/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0378 - val_loss: 0.0157\n",
      "Epoch 14/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0348 - val_loss: 0.0168\n",
      "Epoch 15/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0338 - val_loss: 0.0175\n",
      "Epoch 16/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0324 - val_loss: 0.0158\n",
      "Epoch 17/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0295 - val_loss: 0.0157\n",
      "Epoch 18/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0285 - val_loss: 0.0149\n",
      "Epoch 19/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.0151\n",
      "Epoch 20/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.0151\n",
      "Epoch 21/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0258 - val_loss: 0.0143\n",
      "Epoch 22/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0251 - val_loss: 0.0141\n",
      "Epoch 23/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.0136\n",
      "Epoch 24/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.0139\n",
      "Epoch 25/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.0131\n",
      "Epoch 26/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.0131\n",
      "Epoch 27/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0126\n",
      "Epoch 28/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0146\n",
      "Epoch 29/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0119\n",
      "Epoch 30/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0120\n",
      "Epoch 31/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.0111\n",
      "Epoch 32/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0113\n",
      "Epoch 33/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0110\n",
      "Epoch 34/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0102\n",
      "Epoch 35/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0100\n",
      "Epoch 36/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0099\n",
      "Epoch 37/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0102\n",
      "Epoch 38/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0097\n",
      "Epoch 39/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0101\n",
      "Epoch 40/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0090\n",
      "Epoch 41/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0104\n",
      "Epoch 42/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0091\n",
      "Epoch 43/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0089\n",
      "Epoch 44/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0088\n",
      "Epoch 45/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0094\n",
      "Epoch 46/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0092\n",
      "Epoch 47/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0089\n",
      "Epoch 48/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0091\n",
      "Epoch 49/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0081\n",
      "Epoch 50/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0085\n",
      "Epoch 51/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0090\n",
      "Epoch 52/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0085\n",
      "Epoch 53/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0142 - val_loss: 0.0080\n",
      "Epoch 54/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0083\n",
      "Epoch 55/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0081\n",
      "Epoch 56/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0083\n",
      "Epoch 57/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0081\n",
      "Epoch 58/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0143 - val_loss: 0.0080\n",
      "Epoch 59/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0142 - val_loss: 0.0087\n",
      "Epoch 60/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0085\n",
      "Epoch 61/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0075\n",
      "Epoch 62/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0085\n",
      "Epoch 63/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0075\n",
      "Epoch 64/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0078\n",
      "Epoch 65/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0082\n",
      "Epoch 66/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.0077\n",
      "Epoch 67/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0082\n",
      "Epoch 68/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0077\n",
      "Epoch 69/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0075\n",
      "Epoch 70/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0079\n",
      "Epoch 71/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0071\n",
      "Epoch 72/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0071\n",
      "Epoch 73/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0070\n",
      "Epoch 74/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0070\n",
      "Epoch 75/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0066\n",
      "Epoch 76/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0083\n",
      "Epoch 77/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0068\n",
      "Epoch 78/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0063\n",
      "Epoch 79/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0073\n",
      "Epoch 80/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0066\n",
      "Epoch 81/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0063\n",
      "Epoch 82/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0060\n",
      "Epoch 83/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0061\n",
      "Epoch 84/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0061\n",
      "Epoch 85/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0061\n",
      "Epoch 86/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0065\n",
      "Epoch 87/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0058\n",
      "Epoch 88/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0062\n",
      "Epoch 89/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0064\n",
      "Epoch 90/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0060\n",
      "Epoch 91/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 92/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0059\n",
      "Epoch 93/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0057\n",
      "Epoch 94/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.0058\n",
      "Epoch 95/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0059\n",
      "Epoch 96/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0058\n",
      "Epoch 97/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0067\n",
      "Epoch 98/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0063\n",
      "Epoch 99/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0068\n",
      "Epoch 100/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0060\n",
      "Epoch 101/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0058\n",
      "Epoch 102/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0061\n",
      "Epoch 103/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0061\n",
      "Epoch 104/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0058\n",
      "Epoch 105/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0061\n",
      "Epoch 106/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0060\n",
      "Epoch 107/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0058\n",
      "Epoch 108/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0067\n",
      "Epoch 109/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0069\n",
      "Epoch 110/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0060\n",
      "Epoch 111/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0062\n",
      "Epoch 112/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0060\n",
      "Epoch 113/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0068\n",
      "Epoch 114/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0070\n",
      "Epoch 115/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0062\n",
      "Epoch 116/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0059\n",
      "Epoch 117/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0060\n",
      "Epoch 118/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0058\n",
      "Epoch 119/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0058\n",
      "Epoch 120/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0070\n",
      "Epoch 121/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0062\n",
      "Epoch 122/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0058\n",
      "Epoch 123/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0059\n",
      "Epoch 124/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0061\n",
      "Epoch 125/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0066\n",
      "Epoch 126/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0057\n",
      "Epoch 127/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0057\n",
      "Epoch 128/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0059\n",
      "Epoch 129/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0057\n",
      "Epoch 130/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0060\n",
      "Epoch 131/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0061\n",
      "Epoch 132/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0058\n",
      "Epoch 133/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0056\n",
      "Epoch 134/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0058\n",
      "Epoch 135/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0064\n",
      "Epoch 136/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0060\n",
      "Epoch 137/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0059\n",
      "Epoch 138/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0056\n",
      "Epoch 139/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0071\n",
      "Epoch 140/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0059\n",
      "Epoch 141/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0065\n",
      "Epoch 142/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0066\n",
      "Epoch 143/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0058\n",
      "Epoch 144/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0057\n",
      "Epoch 145/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 146/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0057\n",
      "Epoch 147/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0054\n",
      "Epoch 148/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0068\n",
      "Epoch 149/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0058\n",
      "Epoch 150/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0055\n",
      "Epoch 151/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0059\n",
      "Epoch 152/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0059\n",
      "Epoch 154/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0059\n",
      "Epoch 155/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0057\n",
      "Epoch 156/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0056\n",
      "Epoch 157/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0056\n",
      "Epoch 158/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0055\n",
      "Epoch 159/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0060\n",
      "Epoch 160/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0057\n",
      "Epoch 161/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0063\n",
      "Epoch 162/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0058\n",
      "Epoch 163/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0058\n",
      "Epoch 164/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0057\n",
      "Epoch 165/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0058\n",
      "Epoch 166/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0060\n",
      "Epoch 167/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0055\n",
      "Epoch 168/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0056\n",
      "Epoch 169/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0054\n",
      "Epoch 170/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0054\n",
      "Epoch 171/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0055\n",
      "Epoch 172/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0059\n",
      "Epoch 173/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0064\n",
      "Epoch 174/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0057\n",
      "Epoch 175/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0064\n",
      "Epoch 176/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0062\n",
      "Epoch 177/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0057\n",
      "Epoch 178/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0071\n",
      "Epoch 179/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0056\n",
      "Epoch 180/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0057\n",
      "Epoch 181/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0061\n",
      "Epoch 182/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0057\n",
      "Epoch 183/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0057\n",
      "Epoch 184/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0059\n",
      "Epoch 185/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0056\n",
      "Epoch 186/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0055\n",
      "Epoch 187/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0055\n",
      "Epoch 188/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0055\n",
      "Epoch 189/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0060\n",
      "Epoch 190/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0064\n",
      "Epoch 191/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0056\n",
      "Epoch 192/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0067\n",
      "Epoch 193/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0070\n",
      "Epoch 194/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0054\n",
      "Epoch 195/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0056\n",
      "Epoch 196/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0056\n",
      "Epoch 197/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0053\n",
      "Epoch 198/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0053\n",
      "Epoch 199/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0055\n",
      "Epoch 200/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0057\n",
      "Epoch 201/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0056\n",
      "Epoch 202/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0054\n",
      "Epoch 203/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0058\n",
      "Epoch 204/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0057\n",
      "Epoch 205/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0066\n",
      "Epoch 206/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0062\n",
      "Epoch 207/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0055\n",
      "Epoch 208/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0056\n",
      "Epoch 209/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0053\n",
      "Epoch 210/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0055\n",
      "Epoch 211/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0055\n",
      "Epoch 212/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0055\n",
      "Epoch 213/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0063\n",
      "Epoch 214/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0067\n",
      "Epoch 215/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0056\n",
      "Epoch 216/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0054\n",
      "Epoch 217/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0061\n",
      "Epoch 218/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0071\n",
      "Epoch 219/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0055\n",
      "Epoch 220/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0055\n",
      "Epoch 221/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0061\n",
      "Epoch 222/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0057\n",
      "Epoch 223/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0055\n",
      "Epoch 224/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0054\n",
      "Epoch 225/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0055\n",
      "Epoch 226/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0063\n",
      "Epoch 227/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0057\n",
      "Epoch 228/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0055\n",
      "Epoch 229/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0055\n",
      "Epoch 230/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0056\n",
      "Epoch 231/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0054\n",
      "Epoch 232/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0055\n",
      "Epoch 233/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0055\n",
      "Epoch 234/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0058\n",
      "Epoch 235/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0056\n",
      "Epoch 236/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0061\n",
      "Epoch 237/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0054\n",
      "Epoch 238/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0053\n",
      "Epoch 239/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0057\n",
      "Epoch 240/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0071\n",
      "Epoch 241/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0058\n",
      "Epoch 242/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0057\n",
      "Epoch 243/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0058\n",
      "Epoch 244/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0053\n",
      "Epoch 245/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0068\n",
      "Epoch 246/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0057\n",
      "Epoch 247/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0055\n",
      "Epoch 248/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0056\n",
      "Epoch 249/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0054\n",
      "Epoch 250/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0055\n",
      "Epoch 251/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0059\n",
      "Epoch 252/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0055\n",
      "Epoch 253/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0060\n",
      "Epoch 254/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0063\n",
      "Epoch 255/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0052\n",
      "Epoch 256/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0059\n",
      "Epoch 257/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0054\n",
      "Epoch 258/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0058\n",
      "Epoch 259/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0054\n",
      "Epoch 260/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0057\n",
      "Epoch 261/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0054\n",
      "Epoch 262/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0063\n",
      "Epoch 263/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0054\n",
      "Epoch 264/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0055\n",
      "Epoch 265/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0084\n",
      "Epoch 266/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0064\n",
      "Epoch 267/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0053\n",
      "Epoch 268/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0054\n",
      "Epoch 269/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0057\n",
      "Epoch 270/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0058\n",
      "Epoch 271/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0062\n",
      "Epoch 272/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0053\n",
      "Epoch 273/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0062\n",
      "Epoch 274/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0057\n",
      "Epoch 275/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0056\n",
      "Epoch 276/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0064\n",
      "Epoch 277/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0059\n",
      "Epoch 278/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0056\n",
      "Epoch 279/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0056\n",
      "Epoch 280/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0056\n",
      "Epoch 281/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0058\n",
      "Epoch 282/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0054\n",
      "Epoch 283/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0057\n",
      "Epoch 284/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0053\n",
      "Epoch 285/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0053\n",
      "Epoch 286/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 287/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0050\n",
      "Epoch 288/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0053\n",
      "Epoch 289/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 290/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0053\n",
      "Epoch 291/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0052\n",
      "Epoch 292/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 293/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0051\n",
      "Epoch 294/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0054\n",
      "Epoch 295/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0055\n",
      "Epoch 296/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0052\n",
      "Epoch 297/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0061\n",
      "Epoch 298/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0051\n",
      "Epoch 299/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 300/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0056\n",
      "Epoch 301/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0052\n",
      "Epoch 302/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0053\n",
      "Epoch 303/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0056\n",
      "Epoch 304/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 305/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0066\n",
      "Epoch 306/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0055\n",
      "Epoch 307/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 308/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0055\n",
      "Epoch 309/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0054\n",
      "Epoch 310/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0055\n",
      "Epoch 311/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0052\n",
      "Epoch 312/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0072\n",
      "Epoch 313/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0055\n",
      "Epoch 314/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0053\n",
      "Epoch 315/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0059\n",
      "Epoch 316/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0052\n",
      "Epoch 317/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0054\n",
      "Epoch 318/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0054\n",
      "Epoch 319/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0059\n",
      "Epoch 320/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0055\n",
      "Epoch 321/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 322/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0050\n",
      "Epoch 323/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 324/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 325/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0055\n",
      "Epoch 326/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0062\n",
      "Epoch 327/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0051\n",
      "Epoch 328/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0055\n",
      "Epoch 329/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0060\n",
      "Epoch 330/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0052\n",
      "Epoch 331/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 332/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0052\n",
      "Epoch 333/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0058\n",
      "Epoch 334/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0055\n",
      "Epoch 335/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0053\n",
      "Epoch 336/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 337/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 338/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0057\n",
      "Epoch 339/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 340/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0053\n",
      "Epoch 341/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0051\n",
      "Epoch 342/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 343/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0053\n",
      "Epoch 344/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0055\n",
      "Epoch 345/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 346/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0051\n",
      "Epoch 347/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0056\n",
      "Epoch 348/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0054\n",
      "Epoch 349/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0067\n",
      "Epoch 350/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0054\n",
      "Epoch 351/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 352/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 353/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 354/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 355/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0063\n",
      "Epoch 356/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0055\n",
      "Epoch 357/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0052\n",
      "Epoch 358/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0060\n",
      "Epoch 359/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0055\n",
      "Epoch 360/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0056\n",
      "Epoch 361/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0056\n",
      "Epoch 362/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0056\n",
      "Epoch 363/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0053\n",
      "Epoch 364/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 365/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 366/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 367/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0057\n",
      "Epoch 368/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0052\n",
      "Epoch 369/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0055\n",
      "Epoch 370/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 371/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0053\n",
      "Epoch 372/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 373/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0058\n",
      "Epoch 374/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0050\n",
      "Epoch 375/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 376/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0051\n",
      "Epoch 377/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 378/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0063\n",
      "Epoch 379/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0053\n",
      "Epoch 380/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0052\n",
      "Epoch 381/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 382/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0064\n",
      "Epoch 383/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0053\n",
      "Epoch 384/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0055\n",
      "Epoch 385/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0054\n",
      "Epoch 386/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0050\n",
      "Epoch 387/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0059\n",
      "Epoch 388/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0065\n",
      "Epoch 389/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0054\n",
      "Epoch 390/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 391/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0057\n",
      "Epoch 392/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0056\n",
      "Epoch 393/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0055\n",
      "Epoch 394/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0054\n",
      "Epoch 395/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 396/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 397/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 398/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0052\n",
      "Epoch 399/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0068\n",
      "Epoch 400/10000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0053\n",
      "Epoch 401/10000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0058\n",
      "Epoch 402/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 403/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0059\n",
      "Epoch 404/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 405/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0059\n",
      "Epoch 406/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0060\n",
      "Epoch 407/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0058\n",
      "Epoch 408/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0052\n",
      "Epoch 409/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 410/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 411/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 412/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 413/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 414/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0052\n",
      "Epoch 415/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0055\n",
      "Epoch 416/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0056\n",
      "Epoch 417/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0058\n",
      "Epoch 418/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0050\n",
      "Epoch 419/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0049\n",
      "Epoch 420/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 421/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0059\n",
      "Epoch 422/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0057\n",
      "Epoch 423/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 424/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 425/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0054\n",
      "Epoch 426/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 427/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0051\n",
      "Epoch 428/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0050\n",
      "Epoch 429/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0054\n",
      "Epoch 430/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0050\n",
      "Epoch 431/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0052\n",
      "Epoch 432/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 433/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 434/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 435/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0052\n",
      "Epoch 436/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 437/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 438/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0055\n",
      "Epoch 439/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0059\n",
      "Epoch 440/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0053\n",
      "Epoch 441/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0069\n",
      "Epoch 442/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0060\n",
      "Epoch 443/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0055\n",
      "Epoch 444/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 445/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0055\n",
      "Epoch 446/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 447/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 448/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0055\n",
      "Epoch 449/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 450/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0052\n",
      "Epoch 451/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 452/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0063\n",
      "Epoch 453/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0053\n",
      "Epoch 454/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 455/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0052\n",
      "Epoch 456/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0051\n",
      "Epoch 457/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0053\n",
      "Epoch 458/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 459/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 460/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 461/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 462/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 463/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0050\n",
      "Epoch 464/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 465/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0055\n",
      "Epoch 466/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 467/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 468/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0064\n",
      "Epoch 469/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0059\n",
      "Epoch 470/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0049\n",
      "Epoch 471/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 472/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0053\n",
      "Epoch 473/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 474/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 475/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0052\n",
      "Epoch 476/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0052\n",
      "Epoch 477/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0081\n",
      "Epoch 478/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0054\n",
      "Epoch 479/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 480/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 481/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0059\n",
      "Epoch 482/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0055\n",
      "Epoch 483/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0049\n",
      "Epoch 484/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0055\n",
      "Epoch 485/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 486/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0066\n",
      "Epoch 487/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0051\n",
      "Epoch 488/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 489/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 490/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0053\n",
      "Epoch 491/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 492/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 493/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0058\n",
      "Epoch 494/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0054\n",
      "Epoch 495/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 496/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 497/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 498/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 499/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0056\n",
      "Epoch 500/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0055\n",
      "Epoch 501/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0050\n",
      "Epoch 502/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0055\n",
      "Epoch 503/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0059\n",
      "Epoch 504/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0049\n",
      "Epoch 505/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 506/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0055\n",
      "Epoch 507/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0051\n",
      "Epoch 508/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 509/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 510/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 511/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0050\n",
      "Epoch 512/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0058\n",
      "Epoch 513/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0053\n",
      "Epoch 514/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 515/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0054\n",
      "Epoch 516/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 517/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0055\n",
      "Epoch 518/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 519/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 520/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0053\n",
      "Epoch 521/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 522/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 523/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 524/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0057\n",
      "Epoch 525/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 526/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0049\n",
      "Epoch 527/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0050\n",
      "Epoch 528/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 529/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0049\n",
      "Epoch 530/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 531/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0051\n",
      "Epoch 532/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0068\n",
      "Epoch 533/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0051\n",
      "Epoch 534/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 535/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0059\n",
      "Epoch 536/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 537/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 538/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 539/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 540/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 541/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 542/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0068\n",
      "Epoch 543/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0051\n",
      "Epoch 544/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 545/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0055\n",
      "Epoch 546/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 547/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 548/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0064\n",
      "Epoch 549/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0063\n",
      "Epoch 550/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0050\n",
      "Epoch 551/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 552/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0058\n",
      "Epoch 553/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 554/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 555/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0050\n",
      "Epoch 556/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 557/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0053\n",
      "Epoch 558/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0054\n",
      "Epoch 559/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0055\n",
      "Epoch 560/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 561/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 562/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0052\n",
      "Epoch 563/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0050\n",
      "Epoch 564/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0056\n",
      "Epoch 565/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0056\n",
      "Epoch 566/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 567/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 568/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0050\n",
      "Epoch 569/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0055\n",
      "Epoch 570/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0053\n",
      "Epoch 571/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0051\n",
      "Epoch 572/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0054\n",
      "Epoch 573/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0054\n",
      "Epoch 574/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0054\n",
      "Epoch 575/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0053\n",
      "Epoch 576/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0052\n",
      "Epoch 577/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 578/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 579/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0059\n",
      "Epoch 580/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0053\n",
      "Epoch 581/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 582/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0052\n",
      "Epoch 583/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 584/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0051\n",
      "Epoch 585/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 586/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0053\n",
      "Epoch 587/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0049\n",
      "Epoch 588/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 589/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0053\n",
      "Epoch 590/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0052\n",
      "Epoch 591/10000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.005 - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 592/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 593/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 594/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 595/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0049\n",
      "Epoch 596/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0050\n",
      "Epoch 597/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0052\n",
      "Epoch 598/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 599/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0050\n",
      "Epoch 600/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0052\n",
      "Epoch 601/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0053\n",
      "Epoch 602/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0052\n",
      "Epoch 603/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0049\n",
      "Epoch 604/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0051\n",
      "Epoch 605/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0052\n",
      "Epoch 606/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0054\n",
      "Epoch 607/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0059\n",
      "Epoch 608/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0056\n",
      "Epoch 609/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0051\n",
      "Epoch 610/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0049\n",
      "Epoch 00610: early stopping\n",
      "Epoch 1/10000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5117 - val_loss: 0.0997\n",
      "Epoch 2/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1282 - val_loss: 0.0343\n",
      "Epoch 3/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0956 - val_loss: 0.0339\n",
      "Epoch 4/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0856 - val_loss: 0.0295\n",
      "Epoch 5/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0781 - val_loss: 0.0295\n",
      "Epoch 6/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.0261\n",
      "Epoch 7/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0631 - val_loss: 0.0208\n",
      "Epoch 8/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0565 - val_loss: 0.0183\n",
      "Epoch 9/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0510 - val_loss: 0.0172\n",
      "Epoch 10/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0458 - val_loss: 0.0170\n",
      "Epoch 11/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0427 - val_loss: 0.0173\n",
      "Epoch 12/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0396 - val_loss: 0.0227\n",
      "Epoch 13/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0382 - val_loss: 0.0161\n",
      "Epoch 14/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0352 - val_loss: 0.0201\n",
      "Epoch 15/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0326 - val_loss: 0.0161\n",
      "Epoch 16/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0317 - val_loss: 0.0169\n",
      "Epoch 17/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0300 - val_loss: 0.0153\n",
      "Epoch 18/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0287 - val_loss: 0.0151\n",
      "Epoch 19/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0281 - val_loss: 0.0151\n",
      "Epoch 20/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.0153\n",
      "Epoch 21/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.0149\n",
      "Epoch 22/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.0144\n",
      "Epoch 23/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.0141\n",
      "Epoch 24/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.0139\n",
      "Epoch 25/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.0139\n",
      "Epoch 26/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.0132\n",
      "Epoch 27/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0219 - val_loss: 0.0128\n",
      "Epoch 28/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0220 - val_loss: 0.0123\n",
      "Epoch 29/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0211 - val_loss: 0.0119\n",
      "Epoch 30/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0213 - val_loss: 0.0117\n",
      "Epoch 31/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0204 - val_loss: 0.0113\n",
      "Epoch 32/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0107\n",
      "Epoch 33/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0103\n",
      "Epoch 34/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0105\n",
      "Epoch 35/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0112\n",
      "Epoch 36/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0111\n",
      "Epoch 37/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0104\n",
      "Epoch 38/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.0096\n",
      "Epoch 39/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0093\n",
      "Epoch 40/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0098\n",
      "Epoch 41/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0097\n",
      "Epoch 42/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0097\n",
      "Epoch 43/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0106\n",
      "Epoch 44/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0092\n",
      "Epoch 45/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0093\n",
      "Epoch 46/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0092\n",
      "Epoch 47/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0090\n",
      "Epoch 48/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0101\n",
      "Epoch 49/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0091\n",
      "Epoch 50/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0088\n",
      "Epoch 51/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0094\n",
      "Epoch 52/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0094\n",
      "Epoch 53/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0089\n",
      "Epoch 54/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0082\n",
      "Epoch 55/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.0085\n",
      "Epoch 56/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0083\n",
      "Epoch 57/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0090\n",
      "Epoch 58/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0082\n",
      "Epoch 59/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0082\n",
      "Epoch 60/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0079\n",
      "Epoch 61/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0076\n",
      "Epoch 62/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.0077\n",
      "Epoch 63/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0084\n",
      "Epoch 64/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0075\n",
      "Epoch 65/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.0083\n",
      "Epoch 66/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0074\n",
      "Epoch 67/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0071\n",
      "Epoch 68/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0084\n",
      "Epoch 69/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0074\n",
      "Epoch 70/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0070\n",
      "Epoch 71/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0130 - val_loss: 0.0067\n",
      "Epoch 72/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0066\n",
      "Epoch 73/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0068\n",
      "Epoch 74/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 75/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 76/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0065\n",
      "Epoch 77/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0065\n",
      "Epoch 78/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0061\n",
      "Epoch 79/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0060\n",
      "Epoch 80/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0063\n",
      "Epoch 81/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0061\n",
      "Epoch 82/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0077\n",
      "Epoch 83/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0060\n",
      "Epoch 84/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0064\n",
      "Epoch 85/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0062\n",
      "Epoch 86/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0077\n",
      "Epoch 87/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0066\n",
      "Epoch 88/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0067\n",
      "Epoch 89/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0063\n",
      "Epoch 90/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0064\n",
      "Epoch 91/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0059\n",
      "Epoch 92/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0062\n",
      "Epoch 93/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.0060\n",
      "Epoch 94/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0077\n",
      "Epoch 95/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0069\n",
      "Epoch 96/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0063\n",
      "Epoch 97/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0058\n",
      "Epoch 98/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0060\n",
      "Epoch 99/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0068\n",
      "Epoch 100/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0058\n",
      "Epoch 101/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0059\n",
      "Epoch 102/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0062\n",
      "Epoch 103/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0070\n",
      "Epoch 104/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0067\n",
      "Epoch 105/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0060\n",
      "Epoch 106/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0061\n",
      "Epoch 107/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0075\n",
      "Epoch 108/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0061\n",
      "Epoch 109/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0062\n",
      "Epoch 110/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0062\n",
      "Epoch 111/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0056\n",
      "Epoch 112/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0060\n",
      "Epoch 113/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0062\n",
      "Epoch 114/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0060\n",
      "Epoch 115/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0057\n",
      "Epoch 116/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0063\n",
      "Epoch 117/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0059\n",
      "Epoch 118/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0060\n",
      "Epoch 119/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0057\n",
      "Epoch 120/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0061\n",
      "Epoch 121/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0057\n",
      "Epoch 122/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0058\n",
      "Epoch 123/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0070\n",
      "Epoch 124/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0067\n",
      "Epoch 125/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0061\n",
      "Epoch 126/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0058\n",
      "Epoch 127/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0073\n",
      "Epoch 128/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0081\n",
      "Epoch 129/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0061\n",
      "Epoch 130/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0060\n",
      "Epoch 131/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0058\n",
      "Epoch 132/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0056\n",
      "Epoch 133/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0062\n",
      "Epoch 134/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0064\n",
      "Epoch 135/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0067\n",
      "Epoch 136/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0056\n",
      "Epoch 137/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0066\n",
      "Epoch 138/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0058\n",
      "Epoch 139/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0056\n",
      "Epoch 140/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0062\n",
      "Epoch 141/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0058\n",
      "Epoch 142/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0072\n",
      "Epoch 143/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0060\n",
      "Epoch 144/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0058\n",
      "Epoch 145/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0055\n",
      "Epoch 146/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0058\n",
      "Epoch 147/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0069\n",
      "Epoch 148/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0072\n",
      "Epoch 149/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0058\n",
      "Epoch 150/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0056\n",
      "Epoch 151/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0061\n",
      "Epoch 152/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0059\n",
      "Epoch 153/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0059\n",
      "Epoch 154/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0068\n",
      "Epoch 155/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0056\n",
      "Epoch 156/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0059\n",
      "Epoch 157/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0059\n",
      "Epoch 158/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0055\n",
      "Epoch 159/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0059\n",
      "Epoch 160/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0061\n",
      "Epoch 161/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0059\n",
      "Epoch 162/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0059\n",
      "Epoch 163/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0062\n",
      "Epoch 164/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0062\n",
      "Epoch 165/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0055\n",
      "Epoch 166/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0056\n",
      "Epoch 167/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0054\n",
      "Epoch 168/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0057\n",
      "Epoch 169/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0058\n",
      "Epoch 170/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0060\n",
      "Epoch 171/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0056\n",
      "Epoch 172/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0057\n",
      "Epoch 173/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0055\n",
      "Epoch 174/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0059\n",
      "Epoch 175/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0075\n",
      "Epoch 176/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0057\n",
      "Epoch 177/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0056\n",
      "Epoch 178/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0056\n",
      "Epoch 179/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0054\n",
      "Epoch 180/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0054\n",
      "Epoch 181/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0065\n",
      "Epoch 182/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0057\n",
      "Epoch 183/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0055\n",
      "Epoch 184/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0073\n",
      "Epoch 185/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0058\n",
      "Epoch 186/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0060\n",
      "Epoch 187/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0056\n",
      "Epoch 188/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0058\n",
      "Epoch 189/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0071\n",
      "Epoch 190/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0064\n",
      "Epoch 191/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0055\n",
      "Epoch 192/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0053\n",
      "Epoch 193/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0066\n",
      "Epoch 194/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0065\n",
      "Epoch 195/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0057\n",
      "Epoch 196/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0057\n",
      "Epoch 197/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0058\n",
      "Epoch 198/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0058\n",
      "Epoch 199/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0054\n",
      "Epoch 200/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0057\n",
      "Epoch 201/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0058\n",
      "Epoch 202/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0059\n",
      "Epoch 203/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0059\n",
      "Epoch 204/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0062\n",
      "Epoch 205/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 206/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0058\n",
      "Epoch 207/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0059\n",
      "Epoch 208/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0062\n",
      "Epoch 209/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0056\n",
      "Epoch 210/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0061\n",
      "Epoch 211/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0057\n",
      "Epoch 212/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0063\n",
      "Epoch 213/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0058\n",
      "Epoch 214/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0057\n",
      "Epoch 215/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0060\n",
      "Epoch 216/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0058\n",
      "Epoch 217/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0062\n",
      "Epoch 218/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0057\n",
      "Epoch 219/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0058\n",
      "Epoch 220/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0061\n",
      "Epoch 221/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0055\n",
      "Epoch 222/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0055\n",
      "Epoch 223/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0059\n",
      "Epoch 224/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0054\n",
      "Epoch 225/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0054\n",
      "Epoch 226/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0056\n",
      "Epoch 227/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0056\n",
      "Epoch 228/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0059\n",
      "Epoch 229/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0060\n",
      "Epoch 230/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0059\n",
      "Epoch 231/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0059\n",
      "Epoch 232/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0055\n",
      "Epoch 233/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0058\n",
      "Epoch 234/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0057\n",
      "Epoch 235/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0064\n",
      "Epoch 236/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0056\n",
      "Epoch 237/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0056\n",
      "Epoch 238/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0061\n",
      "Epoch 239/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0056\n",
      "Epoch 240/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0054\n",
      "Epoch 241/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0060\n",
      "Epoch 242/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0058\n",
      "Epoch 243/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0056\n",
      "Epoch 244/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0067\n",
      "Epoch 245/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0055\n",
      "Epoch 246/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0060\n",
      "Epoch 247/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0060\n",
      "Epoch 248/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0058\n",
      "Epoch 249/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0057\n",
      "Epoch 250/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0054\n",
      "Epoch 251/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0056\n",
      "Epoch 252/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0055\n",
      "Epoch 253/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0060\n",
      "Epoch 254/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0052\n",
      "Epoch 255/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0054\n",
      "Epoch 256/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0056\n",
      "Epoch 257/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0053\n",
      "Epoch 258/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0053\n",
      "Epoch 259/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0060\n",
      "Epoch 260/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0072\n",
      "Epoch 261/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0055\n",
      "Epoch 262/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0060\n",
      "Epoch 263/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0052\n",
      "Epoch 264/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0052\n",
      "Epoch 265/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0051\n",
      "Epoch 266/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0055\n",
      "Epoch 267/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 268/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0053\n",
      "Epoch 269/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0058\n",
      "Epoch 270/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 271/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0056\n",
      "Epoch 272/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0053\n",
      "Epoch 273/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0063\n",
      "Epoch 274/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0050\n",
      "Epoch 275/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0050\n",
      "Epoch 276/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0059\n",
      "Epoch 277/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0057\n",
      "Epoch 278/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0056\n",
      "Epoch 279/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0050\n",
      "Epoch 280/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0053\n",
      "Epoch 281/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0075\n",
      "Epoch 282/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0055\n",
      "Epoch 283/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0049\n",
      "Epoch 284/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 285/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0063\n",
      "Epoch 286/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 287/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 288/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0053\n",
      "Epoch 289/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0050\n",
      "Epoch 290/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0048\n",
      "Epoch 291/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0049\n",
      "Epoch 292/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0053\n",
      "Epoch 293/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0069\n",
      "Epoch 294/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0053\n",
      "Epoch 295/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0048\n",
      "Epoch 296/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 297/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0048\n",
      "Epoch 298/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 299/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0049\n",
      "Epoch 300/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 301/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0052\n",
      "Epoch 302/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 303/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 304/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 305/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0047\n",
      "Epoch 306/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0058\n",
      "Epoch 307/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0049\n",
      "Epoch 308/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0048\n",
      "Epoch 309/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0048\n",
      "Epoch 310/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0047\n",
      "Epoch 311/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0049\n",
      "Epoch 312/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0052\n",
      "Epoch 313/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0048\n",
      "Epoch 314/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0050\n",
      "Epoch 315/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0068\n",
      "Epoch 316/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 317/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0048\n",
      "Epoch 318/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0059\n",
      "Epoch 319/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0047\n",
      "Epoch 320/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 321/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0048\n",
      "Epoch 322/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 323/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 324/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0053\n",
      "Epoch 325/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 326/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0047\n",
      "Epoch 327/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 328/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 329/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 330/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 331/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0048\n",
      "Epoch 332/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 333/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 334/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0045\n",
      "Epoch 335/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 336/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 337/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0049\n",
      "Epoch 338/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 339/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 340/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0046\n",
      "Epoch 341/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 342/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 343/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 344/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0052\n",
      "Epoch 345/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0048\n",
      "Epoch 346/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0046\n",
      "Epoch 347/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0051\n",
      "Epoch 348/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0044\n",
      "Epoch 349/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0051\n",
      "Epoch 350/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 351/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0051\n",
      "Epoch 352/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0044\n",
      "Epoch 353/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 354/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 355/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 356/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 357/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 358/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 359/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 360/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0043\n",
      "Epoch 361/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 362/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0045\n",
      "Epoch 363/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 364/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0057\n",
      "Epoch 365/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0044\n",
      "Epoch 366/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 367/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0052\n",
      "Epoch 368/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0043\n",
      "Epoch 369/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 370/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 371/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 372/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0046\n",
      "Epoch 373/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 374/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0045\n",
      "Epoch 375/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 376/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 377/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 378/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 379/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 380/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 381/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0058\n",
      "Epoch 382/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0044\n",
      "Epoch 383/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 384/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 385/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 386/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0047\n",
      "Epoch 387/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 388/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 389/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 390/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 391/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0044\n",
      "Epoch 392/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 393/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 394/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 395/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 396/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 397/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 398/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0052\n",
      "Epoch 399/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 400/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0058\n",
      "Epoch 401/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0044\n",
      "Epoch 402/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 403/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0047\n",
      "Epoch 404/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0046\n",
      "Epoch 405/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 406/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 407/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0066\n",
      "Epoch 408/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0048\n",
      "Epoch 409/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 410/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0048\n",
      "Epoch 411/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0044\n",
      "Epoch 412/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 413/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 414/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 415/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 416/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 417/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0075\n",
      "Epoch 418/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0047\n",
      "Epoch 419/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 420/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 421/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 422/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 423/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 424/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0046\n",
      "Epoch 425/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 426/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 427/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 428/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 429/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 430/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 431/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 432/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 433/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 434/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 435/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 436/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 437/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 438/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 439/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0048\n",
      "Epoch 440/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 441/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0046\n",
      "Epoch 442/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0059\n",
      "Epoch 443/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 444/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 445/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 446/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 447/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 448/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 449/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0056\n",
      "Epoch 450/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 451/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 452/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 453/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 454/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0051\n",
      "Epoch 455/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0052\n",
      "Epoch 456/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 457/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 458/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 459/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 460/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 461/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 462/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0049\n",
      "Epoch 463/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 464/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 465/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0049\n",
      "Epoch 466/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0045\n",
      "Epoch 467/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 468/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 469/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 470/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 471/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0043\n",
      "Epoch 472/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 473/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 474/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 475/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 476/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 477/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 478/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 479/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 480/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 481/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 482/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 483/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 484/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 485/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0049\n",
      "Epoch 486/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 487/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 488/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 489/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 490/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0047\n",
      "Epoch 491/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 492/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 493/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 494/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 495/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0042\n",
      "Epoch 496/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 497/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 498/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0054\n",
      "Epoch 499/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0045\n",
      "Epoch 500/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 501/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 502/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 503/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 504/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 505/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0055\n",
      "Epoch 506/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0044\n",
      "Epoch 507/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 508/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 509/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 510/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 511/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 512/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0047\n",
      "Epoch 513/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 514/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 515/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 516/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 517/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 518/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 519/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 520/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0062\n",
      "Epoch 521/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0047\n",
      "Epoch 522/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 523/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 524/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0045\n",
      "Epoch 525/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 526/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 527/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0047\n",
      "Epoch 528/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0045\n",
      "Epoch 529/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 530/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 531/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 532/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0047\n",
      "Epoch 533/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 534/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 535/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 536/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 537/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 538/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 539/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 540/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 541/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 542/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 543/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 544/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0045\n",
      "Epoch 545/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 546/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 547/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 548/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 549/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 550/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 551/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 552/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 553/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 554/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0044\n",
      "Epoch 555/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 556/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 557/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 558/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 559/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0059\n",
      "Epoch 560/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 561/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 562/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0048\n",
      "Epoch 563/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 564/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 565/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 566/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0042\n",
      "Epoch 567/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 568/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 569/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 570/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0042\n",
      "Epoch 571/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 572/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 573/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0042\n",
      "Epoch 574/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 575/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 576/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 577/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 578/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0058\n",
      "Epoch 579/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0045\n",
      "Epoch 580/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 581/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 582/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 583/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 584/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 585/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 586/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 587/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0060\n",
      "Epoch 588/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 589/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 590/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 591/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 592/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 593/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 594/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 595/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 00595: early stopping\n",
      "Epoch 1/10000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4020 - val_loss: 0.0405\n",
      "Epoch 2/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1004 - val_loss: 0.0444\n",
      "Epoch 3/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0848 - val_loss: 0.0394\n",
      "Epoch 4/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0751 - val_loss: 0.0333\n",
      "Epoch 5/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0656 - val_loss: 0.0344\n",
      "Epoch 6/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0608 - val_loss: 0.0330\n",
      "Epoch 7/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0533 - val_loss: 0.0349\n",
      "Epoch 8/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0495 - val_loss: 0.0308\n",
      "Epoch 9/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0439 - val_loss: 0.0286\n",
      "Epoch 10/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0379 - val_loss: 0.0222\n",
      "Epoch 11/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0320 - val_loss: 0.0176\n",
      "Epoch 12/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0288 - val_loss: 0.0167\n",
      "Epoch 13/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0271 - val_loss: 0.0159\n",
      "Epoch 14/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0262 - val_loss: 0.0158\n",
      "Epoch 15/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0255 - val_loss: 0.0162\n",
      "Epoch 16/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0251 - val_loss: 0.0155\n",
      "Epoch 17/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.0154\n",
      "Epoch 18/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.0183\n",
      "Epoch 19/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0250 - val_loss: 0.0153\n",
      "Epoch 20/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0229 - val_loss: 0.0154\n",
      "Epoch 21/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.0156\n",
      "Epoch 22/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0164\n",
      "Epoch 23/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0151\n",
      "Epoch 24/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0213 - val_loss: 0.0150\n",
      "Epoch 25/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.0150\n",
      "Epoch 26/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0153\n",
      "Epoch 27/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0151\n",
      "Epoch 28/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0205 - val_loss: 0.0155\n",
      "Epoch 29/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0152\n",
      "Epoch 30/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0151\n",
      "Epoch 31/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0198 - val_loss: 0.0162\n",
      "Epoch 32/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0203 - val_loss: 0.0151\n",
      "Epoch 33/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0151\n",
      "Epoch 34/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0195 - val_loss: 0.0154\n",
      "Epoch 35/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0159\n",
      "Epoch 36/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0194 - val_loss: 0.0150\n",
      "Epoch 37/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0159\n",
      "Epoch 38/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0150\n",
      "Epoch 39/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0150\n",
      "Epoch 40/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0190 - val_loss: 0.0149\n",
      "Epoch 41/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0188 - val_loss: 0.0149\n",
      "Epoch 42/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0151\n",
      "Epoch 43/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.0150\n",
      "Epoch 44/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0185 - val_loss: 0.0153\n",
      "Epoch 45/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0150\n",
      "Epoch 46/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0151\n",
      "Epoch 47/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0182 - val_loss: 0.0152\n",
      "Epoch 48/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.0150\n",
      "Epoch 49/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0179 - val_loss: 0.0149\n",
      "Epoch 50/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0157\n",
      "Epoch 51/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0156\n",
      "Epoch 52/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0149\n",
      "Epoch 53/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0149\n",
      "Epoch 54/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0176 - val_loss: 0.0152\n",
      "Epoch 55/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0152\n",
      "Epoch 56/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0149\n",
      "Epoch 57/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0159\n",
      "Epoch 58/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0179 - val_loss: 0.0153\n",
      "Epoch 59/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0152\n",
      "Epoch 60/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0173 - val_loss: 0.0148\n",
      "Epoch 61/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0174 - val_loss: 0.0149\n",
      "Epoch 62/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0173 - val_loss: 0.0149\n",
      "Epoch 63/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.0150\n",
      "Epoch 64/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0174 - val_loss: 0.0150\n",
      "Epoch 65/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0173 - val_loss: 0.0149\n",
      "Epoch 66/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0148\n",
      "Epoch 67/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0152\n",
      "Epoch 68/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0156\n",
      "Epoch 69/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0149\n",
      "Epoch 70/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0152\n",
      "Epoch 71/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0173 - val_loss: 0.0149\n",
      "Epoch 72/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0148\n",
      "Epoch 73/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0171 - val_loss: 0.0179\n",
      "Epoch 74/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0175 - val_loss: 0.0160\n",
      "Epoch 75/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0152\n",
      "Epoch 76/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.0156\n",
      "Epoch 77/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0170 - val_loss: 0.0149\n",
      "Epoch 78/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0153\n",
      "Epoch 79/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0149\n",
      "Epoch 80/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0149\n",
      "Epoch 81/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0149\n",
      "Epoch 82/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0149\n",
      "Epoch 83/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0150\n",
      "Epoch 84/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0149\n",
      "Epoch 85/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0151\n",
      "Epoch 86/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0149\n",
      "Epoch 87/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0149\n",
      "Epoch 88/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0149\n",
      "Epoch 89/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0151\n",
      "Epoch 90/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0150\n",
      "Epoch 91/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0148\n",
      "Epoch 92/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0150\n",
      "Epoch 93/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0152\n",
      "Epoch 94/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0155\n",
      "Epoch 95/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0152\n",
      "Epoch 96/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0148\n",
      "Epoch 97/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0149\n",
      "Epoch 98/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0152\n",
      "Epoch 99/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0151\n",
      "Epoch 100/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0150\n",
      "Epoch 101/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0152\n",
      "Epoch 102/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0151\n",
      "Epoch 103/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0150\n",
      "Epoch 104/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0152\n",
      "Epoch 105/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0159\n",
      "Epoch 106/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0148\n",
      "Epoch 107/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0152\n",
      "Epoch 108/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0149\n",
      "Epoch 109/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0150\n",
      "Epoch 110/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0153\n",
      "Epoch 111/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0149\n",
      "Epoch 112/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0148\n",
      "Epoch 113/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0151\n",
      "Epoch 114/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0153\n",
      "Epoch 115/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0155\n",
      "Epoch 116/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0153\n",
      "Epoch 117/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0149\n",
      "Epoch 118/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0155\n",
      "Epoch 119/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0149\n",
      "Epoch 120/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0148\n",
      "Epoch 121/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0152\n",
      "Epoch 122/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0149\n",
      "Epoch 123/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0164\n",
      "Epoch 124/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0179 - val_loss: 0.0152\n",
      "Epoch 125/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0155\n",
      "Epoch 126/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0149\n",
      "Epoch 127/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0150\n",
      "Epoch 128/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0149\n",
      "Epoch 129/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0149\n",
      "Epoch 130/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0148\n",
      "Epoch 131/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0149\n",
      "Epoch 132/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0148\n",
      "Epoch 133/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0150\n",
      "Epoch 134/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0164\n",
      "Epoch 135/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0150\n",
      "Epoch 136/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0148\n",
      "Epoch 137/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0153\n",
      "Epoch 138/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0150\n",
      "Epoch 139/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0152\n",
      "Epoch 140/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0151\n",
      "Epoch 141/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0148\n",
      "Epoch 142/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0148\n",
      "Epoch 143/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0157\n",
      "Epoch 144/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0148\n",
      "Epoch 145/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0150\n",
      "Epoch 146/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0155\n",
      "Epoch 147/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0150\n",
      "Epoch 148/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0149\n",
      "Epoch 149/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0151\n",
      "Epoch 150/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0151\n",
      "Epoch 151/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0149\n",
      "Epoch 152/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0151\n",
      "Epoch 153/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0160\n",
      "Epoch 154/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0149\n",
      "Epoch 155/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0148\n",
      "Epoch 156/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0150\n",
      "Epoch 157/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0149\n",
      "Epoch 158/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0157\n",
      "Epoch 159/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0151\n",
      "Epoch 160/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0151\n",
      "Epoch 161/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0151\n",
      "Epoch 162/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0150\n",
      "Epoch 163/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0148\n",
      "Epoch 164/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0160\n",
      "Epoch 165/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0152\n",
      "Epoch 166/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0151\n",
      "Epoch 00166: early stopping\n",
      "Epoch 1/10000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3744 - val_loss: 0.0470\n",
      "Epoch 2/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1093 - val_loss: 0.0343\n",
      "Epoch 3/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0914 - val_loss: 0.0338\n",
      "Epoch 4/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0788 - val_loss: 0.0325\n",
      "Epoch 5/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0699 - val_loss: 0.0332\n",
      "Epoch 6/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0617 - val_loss: 0.0298\n",
      "Epoch 7/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0548 - val_loss: 0.0229\n",
      "Epoch 8/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0456 - val_loss: 0.0183\n",
      "Epoch 9/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0392 - val_loss: 0.0168\n",
      "Epoch 10/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0349 - val_loss: 0.0195\n",
      "Epoch 11/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0331 - val_loss: 0.0173\n",
      "Epoch 12/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0296 - val_loss: 0.0163\n",
      "Epoch 13/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.0175\n",
      "Epoch 14/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0271 - val_loss: 0.0153\n",
      "Epoch 15/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0257 - val_loss: 0.0153\n",
      "Epoch 16/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0251 - val_loss: 0.0151\n",
      "Epoch 17/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.0149\n",
      "Epoch 18/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0239 - val_loss: 0.0155\n",
      "Epoch 19/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.0155\n",
      "Epoch 20/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.0154\n",
      "Epoch 21/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.0151\n",
      "Epoch 22/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0146\n",
      "Epoch 23/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.0146\n",
      "Epoch 24/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.0144\n",
      "Epoch 25/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0141\n",
      "Epoch 26/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0141\n",
      "Epoch 27/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0139\n",
      "Epoch 28/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0124\n",
      "Epoch 29/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0128\n",
      "Epoch 30/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.0121\n",
      "Epoch 31/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0121\n",
      "Epoch 32/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0120\n",
      "Epoch 33/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0120\n",
      "Epoch 34/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0118\n",
      "Epoch 35/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0118\n",
      "Epoch 36/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0116\n",
      "Epoch 37/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0117\n",
      "Epoch 38/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0116\n",
      "Epoch 39/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0119\n",
      "Epoch 40/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0114\n",
      "Epoch 41/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0123\n",
      "Epoch 42/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0123\n",
      "Epoch 43/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0118\n",
      "Epoch 44/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0123\n",
      "Epoch 45/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0114\n",
      "Epoch 46/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0116\n",
      "Epoch 47/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0117\n",
      "Epoch 48/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0125\n",
      "Epoch 49/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0139\n",
      "Epoch 51/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0117\n",
      "Epoch 52/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0136\n",
      "Epoch 53/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0120\n",
      "Epoch 54/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0119\n",
      "Epoch 55/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0117\n",
      "Epoch 56/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0116\n",
      "Epoch 57/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0118\n",
      "Epoch 58/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0117\n",
      "Epoch 59/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0121\n",
      "Epoch 60/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0117\n",
      "Epoch 61/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0116\n",
      "Epoch 62/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0114\n",
      "Epoch 63/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0118\n",
      "Epoch 64/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0117\n",
      "Epoch 65/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0118\n",
      "Epoch 66/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0115\n",
      "Epoch 67/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0118\n",
      "Epoch 68/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0118\n",
      "Epoch 69/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0145 - val_loss: 0.0119\n",
      "Epoch 70/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0117\n",
      "Epoch 71/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0117\n",
      "Epoch 72/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0117\n",
      "Epoch 73/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0115\n",
      "Epoch 74/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0117\n",
      "Epoch 75/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0124\n",
      "Epoch 76/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0118\n",
      "Epoch 77/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0142 - val_loss: 0.0120\n",
      "Epoch 78/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0120\n",
      "Epoch 79/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0121\n",
      "Epoch 80/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0130\n",
      "Epoch 81/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0118\n",
      "Epoch 82/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0119\n",
      "Epoch 83/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0116\n",
      "Epoch 84/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0115\n",
      "Epoch 85/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0121\n",
      "Epoch 86/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0115\n",
      "Epoch 87/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0118\n",
      "Epoch 88/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0118\n",
      "Epoch 89/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0128\n",
      "Epoch 90/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0122\n",
      "Epoch 91/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0137\n",
      "Epoch 92/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0124\n",
      "Epoch 93/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0116\n",
      "Epoch 94/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0117\n",
      "Epoch 95/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0115\n",
      "Epoch 96/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0119\n",
      "Epoch 97/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0115\n",
      "Epoch 98/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0116\n",
      "Epoch 99/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0117\n",
      "Epoch 100/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0120\n",
      "Epoch 101/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0117\n",
      "Epoch 102/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.0116\n",
      "Epoch 103/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0124\n",
      "Epoch 104/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0116\n",
      "Epoch 105/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0117\n",
      "Epoch 106/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0121\n",
      "Epoch 107/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0128\n",
      "Epoch 108/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.0122\n",
      "Epoch 109/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0119\n",
      "Epoch 110/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0116\n",
      "Epoch 111/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0117\n",
      "Epoch 112/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0116\n",
      "Epoch 113/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0115\n",
      "Epoch 114/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0116\n",
      "Epoch 115/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0119\n",
      "Epoch 116/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0115\n",
      "Epoch 117/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0119\n",
      "Epoch 118/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0119\n",
      "Epoch 119/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.0118\n",
      "Epoch 120/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0117\n",
      "Epoch 121/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.0116\n",
      "Epoch 122/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.0126\n",
      "Epoch 123/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0124\n",
      "Epoch 124/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0119\n",
      "Epoch 125/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0116\n",
      "Epoch 126/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0126\n",
      "Epoch 127/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0125\n",
      "Epoch 128/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0120\n",
      "Epoch 129/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0118\n",
      "Epoch 130/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0116\n",
      "Epoch 131/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0118\n",
      "Epoch 132/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.0116\n",
      "Epoch 133/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0117\n",
      "Epoch 134/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 135/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.0118\n",
      "Epoch 136/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0129\n",
      "Epoch 137/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0125\n",
      "Epoch 138/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0117\n",
      "Epoch 139/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0122\n",
      "Epoch 140/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0119\n",
      "Epoch 141/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0119\n",
      "Epoch 142/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0116\n",
      "Epoch 143/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0118\n",
      "Epoch 144/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.0121\n",
      "Epoch 145/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0122\n",
      "Epoch 146/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0131\n",
      "Epoch 147/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 148/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0128\n",
      "Epoch 149/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0116\n",
      "Epoch 150/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0120\n",
      "Epoch 151/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0117\n",
      "Epoch 152/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0116\n",
      "Epoch 153/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0116\n",
      "Epoch 154/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0115\n",
      "Epoch 155/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0119\n",
      "Epoch 156/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0119\n",
      "Epoch 157/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0116\n",
      "Epoch 158/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0118\n",
      "Epoch 159/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0116\n",
      "Epoch 160/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.0116\n",
      "Epoch 161/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.0131\n",
      "Epoch 162/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0117\n",
      "Epoch 00162: early stopping\n",
      "Epoch 1/10000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3652 - val_loss: 0.0419\n",
      "Epoch 2/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1048 - val_loss: 0.0354\n",
      "Epoch 3/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0831 - val_loss: 0.0273\n",
      "Epoch 4/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.0203\n",
      "Epoch 5/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0189\n",
      "Epoch 6/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0528 - val_loss: 0.0203\n",
      "Epoch 7/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.0175\n",
      "Epoch 8/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0409 - val_loss: 0.0179\n",
      "Epoch 9/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0368 - val_loss: 0.0158\n",
      "Epoch 10/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0344 - val_loss: 0.0181\n",
      "Epoch 11/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0314 - val_loss: 0.0147\n",
      "Epoch 12/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0285 - val_loss: 0.0141\n",
      "Epoch 13/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.0138\n",
      "Epoch 14/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.0139\n",
      "Epoch 15/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0236 - val_loss: 0.0130\n",
      "Epoch 16/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.0128\n",
      "Epoch 17/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.0122\n",
      "Epoch 18/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0121\n",
      "Epoch 19/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0118\n",
      "Epoch 20/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0124\n",
      "Epoch 21/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0120\n",
      "Epoch 22/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0132\n",
      "Epoch 23/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0117\n",
      "Epoch 24/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0118\n",
      "Epoch 25/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0115\n",
      "Epoch 26/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0117\n",
      "Epoch 27/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0118\n",
      "Epoch 28/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0112\n",
      "Epoch 29/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0111\n",
      "Epoch 30/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0106\n",
      "Epoch 31/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0104\n",
      "Epoch 32/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0107\n",
      "Epoch 33/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0102\n",
      "Epoch 34/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0106\n",
      "Epoch 35/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0096\n",
      "Epoch 36/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0088\n",
      "Epoch 37/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.0092\n",
      "Epoch 38/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0094\n",
      "Epoch 39/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0090\n",
      "Epoch 40/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0088\n",
      "Epoch 41/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.0087\n",
      "Epoch 42/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0085\n",
      "Epoch 43/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0090\n",
      "Epoch 44/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0091\n",
      "Epoch 45/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0100\n",
      "Epoch 46/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0084\n",
      "Epoch 47/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0086\n",
      "Epoch 49/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0087\n",
      "Epoch 50/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0089\n",
      "Epoch 51/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0091\n",
      "Epoch 52/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0086\n",
      "Epoch 53/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0084\n",
      "Epoch 54/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0087\n",
      "Epoch 55/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.0086\n",
      "Epoch 56/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0087\n",
      "Epoch 57/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0085\n",
      "Epoch 58/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0088\n",
      "Epoch 59/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0095\n",
      "Epoch 60/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0095\n",
      "Epoch 61/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0088\n",
      "Epoch 62/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0085\n",
      "Epoch 63/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0090\n",
      "Epoch 64/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0086\n",
      "Epoch 65/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0084\n",
      "Epoch 66/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0089\n",
      "Epoch 67/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 68/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0088\n",
      "Epoch 69/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0095\n",
      "Epoch 70/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0086\n",
      "Epoch 71/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0084\n",
      "Epoch 72/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0089\n",
      "Epoch 73/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0086\n",
      "Epoch 74/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0085\n",
      "Epoch 75/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0087\n",
      "Epoch 76/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0086\n",
      "Epoch 77/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0084\n",
      "Epoch 78/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0084\n",
      "Epoch 79/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0086\n",
      "Epoch 80/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0084\n",
      "Epoch 81/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0091\n",
      "Epoch 82/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0086\n",
      "Epoch 83/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0086\n",
      "Epoch 84/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0086\n",
      "Epoch 85/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.0089\n",
      "Epoch 86/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0088\n",
      "Epoch 87/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0092\n",
      "Epoch 88/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0086\n",
      "Epoch 89/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0090\n",
      "Epoch 90/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0084\n",
      "Epoch 91/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0088\n",
      "Epoch 92/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0088\n",
      "Epoch 93/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0087\n",
      "Epoch 94/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0092\n",
      "Epoch 95/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0089\n",
      "Epoch 96/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0086\n",
      "Epoch 97/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0090\n",
      "Epoch 98/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0084\n",
      "Epoch 99/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0086\n",
      "Epoch 100/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0085\n",
      "Epoch 101/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0088\n",
      "Epoch 102/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0087\n",
      "Epoch 103/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0085\n",
      "Epoch 104/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 105/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0090\n",
      "Epoch 106/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0088\n",
      "Epoch 107/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0088\n",
      "Epoch 108/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0085\n",
      "Epoch 109/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0086\n",
      "Epoch 110/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0084\n",
      "Epoch 111/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0086\n",
      "Epoch 112/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0084\n",
      "Epoch 113/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0084\n",
      "Epoch 114/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0089\n",
      "Epoch 115/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0085\n",
      "Epoch 116/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0095\n",
      "Epoch 117/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0084\n",
      "Epoch 118/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0091\n",
      "Epoch 119/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0084\n",
      "Epoch 120/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0096\n",
      "Epoch 121/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0085\n",
      "Epoch 122/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0085\n",
      "Epoch 123/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0115\n",
      "Epoch 124/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0085\n",
      "Epoch 125/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 126/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0086\n",
      "Epoch 127/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0085\n",
      "Epoch 128/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0086\n",
      "Epoch 129/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0085\n",
      "Epoch 130/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0085\n",
      "Epoch 131/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0087\n",
      "Epoch 132/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0089\n",
      "Epoch 133/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 134/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0088\n",
      "Epoch 135/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0091\n",
      "Epoch 136/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 137/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0097\n",
      "Epoch 138/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0086\n",
      "Epoch 139/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0088\n",
      "Epoch 140/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0084\n",
      "Epoch 141/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0092\n",
      "Epoch 142/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0088\n",
      "Epoch 143/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0095\n",
      "Epoch 144/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0094\n",
      "Epoch 145/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0089\n",
      "Epoch 146/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0087\n",
      "Epoch 147/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0088\n",
      "Epoch 148/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0089\n",
      "Epoch 149/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0085\n",
      "Epoch 150/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0084\n",
      "Epoch 151/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0092\n",
      "Epoch 152/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0086\n",
      "Epoch 153/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0116\n",
      "Epoch 154/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0092\n",
      "Epoch 155/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0086\n",
      "Epoch 156/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0088\n",
      "Epoch 157/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0085\n",
      "Epoch 158/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0085\n",
      "Epoch 159/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0086\n",
      "Epoch 160/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0095\n",
      "Epoch 161/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0085\n",
      "Epoch 162/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0084\n",
      "Epoch 163/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0086\n",
      "Epoch 164/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0085\n",
      "Epoch 165/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0095\n",
      "Epoch 166/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0086\n",
      "Epoch 167/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0084\n",
      "Epoch 168/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0084\n",
      "Epoch 169/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0086\n",
      "Epoch 170/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0084\n",
      "Epoch 171/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0093\n",
      "Epoch 172/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0088\n",
      "Epoch 173/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0090\n",
      "Epoch 174/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0084\n",
      "Epoch 175/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0084\n",
      "Epoch 176/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0086\n",
      "Epoch 177/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0086\n",
      "Epoch 178/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0083\n",
      "Epoch 179/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0086\n",
      "Epoch 180/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0086\n",
      "Epoch 181/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0093\n",
      "Epoch 182/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0086\n",
      "Epoch 183/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0086\n",
      "Epoch 184/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0092\n",
      "Epoch 185/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0084\n",
      "Epoch 186/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0084\n",
      "Epoch 187/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0121\n",
      "Epoch 188/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0089\n",
      "Epoch 189/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0085\n",
      "Epoch 190/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0084\n",
      "Epoch 191/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0087\n",
      "Epoch 192/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0085\n",
      "Epoch 193/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0086\n",
      "Epoch 194/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0092\n",
      "Epoch 195/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0089\n",
      "Epoch 196/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0086\n",
      "Epoch 197/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0087\n",
      "Epoch 198/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0083\n",
      "Epoch 199/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0091\n",
      "Epoch 200/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0088\n",
      "Epoch 201/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0088\n",
      "Epoch 202/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0091\n",
      "Epoch 203/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0088\n",
      "Epoch 204/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0085\n",
      "Epoch 205/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0083\n",
      "Epoch 206/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0089\n",
      "Epoch 207/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0087\n",
      "Epoch 208/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0090\n",
      "Epoch 209/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0088\n",
      "Epoch 210/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0086\n",
      "Epoch 211/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0083\n",
      "Epoch 212/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0082\n",
      "Epoch 213/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0089\n",
      "Epoch 214/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0087\n",
      "Epoch 215/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0083\n",
      "Epoch 216/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0090\n",
      "Epoch 217/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0084\n",
      "Epoch 218/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0084\n",
      "Epoch 219/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0091\n",
      "Epoch 220/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0082\n",
      "Epoch 221/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0096\n",
      "Epoch 222/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0082\n",
      "Epoch 223/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0082\n",
      "Epoch 224/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0087\n",
      "Epoch 225/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0083\n",
      "Epoch 226/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0097\n",
      "Epoch 227/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0084\n",
      "Epoch 228/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0085\n",
      "Epoch 229/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0080\n",
      "Epoch 230/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0081\n",
      "Epoch 231/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0082\n",
      "Epoch 232/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0083\n",
      "Epoch 233/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0091\n",
      "Epoch 234/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0084\n",
      "Epoch 235/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0082\n",
      "Epoch 236/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0082\n",
      "Epoch 237/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0087\n",
      "Epoch 238/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0081\n",
      "Epoch 239/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0089\n",
      "Epoch 240/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0081\n",
      "Epoch 241/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0080\n",
      "Epoch 242/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0080\n",
      "Epoch 243/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0080\n",
      "Epoch 244/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0079\n",
      "Epoch 245/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0087\n",
      "Epoch 246/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0091\n",
      "Epoch 247/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0088\n",
      "Epoch 248/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0084\n",
      "Epoch 249/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0082\n",
      "Epoch 250/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0087\n",
      "Epoch 251/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0078\n",
      "Epoch 252/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0079\n",
      "Epoch 253/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0081\n",
      "Epoch 254/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0080\n",
      "Epoch 255/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0083\n",
      "Epoch 256/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0090\n",
      "Epoch 257/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0081\n",
      "Epoch 258/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0081\n",
      "Epoch 259/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0080\n",
      "Epoch 260/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0086\n",
      "Epoch 261/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0080\n",
      "Epoch 262/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0082\n",
      "Epoch 263/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0079\n",
      "Epoch 264/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0084\n",
      "Epoch 265/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0079\n",
      "Epoch 266/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0085\n",
      "Epoch 267/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 268/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 269/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 270/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0084\n",
      "Epoch 271/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0086\n",
      "Epoch 272/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0080\n",
      "Epoch 273/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 274/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0080\n",
      "Epoch 275/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0082\n",
      "Epoch 276/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0077\n",
      "Epoch 277/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0079\n",
      "Epoch 278/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0078\n",
      "Epoch 279/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0079\n",
      "Epoch 280/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0080\n",
      "Epoch 281/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0083\n",
      "Epoch 282/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0085\n",
      "Epoch 283/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0078\n",
      "Epoch 284/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0078\n",
      "Epoch 285/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0083\n",
      "Epoch 286/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0083\n",
      "Epoch 287/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0077\n",
      "Epoch 288/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0087\n",
      "Epoch 289/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0082\n",
      "Epoch 290/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0080\n",
      "Epoch 291/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0084\n",
      "Epoch 292/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0080\n",
      "Epoch 293/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0077\n",
      "Epoch 294/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0082\n",
      "Epoch 295/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0078\n",
      "Epoch 296/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0082\n",
      "Epoch 297/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0078\n",
      "Epoch 298/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0078\n",
      "Epoch 299/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0083\n",
      "Epoch 300/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0080\n",
      "Epoch 301/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0077\n",
      "Epoch 302/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0082\n",
      "Epoch 303/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0079\n",
      "Epoch 304/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0078\n",
      "Epoch 305/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0079\n",
      "Epoch 306/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0090\n",
      "Epoch 307/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0078\n",
      "Epoch 308/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0078\n",
      "Epoch 309/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0081\n",
      "Epoch 310/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0079\n",
      "Epoch 311/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0077\n",
      "Epoch 312/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0082\n",
      "Epoch 313/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0080\n",
      "Epoch 314/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 315/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0078\n",
      "Epoch 316/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0079\n",
      "Epoch 317/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0088\n",
      "Epoch 318/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0091\n",
      "Epoch 319/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0080\n",
      "Epoch 320/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0079\n",
      "Epoch 321/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0088\n",
      "Epoch 322/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0077\n",
      "Epoch 323/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0078\n",
      "Epoch 324/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0078\n",
      "Epoch 325/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0082\n",
      "Epoch 326/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0079\n",
      "Epoch 327/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0076\n",
      "Epoch 328/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0082\n",
      "Epoch 329/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0079\n",
      "Epoch 330/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0080\n",
      "Epoch 331/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0080\n",
      "Epoch 332/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0089\n",
      "Epoch 333/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0084\n",
      "Epoch 334/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0089\n",
      "Epoch 335/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0077\n",
      "Epoch 336/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0079\n",
      "Epoch 337/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0077\n",
      "Epoch 338/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0083\n",
      "Epoch 339/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0082\n",
      "Epoch 340/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0078\n",
      "Epoch 341/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0081\n",
      "Epoch 342/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0077\n",
      "Epoch 343/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0080\n",
      "Epoch 344/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0081\n",
      "Epoch 345/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 346/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0078\n",
      "Epoch 347/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 348/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0079\n",
      "Epoch 349/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0078\n",
      "Epoch 350/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0076\n",
      "Epoch 351/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0089\n",
      "Epoch 352/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 353/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0077\n",
      "Epoch 354/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0076\n",
      "Epoch 355/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0080\n",
      "Epoch 356/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0075\n",
      "Epoch 357/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0078\n",
      "Epoch 358/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 359/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0074\n",
      "Epoch 360/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0078\n",
      "Epoch 361/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0075\n",
      "Epoch 362/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0077\n",
      "Epoch 363/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0080\n",
      "Epoch 364/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0092\n",
      "Epoch 365/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0074\n",
      "Epoch 366/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0075\n",
      "Epoch 367/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0074\n",
      "Epoch 368/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0076\n",
      "Epoch 369/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0082\n",
      "Epoch 370/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0080\n",
      "Epoch 371/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0074\n",
      "Epoch 372/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0083\n",
      "Epoch 373/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0087\n",
      "Epoch 374/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0074\n",
      "Epoch 375/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0093\n",
      "Epoch 376/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0073\n",
      "Epoch 377/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0076\n",
      "Epoch 378/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0074\n",
      "Epoch 379/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0072\n",
      "Epoch 380/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0075\n",
      "Epoch 381/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0079\n",
      "Epoch 382/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0072\n",
      "Epoch 383/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0071\n",
      "Epoch 384/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0074\n",
      "Epoch 385/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0073\n",
      "Epoch 386/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0071\n",
      "Epoch 387/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0070\n",
      "Epoch 388/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0096\n",
      "Epoch 389/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0075\n",
      "Epoch 390/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0077\n",
      "Epoch 391/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0083\n",
      "Epoch 392/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0074\n",
      "Epoch 393/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0080\n",
      "Epoch 394/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0074\n",
      "Epoch 395/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0071\n",
      "Epoch 396/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0076\n",
      "Epoch 397/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0070\n",
      "Epoch 398/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0072\n",
      "Epoch 399/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0088\n",
      "Epoch 400/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0072\n",
      "Epoch 401/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0071\n",
      "Epoch 402/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0071\n",
      "Epoch 403/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0077\n",
      "Epoch 404/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0071\n",
      "Epoch 405/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0071\n",
      "Epoch 406/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0073\n",
      "Epoch 407/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0071\n",
      "Epoch 408/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 409/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0085\n",
      "Epoch 410/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0076\n",
      "Epoch 411/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0072\n",
      "Epoch 412/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0082\n",
      "Epoch 413/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0070\n",
      "Epoch 414/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0073\n",
      "Epoch 415/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0073\n",
      "Epoch 416/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0078\n",
      "Epoch 417/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0071\n",
      "Epoch 418/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 419/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0100\n",
      "Epoch 420/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0109\n",
      "Epoch 421/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0078\n",
      "Epoch 422/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0090\n",
      "Epoch 423/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0077\n",
      "Epoch 424/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0080\n",
      "Epoch 425/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0080\n",
      "Epoch 426/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0074\n",
      "Epoch 427/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0072\n",
      "Epoch 428/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0072\n",
      "Epoch 429/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0070\n",
      "Epoch 430/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0074\n",
      "Epoch 431/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0071\n",
      "Epoch 432/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0070\n",
      "Epoch 433/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0072\n",
      "Epoch 434/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0098\n",
      "Epoch 435/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0078\n",
      "Epoch 436/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0083\n",
      "Epoch 437/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0072\n",
      "Epoch 438/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0074\n",
      "Epoch 439/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0072\n",
      "Epoch 440/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 441/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0077\n",
      "Epoch 442/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0072\n",
      "Epoch 443/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0071\n",
      "Epoch 444/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0073\n",
      "Epoch 445/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0092\n",
      "Epoch 446/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0072\n",
      "Epoch 447/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0070\n",
      "Epoch 448/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0071\n",
      "Epoch 449/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0070\n",
      "Epoch 450/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0076\n",
      "Epoch 451/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0075\n",
      "Epoch 452/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0076\n",
      "Epoch 453/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0076\n",
      "Epoch 454/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0082\n",
      "Epoch 455/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0074\n",
      "Epoch 456/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0070\n",
      "Epoch 457/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0078\n",
      "Epoch 458/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0068\n",
      "Epoch 459/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0070\n",
      "Epoch 460/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0068\n",
      "Epoch 461/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 462/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0071\n",
      "Epoch 463/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0094\n",
      "Epoch 464/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0072\n",
      "Epoch 465/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0070\n",
      "Epoch 466/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0069\n",
      "Epoch 467/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0070\n",
      "Epoch 468/10000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0071\n",
      "Epoch 469/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0072\n",
      "Epoch 470/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0071\n",
      "Epoch 471/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0070\n",
      "Epoch 472/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0072\n",
      "Epoch 473/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0068\n",
      "Epoch 474/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0074\n",
      "Epoch 475/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0072\n",
      "Epoch 476/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0073\n",
      "Epoch 477/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0070\n",
      "Epoch 478/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0069\n",
      "Epoch 479/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0069\n",
      "Epoch 480/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0076\n",
      "Epoch 481/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0071\n",
      "Epoch 482/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0074\n",
      "Epoch 483/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0071\n",
      "Epoch 484/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0070\n",
      "Epoch 485/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0076\n",
      "Epoch 486/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0072\n",
      "Epoch 487/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0069\n",
      "Epoch 488/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 489/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0069\n",
      "Epoch 490/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0068\n",
      "Epoch 491/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0072\n",
      "Epoch 492/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0071\n",
      "Epoch 493/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0070\n",
      "Epoch 494/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0076\n",
      "Epoch 495/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0075\n",
      "Epoch 496/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0071\n",
      "Epoch 497/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0071\n",
      "Epoch 498/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0068\n",
      "Epoch 499/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0069\n",
      "Epoch 500/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0071\n",
      "Epoch 501/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0076\n",
      "Epoch 502/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0070\n",
      "Epoch 503/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0068\n",
      "Epoch 504/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0069\n",
      "Epoch 505/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0068\n",
      "Epoch 506/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0071\n",
      "Epoch 507/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 508/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0067\n",
      "Epoch 509/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0069\n",
      "Epoch 510/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0070\n",
      "Epoch 511/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0070\n",
      "Epoch 512/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0073\n",
      "Epoch 513/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0070\n",
      "Epoch 514/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0076\n",
      "Epoch 515/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0069\n",
      "Epoch 516/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0071\n",
      "Epoch 517/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0071\n",
      "Epoch 518/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0068\n",
      "Epoch 519/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0070\n",
      "Epoch 520/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0069\n",
      "Epoch 521/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0070\n",
      "Epoch 522/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0070\n",
      "Epoch 523/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0070\n",
      "Epoch 524/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0074\n",
      "Epoch 525/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0068\n",
      "Epoch 526/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0067\n",
      "Epoch 527/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0071\n",
      "Epoch 528/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0068\n",
      "Epoch 529/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0070\n",
      "Epoch 530/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0068\n",
      "Epoch 531/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0075\n",
      "Epoch 532/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0071\n",
      "Epoch 533/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 534/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0070\n",
      "Epoch 535/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0068\n",
      "Epoch 536/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0067\n",
      "Epoch 537/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0067\n",
      "Epoch 538/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0067\n",
      "Epoch 539/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 540/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0067\n",
      "Epoch 541/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0068\n",
      "Epoch 542/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0071\n",
      "Epoch 543/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0068\n",
      "Epoch 544/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0067\n",
      "Epoch 545/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0076\n",
      "Epoch 546/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0068\n",
      "Epoch 547/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0069\n",
      "Epoch 548/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0067\n",
      "Epoch 549/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0079\n",
      "Epoch 550/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0070\n",
      "Epoch 551/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0072\n",
      "Epoch 552/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0075\n",
      "Epoch 553/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0069\n",
      "Epoch 554/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0068\n",
      "Epoch 555/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0070\n",
      "Epoch 556/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0071\n",
      "Epoch 557/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0067\n",
      "Epoch 558/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0067\n",
      "Epoch 559/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0074\n",
      "Epoch 560/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0083\n",
      "Epoch 561/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0066\n",
      "Epoch 562/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0068\n",
      "Epoch 563/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0068\n",
      "Epoch 564/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0069\n",
      "Epoch 565/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0081\n",
      "Epoch 566/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0071\n",
      "Epoch 567/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0068\n",
      "Epoch 568/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0072\n",
      "Epoch 569/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0067\n",
      "Epoch 570/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0068\n",
      "Epoch 571/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0068\n",
      "Epoch 572/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0068\n",
      "Epoch 573/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0067\n",
      "Epoch 574/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0068\n",
      "Epoch 575/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0075\n",
      "Epoch 576/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0066\n",
      "Epoch 577/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0068\n",
      "Epoch 578/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0068\n",
      "Epoch 579/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0072\n",
      "Epoch 580/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0070\n",
      "Epoch 581/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0069\n",
      "Epoch 582/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0071\n",
      "Epoch 583/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0068\n",
      "Epoch 584/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0070\n",
      "Epoch 585/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0069\n",
      "Epoch 586/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0067\n",
      "Epoch 587/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 588/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0068\n",
      "Epoch 589/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0069\n",
      "Epoch 590/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0068\n",
      "Epoch 591/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0068\n",
      "Epoch 592/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0071\n",
      "Epoch 593/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0074\n",
      "Epoch 594/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0070\n",
      "Epoch 595/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0082\n",
      "Epoch 596/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0069\n",
      "Epoch 597/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0071\n",
      "Epoch 598/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0076\n",
      "Epoch 599/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0070\n",
      "Epoch 600/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0067\n",
      "Epoch 601/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0080\n",
      "Epoch 602/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0070\n",
      "Epoch 603/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0070\n",
      "Epoch 604/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0074\n",
      "Epoch 605/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0075\n",
      "Epoch 606/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0069\n",
      "Epoch 607/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 608/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0078\n",
      "Epoch 609/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0069\n",
      "Epoch 610/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0066\n",
      "Epoch 611/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0073\n",
      "Epoch 612/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0078\n",
      "Epoch 613/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0070\n",
      "Epoch 614/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0068\n",
      "Epoch 615/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0069\n",
      "Epoch 616/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0074\n",
      "Epoch 617/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0069\n",
      "Epoch 618/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0068\n",
      "Epoch 619/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0069\n",
      "Epoch 620/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0068\n",
      "Epoch 621/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 622/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0067\n",
      "Epoch 623/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0078\n",
      "Epoch 624/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0072\n",
      "Epoch 625/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0066\n",
      "Epoch 626/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0067\n",
      "Epoch 627/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0070\n",
      "Epoch 628/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0073\n",
      "Epoch 629/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0069\n",
      "Epoch 630/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0069\n",
      "Epoch 631/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0070\n",
      "Epoch 632/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0069\n",
      "Epoch 633/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0067\n",
      "Epoch 634/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0069\n",
      "Epoch 635/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0068\n",
      "Epoch 636/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0070\n",
      "Epoch 637/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0075\n",
      "Epoch 638/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0068\n",
      "Epoch 639/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0068\n",
      "Epoch 640/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 641/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0072\n",
      "Epoch 642/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0068\n",
      "Epoch 643/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0068\n",
      "Epoch 644/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0067\n",
      "Epoch 645/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0088\n",
      "Epoch 646/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0069\n",
      "Epoch 647/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0074\n",
      "Epoch 648/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0069\n",
      "Epoch 649/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0069\n",
      "Epoch 650/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 651/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0076\n",
      "Epoch 652/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0071\n",
      "Epoch 653/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0069\n",
      "Epoch 654/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0068\n",
      "Epoch 655/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0073\n",
      "Epoch 656/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0066\n",
      "Epoch 657/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0068\n",
      "Epoch 658/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0073\n",
      "Epoch 659/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0068\n",
      "Epoch 660/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0068\n",
      "Epoch 661/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0068\n",
      "Epoch 662/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0069\n",
      "Epoch 663/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0079\n",
      "Epoch 664/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0082\n",
      "Epoch 665/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0069\n",
      "Epoch 666/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0068\n",
      "Epoch 667/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0067\n",
      "Epoch 668/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0071\n",
      "Epoch 669/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0071\n",
      "Epoch 670/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0071\n",
      "Epoch 671/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0067\n",
      "Epoch 672/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0070\n",
      "Epoch 673/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0076\n",
      "Epoch 674/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0073\n",
      "Epoch 675/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0083\n",
      "Epoch 676/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0073\n",
      "Epoch 00676: early stopping\n",
      "Epoch 1/10000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3925 - val_loss: 0.0420\n",
      "Epoch 2/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1073 - val_loss: 0.0328\n",
      "Epoch 3/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0830 - val_loss: 0.0318\n",
      "Epoch 4/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0716 - val_loss: 0.0262\n",
      "Epoch 5/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0599 - val_loss: 0.0219\n",
      "Epoch 6/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.0202\n",
      "Epoch 7/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0472 - val_loss: 0.0165\n",
      "Epoch 8/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0397 - val_loss: 0.0156\n",
      "Epoch 9/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0357 - val_loss: 0.0147\n",
      "Epoch 10/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0328 - val_loss: 0.0169\n",
      "Epoch 11/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0311 - val_loss: 0.0126\n",
      "Epoch 12/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0265 - val_loss: 0.0122\n",
      "Epoch 13/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0250 - val_loss: 0.0112\n",
      "Epoch 14/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0233 - val_loss: 0.0126\n",
      "Epoch 15/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.0103\n",
      "Epoch 16/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.0107\n",
      "Epoch 17/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0098\n",
      "Epoch 18/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0092\n",
      "Epoch 19/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0092\n",
      "Epoch 20/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0090\n",
      "Epoch 21/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0092\n",
      "Epoch 22/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0091\n",
      "Epoch 23/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0093\n",
      "Epoch 24/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0087\n",
      "Epoch 25/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0088\n",
      "Epoch 26/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0085\n",
      "Epoch 27/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0086\n",
      "Epoch 28/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0091\n",
      "Epoch 29/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0087\n",
      "Epoch 30/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0097\n",
      "Epoch 31/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0086\n",
      "Epoch 32/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0086\n",
      "Epoch 33/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0089\n",
      "Epoch 34/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0084\n",
      "Epoch 35/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0082\n",
      "Epoch 36/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0081\n",
      "Epoch 37/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0082\n",
      "Epoch 38/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.0081\n",
      "Epoch 39/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0080\n",
      "Epoch 40/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0097\n",
      "Epoch 41/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0079\n",
      "Epoch 42/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0073\n",
      "Epoch 43/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0072\n",
      "Epoch 44/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0070\n",
      "Epoch 45/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0074\n",
      "Epoch 46/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0073\n",
      "Epoch 47/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0072\n",
      "Epoch 48/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0068\n",
      "Epoch 49/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0074\n",
      "Epoch 50/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0077\n",
      "Epoch 51/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0078\n",
      "Epoch 52/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0070\n",
      "Epoch 53/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0067\n",
      "Epoch 54/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0068\n",
      "Epoch 55/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0069\n",
      "Epoch 56/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0066\n",
      "Epoch 57/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0071\n",
      "Epoch 58/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0067\n",
      "Epoch 59/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0073\n",
      "Epoch 60/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0067\n",
      "Epoch 61/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0069\n",
      "Epoch 62/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0065\n",
      "Epoch 63/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0066\n",
      "Epoch 64/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0073\n",
      "Epoch 65/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0071\n",
      "Epoch 66/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0066\n",
      "Epoch 67/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0064\n",
      "Epoch 68/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0068\n",
      "Epoch 69/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0067\n",
      "Epoch 70/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0083\n",
      "Epoch 71/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0065\n",
      "Epoch 72/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0065\n",
      "Epoch 73/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0066\n",
      "Epoch 74/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0066\n",
      "Epoch 75/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0067\n",
      "Epoch 76/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0073\n",
      "Epoch 77/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0068\n",
      "Epoch 78/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0068\n",
      "Epoch 79/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0066\n",
      "Epoch 80/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0064\n",
      "Epoch 81/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0070\n",
      "Epoch 82/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0066\n",
      "Epoch 83/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0078\n",
      "Epoch 84/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0069\n",
      "Epoch 85/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0073\n",
      "Epoch 86/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0067\n",
      "Epoch 87/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0066\n",
      "Epoch 88/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0067\n",
      "Epoch 89/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0067\n",
      "Epoch 90/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0066\n",
      "Epoch 91/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0075\n",
      "Epoch 92/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0083\n",
      "Epoch 93/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0067\n",
      "Epoch 94/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0066\n",
      "Epoch 95/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0069\n",
      "Epoch 96/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0065\n",
      "Epoch 97/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0073\n",
      "Epoch 98/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0064\n",
      "Epoch 99/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0066\n",
      "Epoch 100/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0068\n",
      "Epoch 101/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0065\n",
      "Epoch 102/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0067\n",
      "Epoch 103/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0070\n",
      "Epoch 104/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0067\n",
      "Epoch 105/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0069\n",
      "Epoch 106/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0065\n",
      "Epoch 107/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0065\n",
      "Epoch 108/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0068\n",
      "Epoch 109/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0071\n",
      "Epoch 110/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0081\n",
      "Epoch 111/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0075\n",
      "Epoch 112/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0077\n",
      "Epoch 113/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0081\n",
      "Epoch 114/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0066\n",
      "Epoch 115/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0068\n",
      "Epoch 116/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0068\n",
      "Epoch 117/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0066\n",
      "Epoch 118/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0069\n",
      "Epoch 119/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0068\n",
      "Epoch 120/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0076\n",
      "Epoch 121/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0065\n",
      "Epoch 122/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0070\n",
      "Epoch 123/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0064\n",
      "Epoch 124/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0068\n",
      "Epoch 125/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0070\n",
      "Epoch 126/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0067\n",
      "Epoch 127/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0065\n",
      "Epoch 128/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0067\n",
      "Epoch 129/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0066\n",
      "Epoch 130/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0076\n",
      "Epoch 131/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0073\n",
      "Epoch 132/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0069\n",
      "Epoch 133/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0077\n",
      "Epoch 134/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0077\n",
      "Epoch 135/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0068\n",
      "Epoch 136/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0069\n",
      "Epoch 137/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0065\n",
      "Epoch 138/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0077\n",
      "Epoch 139/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0067\n",
      "Epoch 140/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0073\n",
      "Epoch 141/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0065\n",
      "Epoch 142/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0065\n",
      "Epoch 143/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0065\n",
      "Epoch 144/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0067\n",
      "Epoch 145/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0068\n",
      "Epoch 146/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0076\n",
      "Epoch 147/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0067\n",
      "Epoch 148/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0084\n",
      "Epoch 149/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0067\n",
      "Epoch 150/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0075\n",
      "Epoch 151/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 152/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0064\n",
      "Epoch 153/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 154/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0068\n",
      "Epoch 155/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 156/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0066\n",
      "Epoch 157/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 158/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0074\n",
      "Epoch 159/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0075\n",
      "Epoch 160/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0070\n",
      "Epoch 161/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0066\n",
      "Epoch 162/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0068\n",
      "Epoch 163/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0065\n",
      "Epoch 164/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0067\n",
      "Epoch 166/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0064\n",
      "Epoch 167/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0066\n",
      "Epoch 168/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0077\n",
      "Epoch 169/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0065\n",
      "Epoch 170/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0068\n",
      "Epoch 171/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0065\n",
      "Epoch 172/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0066\n",
      "Epoch 173/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0065\n",
      "Epoch 174/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0067\n",
      "Epoch 175/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0066\n",
      "Epoch 176/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0066\n",
      "Epoch 177/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0065\n",
      "Epoch 178/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0066\n",
      "Epoch 179/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0072\n",
      "Epoch 180/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0091\n",
      "Epoch 00180: early stopping\n",
      "Epoch 1/10000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3899 - val_loss: 0.0431\n",
      "Epoch 2/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1096 - val_loss: 0.0343\n",
      "Epoch 3/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0839 - val_loss: 0.0240\n",
      "Epoch 4/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.0295\n",
      "Epoch 5/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0612 - val_loss: 0.0191\n",
      "Epoch 6/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.0176\n",
      "Epoch 7/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0463 - val_loss: 0.0156\n",
      "Epoch 8/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.0156\n",
      "Epoch 9/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0373 - val_loss: 0.0161\n",
      "Epoch 10/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0328 - val_loss: 0.0139\n",
      "Epoch 11/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0301 - val_loss: 0.0159\n",
      "Epoch 12/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0285 - val_loss: 0.0139\n",
      "Epoch 13/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.0185\n",
      "Epoch 14/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.0125\n",
      "Epoch 15/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.0114\n",
      "Epoch 16/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0220 - val_loss: 0.0108\n",
      "Epoch 17/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0107\n",
      "Epoch 18/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0100\n",
      "Epoch 19/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0096\n",
      "Epoch 20/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0096\n",
      "Epoch 21/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0096\n",
      "Epoch 22/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0090\n",
      "Epoch 23/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0112\n",
      "Epoch 24/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0087\n",
      "Epoch 25/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0086\n",
      "Epoch 26/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0084\n",
      "Epoch 27/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0081\n",
      "Epoch 28/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0084\n",
      "Epoch 29/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0081\n",
      "Epoch 30/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0086\n",
      "Epoch 31/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0083\n",
      "Epoch 32/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0076\n",
      "Epoch 33/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0073\n",
      "Epoch 34/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0072\n",
      "Epoch 35/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0071\n",
      "Epoch 36/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0070\n",
      "Epoch 37/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0069\n",
      "Epoch 38/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0072\n",
      "Epoch 39/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0074\n",
      "Epoch 40/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0067\n",
      "Epoch 41/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.0065\n",
      "Epoch 42/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0062\n",
      "Epoch 43/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0068\n",
      "Epoch 44/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0062\n",
      "Epoch 45/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0058\n",
      "Epoch 46/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0059\n",
      "Epoch 47/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0057\n",
      "Epoch 48/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0055\n",
      "Epoch 49/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0064\n",
      "Epoch 50/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0057\n",
      "Epoch 51/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0057\n",
      "Epoch 52/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0054\n",
      "Epoch 53/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0059\n",
      "Epoch 54/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0058\n",
      "Epoch 55/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0054\n",
      "Epoch 56/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0052\n",
      "Epoch 57/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 58/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0054\n",
      "Epoch 59/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0059\n",
      "Epoch 60/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0052\n",
      "Epoch 61/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0054\n",
      "Epoch 62/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 63/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0055\n",
      "Epoch 64/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0055\n",
      "Epoch 66/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0074\n",
      "Epoch 67/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0064\n",
      "Epoch 68/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0056\n",
      "Epoch 69/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0057\n",
      "Epoch 70/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0057\n",
      "Epoch 71/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0055\n",
      "Epoch 72/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0061\n",
      "Epoch 73/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0058\n",
      "Epoch 74/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0054\n",
      "Epoch 75/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0055\n",
      "Epoch 76/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0051\n",
      "Epoch 77/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0053\n",
      "Epoch 78/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0053\n",
      "Epoch 79/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0052\n",
      "Epoch 80/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0051\n",
      "Epoch 81/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0056\n",
      "Epoch 82/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0051\n",
      "Epoch 83/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0061\n",
      "Epoch 84/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0068\n",
      "Epoch 85/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0060\n",
      "Epoch 86/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0056\n",
      "Epoch 87/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0055\n",
      "Epoch 88/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0053\n",
      "Epoch 89/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0058\n",
      "Epoch 90/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0054\n",
      "Epoch 91/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0052\n",
      "Epoch 92/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0052\n",
      "Epoch 93/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0054\n",
      "Epoch 94/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0055\n",
      "Epoch 95/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0055\n",
      "Epoch 96/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0058\n",
      "Epoch 97/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0054\n",
      "Epoch 98/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0054\n",
      "Epoch 99/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0054\n",
      "Epoch 100/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0055\n",
      "Epoch 101/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0053\n",
      "Epoch 102/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0052\n",
      "Epoch 103/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0058\n",
      "Epoch 104/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0052\n",
      "Epoch 105/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0054\n",
      "Epoch 106/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0057\n",
      "Epoch 107/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0051\n",
      "Epoch 108/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0052\n",
      "Epoch 109/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0064\n",
      "Epoch 110/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0052\n",
      "Epoch 111/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0058\n",
      "Epoch 112/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0065\n",
      "Epoch 113/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0052\n",
      "Epoch 114/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0053\n",
      "Epoch 115/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0054\n",
      "Epoch 116/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0064\n",
      "Epoch 117/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0054\n",
      "Epoch 118/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0062\n",
      "Epoch 119/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0055\n",
      "Epoch 120/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0053\n",
      "Epoch 121/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0056\n",
      "Epoch 122/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0053\n",
      "Epoch 123/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0051\n",
      "Epoch 124/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0052\n",
      "Epoch 125/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0053\n",
      "Epoch 126/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0057\n",
      "Epoch 127/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0051\n",
      "Epoch 128/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0053\n",
      "Epoch 129/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0084\n",
      "Epoch 130/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0058\n",
      "Epoch 131/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0052\n",
      "Epoch 132/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0052\n",
      "Epoch 133/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0053\n",
      "Epoch 134/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0053\n",
      "Epoch 135/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0050\n",
      "Epoch 136/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0053\n",
      "Epoch 137/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0055\n",
      "Epoch 138/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0054\n",
      "Epoch 139/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0052\n",
      "Epoch 140/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0059\n",
      "Epoch 141/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0055\n",
      "Epoch 142/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0056\n",
      "Epoch 143/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0053\n",
      "Epoch 144/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0087\n",
      "Epoch 146/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0053\n",
      "Epoch 147/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0051\n",
      "Epoch 148/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0053\n",
      "Epoch 149/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0051\n",
      "Epoch 150/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0052\n",
      "Epoch 151/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0052\n",
      "Epoch 152/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0061\n",
      "Epoch 153/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0051\n",
      "Epoch 154/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0053\n",
      "Epoch 155/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0056\n",
      "Epoch 156/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0051\n",
      "Epoch 157/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0050\n",
      "Epoch 158/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0050\n",
      "Epoch 159/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0059\n",
      "Epoch 160/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0052\n",
      "Epoch 161/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0051\n",
      "Epoch 162/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0056\n",
      "Epoch 163/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 164/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0054\n",
      "Epoch 165/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0055\n",
      "Epoch 166/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0054\n",
      "Epoch 167/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0054\n",
      "Epoch 168/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0054\n",
      "Epoch 169/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0061\n",
      "Epoch 170/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0058\n",
      "Epoch 171/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0055\n",
      "Epoch 172/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0060\n",
      "Epoch 173/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0057\n",
      "Epoch 174/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0052\n",
      "Epoch 175/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0051\n",
      "Epoch 176/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0051\n",
      "Epoch 177/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0064\n",
      "Epoch 178/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0052\n",
      "Epoch 179/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0054\n",
      "Epoch 180/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0057\n",
      "Epoch 181/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0052\n",
      "Epoch 182/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0053\n",
      "Epoch 183/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0051\n",
      "Epoch 184/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0051\n",
      "Epoch 185/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0053\n",
      "Epoch 186/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0051\n",
      "Epoch 187/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0060\n",
      "Epoch 188/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0051\n",
      "Epoch 189/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0066\n",
      "Epoch 190/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0052\n",
      "Epoch 191/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 192/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0056\n",
      "Epoch 193/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0051\n",
      "Epoch 194/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 195/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0055\n",
      "Epoch 196/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 197/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0055\n",
      "Epoch 198/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 199/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0052\n",
      "Epoch 200/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0060\n",
      "Epoch 201/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0060\n",
      "Epoch 202/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0073\n",
      "Epoch 203/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0057\n",
      "Epoch 204/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 205/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0052\n",
      "Epoch 206/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0056\n",
      "Epoch 207/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 208/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 209/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 210/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 211/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 212/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0052\n",
      "Epoch 213/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 214/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0054\n",
      "Epoch 215/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0059\n",
      "Epoch 216/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0057\n",
      "Epoch 217/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0051\n",
      "Epoch 218/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 219/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 220/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0052\n",
      "Epoch 221/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0063\n",
      "Epoch 222/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0057\n",
      "Epoch 223/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0059\n",
      "Epoch 224/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0063\n",
      "Epoch 225/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0052\n",
      "Epoch 226/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0055\n",
      "Epoch 227/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0055\n",
      "Epoch 228/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0055\n",
      "Epoch 229/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 230/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0057\n",
      "Epoch 231/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0053\n",
      "Epoch 232/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0064\n",
      "Epoch 233/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0073\n",
      "Epoch 234/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0072\n",
      "Epoch 235/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0062\n",
      "Epoch 236/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0052\n",
      "Epoch 237/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 238/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 239/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 240/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 241/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 242/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 243/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0051\n",
      "Epoch 244/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0049\n",
      "Epoch 245/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 246/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0059\n",
      "Epoch 247/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0055\n",
      "Epoch 248/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0059\n",
      "Epoch 249/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0051\n",
      "Epoch 250/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0051\n",
      "Epoch 251/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0053\n",
      "Epoch 252/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 253/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0050\n",
      "Epoch 254/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0055\n",
      "Epoch 255/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0061\n",
      "Epoch 256/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0054\n",
      "Epoch 257/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0053\n",
      "Epoch 258/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 259/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 260/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0049\n",
      "Epoch 261/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0051\n",
      "Epoch 262/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0051\n",
      "Epoch 263/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 264/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 265/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 266/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0060\n",
      "Epoch 267/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0055\n",
      "Epoch 268/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0055\n",
      "Epoch 269/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0056\n",
      "Epoch 270/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0057\n",
      "Epoch 271/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0050\n",
      "Epoch 272/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 273/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 274/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 275/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 276/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0050\n",
      "Epoch 277/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0053\n",
      "Epoch 278/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0059\n",
      "Epoch 279/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 280/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0051\n",
      "Epoch 281/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 282/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 283/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 284/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 285/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 286/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 287/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 288/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 289/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0053\n",
      "Epoch 290/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 291/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 292/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 293/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0061\n",
      "Epoch 294/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0050\n",
      "Epoch 295/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 296/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 297/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 298/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 299/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 300/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0050\n",
      "Epoch 301/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 302/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0074\n",
      "Epoch 303/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0050\n",
      "Epoch 304/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 305/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 306/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 307/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 308/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 309/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 310/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0050\n",
      "Epoch 311/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 312/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0064\n",
      "Epoch 313/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0056\n",
      "Epoch 314/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 315/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 316/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 317/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0050\n",
      "Epoch 318/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 319/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 320/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 321/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0049\n",
      "Epoch 322/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0061\n",
      "Epoch 323/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 324/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 325/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 326/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0063\n",
      "Epoch 327/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 328/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 329/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 330/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 331/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 332/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 333/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 334/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 335/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 336/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 337/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0072\n",
      "Epoch 338/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0065\n",
      "Epoch 339/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 340/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 341/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 342/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0050\n",
      "Epoch 343/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 344/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 345/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 346/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0053\n",
      "Epoch 347/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 348/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0057\n",
      "Epoch 349/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0057\n",
      "Epoch 350/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0050\n",
      "Epoch 351/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 352/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 353/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 354/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0050\n",
      "Epoch 355/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 356/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 357/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0054\n",
      "Epoch 358/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 359/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 360/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 361/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 362/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 363/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 364/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 365/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 366/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0056\n",
      "Epoch 367/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0061\n",
      "Epoch 368/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0052\n",
      "Epoch 369/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 370/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 371/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 372/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0061\n",
      "Epoch 373/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 374/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 375/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 376/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 377/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 378/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 379/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 380/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0050\n",
      "Epoch 381/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 382/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 383/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 384/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 385/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0062\n",
      "Epoch 386/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0053\n",
      "Epoch 387/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0048\n",
      "Epoch 388/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 389/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 390/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 391/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 392/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 393/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 394/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 395/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 396/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 397/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 398/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 399/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 400/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0057\n",
      "Epoch 401/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 402/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 403/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0056\n",
      "Epoch 404/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 405/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 406/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 407/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 408/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 409/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0061\n",
      "Epoch 410/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 411/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 412/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 413/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0062\n",
      "Epoch 414/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 415/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 416/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 417/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 418/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 419/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 420/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 421/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0060\n",
      "Epoch 422/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0063\n",
      "Epoch 423/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 424/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 425/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 426/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 427/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 428/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 429/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 430/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0052\n",
      "Epoch 431/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 432/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 433/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 434/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 435/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 436/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 437/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 438/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 439/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0057\n",
      "Epoch 440/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 441/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 442/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 443/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 444/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 445/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 446/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 447/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0057\n",
      "Epoch 448/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 449/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 450/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 451/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 452/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 453/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 454/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 455/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 456/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 457/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 458/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 459/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 460/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0063\n",
      "Epoch 461/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0050\n",
      "Epoch 462/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 463/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 464/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 465/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 466/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 467/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 468/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 469/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 470/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 471/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 472/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 473/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 474/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 475/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 476/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 477/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 478/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0058\n",
      "Epoch 479/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 480/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 481/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 482/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 483/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0063\n",
      "Epoch 484/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 485/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 486/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 487/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 488/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 489/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 490/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 491/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 492/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0056\n",
      "Epoch 493/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0058\n",
      "Epoch 494/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 495/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 496/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 497/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 498/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 499/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 500/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 501/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 502/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 503/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 504/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 00504: early stopping\n",
      "Epoch 1/10000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3661 - val_loss: 0.0406\n",
      "Epoch 2/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1048 - val_loss: 0.0299\n",
      "Epoch 3/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0795 - val_loss: 0.0272\n",
      "Epoch 4/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0642 - val_loss: 0.0226\n",
      "Epoch 5/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0555 - val_loss: 0.0227\n",
      "Epoch 6/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0254\n",
      "Epoch 7/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0441 - val_loss: 0.0159\n",
      "Epoch 8/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0391 - val_loss: 0.0166\n",
      "Epoch 9/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0346 - val_loss: 0.0144\n",
      "Epoch 10/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0324 - val_loss: 0.0142\n",
      "Epoch 11/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0290 - val_loss: 0.0131\n",
      "Epoch 12/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.0158\n",
      "Epoch 13/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.0120\n",
      "Epoch 14/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0236 - val_loss: 0.0120\n",
      "Epoch 15/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.0110\n",
      "Epoch 16/10000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.020 - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0103\n",
      "Epoch 17/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0109\n",
      "Epoch 18/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0101\n",
      "Epoch 19/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0096\n",
      "Epoch 20/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0089\n",
      "Epoch 21/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0088\n",
      "Epoch 22/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0084\n",
      "Epoch 23/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0084\n",
      "Epoch 24/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0084\n",
      "Epoch 25/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0083\n",
      "Epoch 26/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0082\n",
      "Epoch 27/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0079\n",
      "Epoch 28/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0083\n",
      "Epoch 29/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0076\n",
      "Epoch 30/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0076\n",
      "Epoch 31/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0072\n",
      "Epoch 32/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0072\n",
      "Epoch 33/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0071\n",
      "Epoch 34/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0069\n",
      "Epoch 35/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0089\n",
      "Epoch 36/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0070\n",
      "Epoch 37/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0066\n",
      "Epoch 38/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0084\n",
      "Epoch 39/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0062\n",
      "Epoch 40/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0062\n",
      "Epoch 41/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0062\n",
      "Epoch 42/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0079\n",
      "Epoch 43/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0059\n",
      "Epoch 44/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0070\n",
      "Epoch 45/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0060\n",
      "Epoch 46/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0057\n",
      "Epoch 47/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0055\n",
      "Epoch 48/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0054\n",
      "Epoch 49/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0064\n",
      "Epoch 50/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0053\n",
      "Epoch 51/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0054\n",
      "Epoch 52/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0056\n",
      "Epoch 53/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0060\n",
      "Epoch 54/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0058\n",
      "Epoch 55/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0057\n",
      "Epoch 56/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0053\n",
      "Epoch 57/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0063\n",
      "Epoch 58/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0051\n",
      "Epoch 59/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0057\n",
      "Epoch 60/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0052\n",
      "Epoch 61/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0053\n",
      "Epoch 62/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0052\n",
      "Epoch 63/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0056\n",
      "Epoch 64/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0053\n",
      "Epoch 65/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0055\n",
      "Epoch 66/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0067\n",
      "Epoch 67/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0050\n",
      "Epoch 68/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0062\n",
      "Epoch 69/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0050\n",
      "Epoch 70/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0054\n",
      "Epoch 71/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0058\n",
      "Epoch 72/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0046\n",
      "Epoch 73/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0045\n",
      "Epoch 74/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0046\n",
      "Epoch 75/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0057\n",
      "Epoch 76/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0048\n",
      "Epoch 77/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0056\n",
      "Epoch 78/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0049\n",
      "Epoch 79/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0049\n",
      "Epoch 80/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0048\n",
      "Epoch 81/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0054\n",
      "Epoch 82/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0045\n",
      "Epoch 83/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0069\n",
      "Epoch 84/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0051\n",
      "Epoch 85/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0054\n",
      "Epoch 86/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0048\n",
      "Epoch 87/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0049\n",
      "Epoch 88/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0047\n",
      "Epoch 89/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0045\n",
      "Epoch 90/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0052\n",
      "Epoch 91/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0046\n",
      "Epoch 92/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0044\n",
      "Epoch 93/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0047\n",
      "Epoch 94/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0047\n",
      "Epoch 95/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0045\n",
      "Epoch 96/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0044\n",
      "Epoch 97/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0050\n",
      "Epoch 98/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0081\n",
      "Epoch 99/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0051\n",
      "Epoch 100/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0044\n",
      "Epoch 101/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0044\n",
      "Epoch 102/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0052\n",
      "Epoch 103/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0048\n",
      "Epoch 104/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0044\n",
      "Epoch 105/10000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.011 - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0045\n",
      "Epoch 106/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0043\n",
      "Epoch 107/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0042\n",
      "Epoch 108/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0046\n",
      "Epoch 109/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0057\n",
      "Epoch 110/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0063\n",
      "Epoch 111/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0048\n",
      "Epoch 112/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0044\n",
      "Epoch 113/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0061\n",
      "Epoch 114/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0054\n",
      "Epoch 115/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0045\n",
      "Epoch 116/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0069\n",
      "Epoch 117/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0049\n",
      "Epoch 118/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0048\n",
      "Epoch 119/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0046\n",
      "Epoch 120/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0047\n",
      "Epoch 121/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0046\n",
      "Epoch 122/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0045\n",
      "Epoch 123/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0051\n",
      "Epoch 124/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0044\n",
      "Epoch 125/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0045\n",
      "Epoch 126/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0052\n",
      "Epoch 127/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0045\n",
      "Epoch 128/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0043\n",
      "Epoch 129/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 130/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0044\n",
      "Epoch 131/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0044\n",
      "Epoch 132/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0050\n",
      "Epoch 133/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0047\n",
      "Epoch 134/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0053\n",
      "Epoch 135/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0047\n",
      "Epoch 136/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0047\n",
      "Epoch 137/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0048\n",
      "Epoch 138/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 139/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0047\n",
      "Epoch 140/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0049\n",
      "Epoch 141/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0047\n",
      "Epoch 142/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0046\n",
      "Epoch 143/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0043\n",
      "Epoch 144/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0047\n",
      "Epoch 145/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0043\n",
      "Epoch 146/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0047\n",
      "Epoch 147/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0051\n",
      "Epoch 148/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0044\n",
      "Epoch 149/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0044\n",
      "Epoch 150/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0042\n",
      "Epoch 151/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0048\n",
      "Epoch 152/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0046\n",
      "Epoch 153/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0045\n",
      "Epoch 154/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0048\n",
      "Epoch 155/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0043\n",
      "Epoch 156/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0043\n",
      "Epoch 157/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0045\n",
      "Epoch 158/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 159/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0048\n",
      "Epoch 160/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0047\n",
      "Epoch 161/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0047\n",
      "Epoch 162/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0042\n",
      "Epoch 163/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0043\n",
      "Epoch 164/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 165/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0042\n",
      "Epoch 166/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0043\n",
      "Epoch 167/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 168/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0046\n",
      "Epoch 169/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0043\n",
      "Epoch 170/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0049\n",
      "Epoch 171/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0042\n",
      "Epoch 172/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0044\n",
      "Epoch 173/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 174/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0047\n",
      "Epoch 175/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 176/10000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0045\n",
      "Epoch 177/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 178/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0045\n",
      "Epoch 179/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 180/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 181/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0043\n",
      "Epoch 182/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 183/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 184/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0044\n",
      "Epoch 185/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 186/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 187/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 188/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 189/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 190/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0042\n",
      "Epoch 191/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 192/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 193/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 194/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 195/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 196/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 197/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0053\n",
      "Epoch 198/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 199/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 200/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 201/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 202/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 203/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 204/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0062\n",
      "Epoch 205/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 206/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 207/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 208/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0068\n",
      "Epoch 209/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0060\n",
      "Epoch 210/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0046\n",
      "Epoch 211/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 212/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 213/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 214/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 215/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 216/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 217/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 218/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 219/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 220/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 221/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 222/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 223/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 224/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 225/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0063\n",
      "Epoch 226/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 227/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 228/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 229/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 230/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 231/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 232/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 233/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 234/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 235/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 236/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 237/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 238/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 239/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 240/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0057\n",
      "Epoch 241/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 242/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 243/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 244/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 245/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 246/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 247/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 248/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 249/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 250/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 251/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0062\n",
      "Epoch 252/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 253/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 254/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 255/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 256/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 257/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 258/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 259/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 260/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 261/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 262/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 263/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 264/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 265/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 266/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 267/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 268/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 269/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0050\n",
      "Epoch 270/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 271/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 272/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 273/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 274/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 275/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 276/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 277/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 278/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 279/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 280/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 281/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 282/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0061\n",
      "Epoch 283/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 284/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 285/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 286/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 287/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 288/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 289/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 290/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 291/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 292/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 293/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 294/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0061\n",
      "Epoch 295/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 296/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 297/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 298/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 299/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 300/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 301/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 302/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 303/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0058\n",
      "Epoch 304/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 305/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 306/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 307/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 308/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 309/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 310/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 311/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 312/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 313/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 314/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 315/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 316/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 317/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 318/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 319/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 320/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 321/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0065\n",
      "Epoch 322/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 323/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 324/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0067\n",
      "Epoch 325/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 326/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 327/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 328/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 329/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 330/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 331/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 332/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 333/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 334/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 335/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 336/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 337/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 338/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 339/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 340/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 341/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 342/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 343/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 344/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 345/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 346/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 347/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 348/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 349/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0060\n",
      "Epoch 350/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 351/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 352/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 353/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 354/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 355/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 356/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 357/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 358/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 359/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 360/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 361/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 362/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 363/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 364/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 365/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 366/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 367/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 368/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 369/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0041\n",
      "Epoch 370/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 371/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 372/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 373/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 374/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 375/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 376/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 377/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 378/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 379/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 380/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 381/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 382/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 383/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 384/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 385/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 386/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 387/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 388/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 389/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 390/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 391/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 392/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 393/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 394/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 395/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 396/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 397/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 398/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 399/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 400/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 401/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 402/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 403/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 404/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 405/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 406/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 407/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 408/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 409/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 410/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 411/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 412/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 413/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 414/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 415/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0059\n",
      "Epoch 416/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 417/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 418/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 419/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 420/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 421/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 422/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0060\n",
      "Epoch 423/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0074\n",
      "Epoch 424/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0064\n",
      "Epoch 425/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 426/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 427/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 428/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 429/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 430/10000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.003 - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 431/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 432/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 433/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 434/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 435/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 436/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 437/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 438/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 439/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 440/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 441/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 442/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 443/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 444/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0065\n",
      "Epoch 445/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 446/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 447/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 448/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 449/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 450/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 451/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 452/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 453/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 454/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 455/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 456/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 457/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 458/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 459/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 460/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 461/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 462/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 463/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0057\n",
      "Epoch 464/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 465/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 466/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 467/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 468/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 469/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 470/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 471/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 472/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 473/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 474/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 475/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 476/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 477/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 478/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 479/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 480/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 481/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0060\n",
      "Epoch 482/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 483/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 484/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 485/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 486/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 487/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 488/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 489/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 490/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 491/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 492/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 493/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0063\n",
      "Epoch 494/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 495/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 496/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 497/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 498/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 499/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 500/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 501/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 502/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 503/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 504/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0059\n",
      "Epoch 505/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 506/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 507/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 508/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 509/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 510/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 511/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 512/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 513/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 514/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 515/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 516/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 517/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 518/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 519/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 520/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 521/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 522/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 523/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 524/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 525/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 526/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 527/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 528/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 529/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 530/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0050\n",
      "Epoch 531/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 532/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 533/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 534/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 535/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 536/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 537/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0060\n",
      "Epoch 538/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 539/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 540/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 541/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 542/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 543/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 544/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 545/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 546/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 547/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 548/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 549/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 550/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 551/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 552/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 553/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 554/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 555/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 556/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 557/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 558/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 559/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 560/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 561/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 562/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0060\n",
      "Epoch 563/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 564/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 565/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 566/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 567/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 568/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 569/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 570/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 571/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 572/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 573/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 574/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 575/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 576/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 577/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 578/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 579/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 580/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 581/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 582/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 583/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 584/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 585/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 586/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 587/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0063\n",
      "Epoch 588/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 589/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 590/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 591/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 592/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 593/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 594/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 595/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 596/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 597/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 598/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 599/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 600/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 601/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 602/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 603/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 604/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 605/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 606/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 607/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 608/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 609/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 610/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 611/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0057\n",
      "Epoch 612/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 613/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 614/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 615/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 616/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 617/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 618/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 619/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 620/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 621/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 622/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 623/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 624/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 625/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 626/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 627/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 628/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 629/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 630/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 631/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 632/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 633/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 634/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 635/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 636/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 637/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 638/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 639/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 640/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 641/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 642/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 643/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 644/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 645/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 646/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 647/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 648/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 649/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 650/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 651/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 652/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 653/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 654/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 655/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 656/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 657/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 658/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 659/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 660/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 661/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 662/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 663/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 664/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 665/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 666/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 667/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0065\n",
      "Epoch 668/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0048\n",
      "Epoch 669/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 670/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 671/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 672/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 673/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 674/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 675/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 676/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 677/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 678/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 679/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 680/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 681/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 682/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 683/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 684/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 685/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 686/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 687/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 688/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 689/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 690/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 691/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 692/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 693/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 694/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 695/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 696/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 697/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 698/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 699/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 700/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 701/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 702/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 703/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 704/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 705/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 706/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0061\n",
      "Epoch 707/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 708/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 709/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 710/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 711/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 712/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 713/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 714/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 715/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 716/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 717/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 718/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 719/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 720/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 721/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 722/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 723/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 724/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 725/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 726/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 727/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 728/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 729/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 730/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 00730: early stopping\n",
      "Epoch 1/10000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3525 - val_loss: 0.0413\n",
      "Epoch 2/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0906 - val_loss: 0.0399\n",
      "Epoch 3/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0722 - val_loss: 0.0338\n",
      "Epoch 4/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0610 - val_loss: 0.0384\n",
      "Epoch 5/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0555 - val_loss: 0.0337\n",
      "Epoch 6/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0512 - val_loss: 0.0343\n",
      "Epoch 7/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0447 - val_loss: 0.0296\n",
      "Epoch 8/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0391 - val_loss: 0.0255\n",
      "Epoch 9/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0298 - val_loss: 0.0162\n",
      "Epoch 10/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0254 - val_loss: 0.0156\n",
      "Epoch 11/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0244 - val_loss: 0.0153\n",
      "Epoch 12/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0239 - val_loss: 0.0161\n",
      "Epoch 13/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.0151\n",
      "Epoch 14/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0226 - val_loss: 0.0157\n",
      "Epoch 15/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.0152\n",
      "Epoch 16/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0215 - val_loss: 0.0149\n",
      "Epoch 17/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.0152\n",
      "Epoch 18/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0151\n",
      "Epoch 19/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0154\n",
      "Epoch 20/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0154\n",
      "Epoch 21/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0149\n",
      "Epoch 22/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0156\n",
      "Epoch 23/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0150\n",
      "Epoch 24/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0149\n",
      "Epoch 25/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0151\n",
      "Epoch 26/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0149\n",
      "Epoch 27/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0149\n",
      "Epoch 28/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0152\n",
      "Epoch 29/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0161\n",
      "Epoch 30/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0152\n",
      "Epoch 31/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0153\n",
      "Epoch 32/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0150\n",
      "Epoch 33/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0149\n",
      "Epoch 34/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0152\n",
      "Epoch 35/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0150\n",
      "Epoch 36/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0148\n",
      "Epoch 37/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0151\n",
      "Epoch 38/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0150\n",
      "Epoch 39/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0153\n",
      "Epoch 40/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0152\n",
      "Epoch 41/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0153\n",
      "Epoch 42/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0149\n",
      "Epoch 43/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0149\n",
      "Epoch 44/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0151\n",
      "Epoch 45/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0163\n",
      "Epoch 46/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0150\n",
      "Epoch 47/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0149\n",
      "Epoch 48/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0154\n",
      "Epoch 49/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0152\n",
      "Epoch 50/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0154\n",
      "Epoch 51/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0156\n",
      "Epoch 52/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0148\n",
      "Epoch 53/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0151\n",
      "Epoch 54/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0149\n",
      "Epoch 55/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0151\n",
      "Epoch 56/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0148\n",
      "Epoch 57/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0163\n",
      "Epoch 58/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0153\n",
      "Epoch 59/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0148\n",
      "Epoch 60/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0148\n",
      "Epoch 61/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0147\n",
      "Epoch 62/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0158\n",
      "Epoch 63/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0151\n",
      "Epoch 64/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0151\n",
      "Epoch 65/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0150\n",
      "Epoch 66/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0147\n",
      "Epoch 67/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0148\n",
      "Epoch 68/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0149\n",
      "Epoch 69/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0149\n",
      "Epoch 70/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0156\n",
      "Epoch 71/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0147\n",
      "Epoch 72/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0150\n",
      "Epoch 73/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0148\n",
      "Epoch 74/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0148\n",
      "Epoch 75/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0153\n",
      "Epoch 76/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0148\n",
      "Epoch 77/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0148\n",
      "Epoch 78/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0147\n",
      "Epoch 79/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0153\n",
      "Epoch 80/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0150\n",
      "Epoch 81/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0148\n",
      "Epoch 82/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0150\n",
      "Epoch 83/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0147\n",
      "Epoch 84/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0150\n",
      "Epoch 85/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0150\n",
      "Epoch 86/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0148\n",
      "Epoch 87/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0154\n",
      "Epoch 88/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0156\n",
      "Epoch 89/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0149\n",
      "Epoch 90/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0148\n",
      "Epoch 91/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0147\n",
      "Epoch 92/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0148\n",
      "Epoch 93/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0147\n",
      "Epoch 94/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0151\n",
      "Epoch 95/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0148\n",
      "Epoch 96/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0152\n",
      "Epoch 97/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0148\n",
      "Epoch 98/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0148\n",
      "Epoch 99/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0149\n",
      "Epoch 100/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0159\n",
      "Epoch 101/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0150\n",
      "Epoch 102/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0148\n",
      "Epoch 103/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0147\n",
      "Epoch 104/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0149\n",
      "Epoch 105/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0152\n",
      "Epoch 106/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0148\n",
      "Epoch 107/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0148\n",
      "Epoch 108/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0150\n",
      "Epoch 109/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0148\n",
      "Epoch 110/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0153\n",
      "Epoch 111/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0149\n",
      "Epoch 112/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0170\n",
      "Epoch 113/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0150\n",
      "Epoch 114/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0150\n",
      "Epoch 115/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0148\n",
      "Epoch 116/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0147\n",
      "Epoch 117/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0148\n",
      "Epoch 118/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0151\n",
      "Epoch 119/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0151\n",
      "Epoch 120/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0153\n",
      "Epoch 121/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0149\n",
      "Epoch 122/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0148\n",
      "Epoch 123/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0157\n",
      "Epoch 124/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0150\n",
      "Epoch 125/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0147\n",
      "Epoch 126/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0149\n",
      "Epoch 127/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0149\n",
      "Epoch 128/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0148\n",
      "Epoch 129/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0147\n",
      "Epoch 130/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0159\n",
      "Epoch 131/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0147\n",
      "Epoch 132/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0148\n",
      "Epoch 133/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0157\n",
      "Epoch 134/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0148\n",
      "Epoch 135/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0148\n",
      "Epoch 136/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0153\n",
      "Epoch 137/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0155\n",
      "Epoch 138/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0150\n",
      "Epoch 139/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0159\n",
      "Epoch 140/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0148\n",
      "Epoch 141/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0150\n",
      "Epoch 142/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0150\n",
      "Epoch 143/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0148\n",
      "Epoch 144/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0150\n",
      "Epoch 145/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0154\n",
      "Epoch 146/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0149\n",
      "Epoch 147/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0152\n",
      "Epoch 148/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0150\n",
      "Epoch 149/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0147\n",
      "Epoch 150/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0148\n",
      "Epoch 151/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0148\n",
      "Epoch 152/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0157\n",
      "Epoch 153/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0156\n",
      "Epoch 154/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0150\n",
      "Epoch 155/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0148\n",
      "Epoch 156/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0160\n",
      "Epoch 157/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0149\n",
      "Epoch 158/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0180\n",
      "Epoch 159/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0151\n",
      "Epoch 160/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0152\n",
      "Epoch 161/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0150\n",
      "Epoch 162/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0151\n",
      "Epoch 163/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0149\n",
      "Epoch 164/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0148\n",
      "Epoch 165/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0149\n",
      "Epoch 166/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 167/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0160\n",
      "Epoch 168/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0161\n",
      "Epoch 169/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0149\n",
      "Epoch 170/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0149\n",
      "Epoch 171/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0149\n",
      "Epoch 172/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0149\n",
      "Epoch 173/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0150\n",
      "Epoch 174/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0148\n",
      "Epoch 175/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0148\n",
      "Epoch 176/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0148\n",
      "Epoch 177/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0150\n",
      "Epoch 178/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0148\n",
      "Epoch 179/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0151\n",
      "Epoch 180/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 181/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0152\n",
      "Epoch 182/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 183/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0157\n",
      "Epoch 184/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0157\n",
      "Epoch 185/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0153\n",
      "Epoch 186/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0148\n",
      "Epoch 187/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0148\n",
      "Epoch 188/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0150\n",
      "Epoch 189/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0148\n",
      "Epoch 190/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0162\n",
      "Epoch 191/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0148\n",
      "Epoch 192/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0150\n",
      "Epoch 193/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0148\n",
      "Epoch 194/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0149\n",
      "Epoch 195/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0148\n",
      "Epoch 196/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 197/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0150\n",
      "Epoch 198/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 199/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0155\n",
      "Epoch 200/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 201/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0151\n",
      "Epoch 202/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0182\n",
      "Epoch 203/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0183\n",
      "Epoch 204/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0150\n",
      "Epoch 205/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0150\n",
      "Epoch 206/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0155\n",
      "Epoch 207/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0149\n",
      "Epoch 208/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0156\n",
      "Epoch 209/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0149\n",
      "Epoch 210/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 211/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0150\n",
      "Epoch 212/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0153\n",
      "Epoch 213/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0149\n",
      "Epoch 214/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0148\n",
      "Epoch 215/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 216/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 217/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0173\n",
      "Epoch 218/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0149\n",
      "Epoch 219/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0151\n",
      "Epoch 220/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0151\n",
      "Epoch 221/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 222/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0149\n",
      "Epoch 223/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0149\n",
      "Epoch 224/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0148\n",
      "Epoch 225/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0150\n",
      "Epoch 226/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0151\n",
      "Epoch 227/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0154\n",
      "Epoch 228/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0149\n",
      "Epoch 229/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0148\n",
      "Epoch 00229: early stopping\n",
      "Epoch 1/10000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3791 - val_loss: 0.0446\n",
      "Epoch 2/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0937 - val_loss: 0.0325\n",
      "Epoch 3/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0711 - val_loss: 0.0301\n",
      "Epoch 4/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0569 - val_loss: 0.0171\n",
      "Epoch 5/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0460 - val_loss: 0.0182\n",
      "Epoch 6/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0196\n",
      "Epoch 7/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0355 - val_loss: 0.0162\n",
      "Epoch 8/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0308 - val_loss: 0.0178\n",
      "Epoch 9/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0288 - val_loss: 0.0152\n",
      "Epoch 10/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.0151\n",
      "Epoch 11/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0251 - val_loss: 0.0149\n",
      "Epoch 12/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.0149\n",
      "Epoch 13/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.0148\n",
      "Epoch 14/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.0146\n",
      "Epoch 15/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.0144\n",
      "Epoch 16/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.0142\n",
      "Epoch 17/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0135\n",
      "Epoch 18/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0131\n",
      "Epoch 19/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0126\n",
      "Epoch 20/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0127\n",
      "Epoch 21/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0143\n",
      "Epoch 22/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0125\n",
      "Epoch 23/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0124\n",
      "Epoch 24/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0120\n",
      "Epoch 25/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0123\n",
      "Epoch 26/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0123\n",
      "Epoch 27/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0128\n",
      "Epoch 29/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0126\n",
      "Epoch 30/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0119\n",
      "Epoch 31/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0122\n",
      "Epoch 32/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0125\n",
      "Epoch 33/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0122\n",
      "Epoch 34/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0120\n",
      "Epoch 35/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0119\n",
      "Epoch 36/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0119\n",
      "Epoch 37/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0120\n",
      "Epoch 38/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0120\n",
      "Epoch 39/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0126\n",
      "Epoch 40/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0119\n",
      "Epoch 41/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0139\n",
      "Epoch 42/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0119\n",
      "Epoch 43/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0128\n",
      "Epoch 44/10000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.012 - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0119\n",
      "Epoch 45/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0129\n",
      "Epoch 46/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0120\n",
      "Epoch 47/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0122\n",
      "Epoch 48/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0124\n",
      "Epoch 49/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0119\n",
      "Epoch 50/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0119\n",
      "Epoch 51/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0127\n",
      "Epoch 52/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0120\n",
      "Epoch 53/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0117\n",
      "Epoch 54/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0119\n",
      "Epoch 55/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0122\n",
      "Epoch 56/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0120\n",
      "Epoch 57/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0119\n",
      "Epoch 58/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0117\n",
      "Epoch 59/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0119\n",
      "Epoch 60/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0119\n",
      "Epoch 61/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0118\n",
      "Epoch 62/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0118\n",
      "Epoch 63/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0119\n",
      "Epoch 64/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0117\n",
      "Epoch 65/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0119\n",
      "Epoch 66/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0118\n",
      "Epoch 67/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0120\n",
      "Epoch 68/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0119\n",
      "Epoch 69/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0116\n",
      "Epoch 70/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0121\n",
      "Epoch 71/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0120\n",
      "Epoch 72/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0116\n",
      "Epoch 73/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0117\n",
      "Epoch 74/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0129\n",
      "Epoch 75/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0118\n",
      "Epoch 76/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0120\n",
      "Epoch 77/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0119\n",
      "Epoch 78/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0116\n",
      "Epoch 79/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0125\n",
      "Epoch 80/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0116\n",
      "Epoch 81/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0116\n",
      "Epoch 82/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0118\n",
      "Epoch 83/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0116\n",
      "Epoch 84/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0118\n",
      "Epoch 85/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0120\n",
      "Epoch 86/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0136\n",
      "Epoch 87/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0120\n",
      "Epoch 88/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0118\n",
      "Epoch 89/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0130\n",
      "Epoch 90/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0126\n",
      "Epoch 91/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0118\n",
      "Epoch 92/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0117\n",
      "Epoch 93/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0116\n",
      "Epoch 94/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0117\n",
      "Epoch 95/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0118\n",
      "Epoch 96/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0117\n",
      "Epoch 97/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0116\n",
      "Epoch 98/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0117\n",
      "Epoch 99/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0120\n",
      "Epoch 100/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0119\n",
      "Epoch 101/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0115\n",
      "Epoch 102/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0115\n",
      "Epoch 103/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0115\n",
      "Epoch 104/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0141\n",
      "Epoch 105/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0117\n",
      "Epoch 106/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0121\n",
      "Epoch 107/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0118\n",
      "Epoch 108/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0120\n",
      "Epoch 109/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0117\n",
      "Epoch 110/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0117\n",
      "Epoch 111/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0118\n",
      "Epoch 112/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0116\n",
      "Epoch 113/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0117\n",
      "Epoch 114/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0116\n",
      "Epoch 115/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0117\n",
      "Epoch 116/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0127\n",
      "Epoch 117/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0125\n",
      "Epoch 118/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0124\n",
      "Epoch 119/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0120\n",
      "Epoch 120/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0115\n",
      "Epoch 121/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0116\n",
      "Epoch 122/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0123\n",
      "Epoch 123/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0118\n",
      "Epoch 124/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0116\n",
      "Epoch 125/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0117\n",
      "Epoch 126/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0118\n",
      "Epoch 127/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0116\n",
      "Epoch 128/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0116\n",
      "Epoch 129/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0117\n",
      "Epoch 130/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0116\n",
      "Epoch 131/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0115\n",
      "Epoch 132/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0119\n",
      "Epoch 133/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0116\n",
      "Epoch 134/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0120\n",
      "Epoch 135/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0118\n",
      "Epoch 136/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0118\n",
      "Epoch 137/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0122\n",
      "Epoch 138/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0118\n",
      "Epoch 139/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0116\n",
      "Epoch 140/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0117\n",
      "Epoch 141/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0121\n",
      "Epoch 142/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 143/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0115\n",
      "Epoch 144/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0160\n",
      "Epoch 145/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0134\n",
      "Epoch 146/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0132\n",
      "Epoch 147/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0121\n",
      "Epoch 148/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0119\n",
      "Epoch 149/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0117\n",
      "Epoch 150/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0121\n",
      "Epoch 151/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0117\n",
      "Epoch 152/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0116\n",
      "Epoch 153/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0116\n",
      "Epoch 154/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0117\n",
      "Epoch 155/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0123\n",
      "Epoch 156/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0122\n",
      "Epoch 157/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0117\n",
      "Epoch 158/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0126\n",
      "Epoch 159/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0125\n",
      "Epoch 160/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 161/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0115\n",
      "Epoch 162/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0122\n",
      "Epoch 163/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0118\n",
      "Epoch 164/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0116\n",
      "Epoch 165/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0116\n",
      "Epoch 166/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0116\n",
      "Epoch 167/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0121\n",
      "Epoch 168/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0115\n",
      "Epoch 169/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0116\n",
      "Epoch 170/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0123\n",
      "Epoch 171/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0123\n",
      "Epoch 172/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0117\n",
      "Epoch 173/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0118\n",
      "Epoch 174/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0116\n",
      "Epoch 175/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0115\n",
      "Epoch 176/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0118\n",
      "Epoch 177/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0124\n",
      "Epoch 178/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0118\n",
      "Epoch 179/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0118\n",
      "Epoch 180/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0117\n",
      "Epoch 181/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0118\n",
      "Epoch 182/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0126\n",
      "Epoch 183/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0119\n",
      "Epoch 184/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0118\n",
      "Epoch 185/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0118\n",
      "Epoch 186/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0155\n",
      "Epoch 187/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0117\n",
      "Epoch 188/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0121\n",
      "Epoch 189/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0144\n",
      "Epoch 190/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0118\n",
      "Epoch 191/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0119\n",
      "Epoch 192/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0116\n",
      "Epoch 193/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0122\n",
      "Epoch 194/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0117\n",
      "Epoch 195/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0116\n",
      "Epoch 196/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0117\n",
      "Epoch 197/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0116\n",
      "Epoch 198/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0117\n",
      "Epoch 199/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0117\n",
      "Epoch 200/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0117\n",
      "Epoch 201/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0121\n",
      "Epoch 202/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0116\n",
      "Epoch 203/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0121\n",
      "Epoch 204/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0117\n",
      "Epoch 205/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0117\n",
      "Epoch 206/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0128\n",
      "Epoch 207/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0124\n",
      "Epoch 208/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0126\n",
      "Epoch 209/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0116\n",
      "Epoch 210/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0121\n",
      "Epoch 211/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0115\n",
      "Epoch 212/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0115\n",
      "Epoch 213/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0125\n",
      "Epoch 214/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0121\n",
      "Epoch 215/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0117\n",
      "Epoch 216/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0133\n",
      "Epoch 217/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0116\n",
      "Epoch 218/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0122\n",
      "Epoch 219/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0117\n",
      "Epoch 220/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0129\n",
      "Epoch 221/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0118\n",
      "Epoch 222/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0118\n",
      "Epoch 223/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0122\n",
      "Epoch 224/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0119\n",
      "Epoch 225/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0117\n",
      "Epoch 226/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0116\n",
      "Epoch 227/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0127\n",
      "Epoch 228/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0125\n",
      "Epoch 229/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0121\n",
      "Epoch 230/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0115\n",
      "Epoch 231/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0115\n",
      "Epoch 232/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0123\n",
      "Epoch 233/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0124\n",
      "Epoch 234/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0116\n",
      "Epoch 235/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0119\n",
      "Epoch 236/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0120\n",
      "Epoch 237/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0120\n",
      "Epoch 238/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0119\n",
      "Epoch 239/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0118\n",
      "Epoch 240/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0116\n",
      "Epoch 241/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0120\n",
      "Epoch 242/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0116\n",
      "Epoch 243/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0118\n",
      "Epoch 244/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0117\n",
      "Epoch 245/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0121\n",
      "Epoch 246/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0117\n",
      "Epoch 247/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0115\n",
      "Epoch 248/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0117\n",
      "Epoch 249/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0122\n",
      "Epoch 250/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0124\n",
      "Epoch 251/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0118\n",
      "Epoch 252/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0115\n",
      "Epoch 253/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0117\n",
      "Epoch 254/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0123\n",
      "Epoch 255/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0122\n",
      "Epoch 256/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0116\n",
      "Epoch 257/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0115\n",
      "Epoch 258/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0115\n",
      "Epoch 259/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0120\n",
      "Epoch 260/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0135\n",
      "Epoch 261/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0121\n",
      "Epoch 262/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0123\n",
      "Epoch 263/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0127\n",
      "Epoch 264/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0118\n",
      "Epoch 265/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0118\n",
      "Epoch 266/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0116\n",
      "Epoch 267/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0123\n",
      "Epoch 268/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0114\n",
      "Epoch 269/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0117\n",
      "Epoch 270/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0115\n",
      "Epoch 271/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0118\n",
      "Epoch 272/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0118\n",
      "Epoch 273/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0116\n",
      "Epoch 274/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0115\n",
      "Epoch 275/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0119\n",
      "Epoch 276/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0120\n",
      "Epoch 277/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0115\n",
      "Epoch 278/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0114\n",
      "Epoch 279/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0119\n",
      "Epoch 280/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0114\n",
      "Epoch 281/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0119\n",
      "Epoch 282/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0114\n",
      "Epoch 283/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0115\n",
      "Epoch 284/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0115\n",
      "Epoch 285/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0122\n",
      "Epoch 286/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0137\n",
      "Epoch 287/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0115\n",
      "Epoch 288/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0118\n",
      "Epoch 289/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0121\n",
      "Epoch 290/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0118\n",
      "Epoch 291/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0115\n",
      "Epoch 292/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0121\n",
      "Epoch 293/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 294/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0119\n",
      "Epoch 295/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0129\n",
      "Epoch 296/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0115\n",
      "Epoch 297/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 298/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0115\n",
      "Epoch 299/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0119\n",
      "Epoch 300/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0119\n",
      "Epoch 301/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0117\n",
      "Epoch 302/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0110\n",
      "Epoch 303/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0112\n",
      "Epoch 304/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0113\n",
      "Epoch 305/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0115\n",
      "Epoch 306/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0113\n",
      "Epoch 307/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0113\n",
      "Epoch 308/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0112\n",
      "Epoch 309/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0118\n",
      "Epoch 310/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0109\n",
      "Epoch 311/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0114\n",
      "Epoch 312/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 313/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0118\n",
      "Epoch 314/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0116\n",
      "Epoch 315/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0112\n",
      "Epoch 316/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0110\n",
      "Epoch 317/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0112\n",
      "Epoch 318/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0112\n",
      "Epoch 319/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 320/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0115\n",
      "Epoch 321/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 322/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0123\n",
      "Epoch 323/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 324/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0116\n",
      "Epoch 325/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 326/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0118\n",
      "Epoch 327/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0115\n",
      "Epoch 328/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0117\n",
      "Epoch 329/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 330/10000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.009 - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0114\n",
      "Epoch 331/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0120\n",
      "Epoch 332/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 333/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0113\n",
      "Epoch 334/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0198\n",
      "Epoch 335/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0128\n",
      "Epoch 336/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0113\n",
      "Epoch 337/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0117\n",
      "Epoch 338/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0113\n",
      "Epoch 339/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 340/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0112\n",
      "Epoch 341/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0110\n",
      "Epoch 342/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0110\n",
      "Epoch 343/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0118\n",
      "Epoch 344/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 345/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0118\n",
      "Epoch 346/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0121\n",
      "Epoch 347/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0111\n",
      "Epoch 348/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 349/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0118\n",
      "Epoch 350/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0113\n",
      "Epoch 351/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0118\n",
      "Epoch 352/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0112\n",
      "Epoch 353/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 354/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0119\n",
      "Epoch 355/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0111\n",
      "Epoch 356/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0114\n",
      "Epoch 357/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 358/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0120\n",
      "Epoch 359/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0113\n",
      "Epoch 360/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 361/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0119\n",
      "Epoch 362/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0112\n",
      "Epoch 363/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 364/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 365/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 366/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 367/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0114\n",
      "Epoch 368/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0117\n",
      "Epoch 369/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0113\n",
      "Epoch 370/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 371/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0110\n",
      "Epoch 372/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 373/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0109\n",
      "Epoch 374/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0116\n",
      "Epoch 375/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0113\n",
      "Epoch 376/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0113\n",
      "Epoch 377/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 378/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0110\n",
      "Epoch 379/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 380/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0109\n",
      "Epoch 381/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0126\n",
      "Epoch 382/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 383/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 384/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0110\n",
      "Epoch 385/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 386/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0110\n",
      "Epoch 387/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 388/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 389/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0123\n",
      "Epoch 390/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0113\n",
      "Epoch 391/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0119\n",
      "Epoch 392/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 393/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0130\n",
      "Epoch 394/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0117\n",
      "Epoch 395/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0110\n",
      "Epoch 396/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0113\n",
      "Epoch 397/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0121\n",
      "Epoch 398/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 399/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0123\n",
      "Epoch 400/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0118\n",
      "Epoch 401/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0120\n",
      "Epoch 402/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0110\n",
      "Epoch 403/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 404/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0110\n",
      "Epoch 405/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0120\n",
      "Epoch 406/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0115\n",
      "Epoch 407/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 408/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 409/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 410/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 411/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0108\n",
      "Epoch 412/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 413/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0109\n",
      "Epoch 414/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0111\n",
      "Epoch 415/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0113\n",
      "Epoch 416/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 417/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0118\n",
      "Epoch 418/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0114\n",
      "Epoch 419/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 420/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0108\n",
      "Epoch 421/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 422/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 423/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 424/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0109\n",
      "Epoch 425/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0109\n",
      "Epoch 426/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0108\n",
      "Epoch 427/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 428/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0112\n",
      "Epoch 429/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0180\n",
      "Epoch 430/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0140\n",
      "Epoch 431/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0113\n",
      "Epoch 432/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0114\n",
      "Epoch 433/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0110\n",
      "Epoch 434/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0109\n",
      "Epoch 435/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0110\n",
      "Epoch 436/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 437/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 438/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 439/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0110\n",
      "Epoch 440/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0121\n",
      "Epoch 441/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0112\n",
      "Epoch 442/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0114\n",
      "Epoch 443/10000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.010 - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0109\n",
      "Epoch 444/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0117\n",
      "Epoch 445/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 446/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 447/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0112\n",
      "Epoch 448/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 449/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 450/10000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.011 - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 451/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0111\n",
      "Epoch 452/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0113\n",
      "Epoch 453/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0108\n",
      "Epoch 454/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0109\n",
      "Epoch 455/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 456/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0108\n",
      "Epoch 457/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0110\n",
      "Epoch 458/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 459/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 460/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0107\n",
      "Epoch 461/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 462/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0113\n",
      "Epoch 463/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 464/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0108\n",
      "Epoch 465/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0124\n",
      "Epoch 466/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0115\n",
      "Epoch 467/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 468/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 469/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0111\n",
      "Epoch 470/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 471/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0109\n",
      "Epoch 472/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 473/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 474/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 475/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 476/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 477/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0108\n",
      "Epoch 478/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 479/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0123\n",
      "Epoch 480/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0114\n",
      "Epoch 481/10000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.010 - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0169\n",
      "Epoch 482/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0124\n",
      "Epoch 483/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0113\n",
      "Epoch 484/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0112\n",
      "Epoch 485/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0111\n",
      "Epoch 486/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0110\n",
      "Epoch 487/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0125\n",
      "Epoch 488/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0107\n",
      "Epoch 489/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0110\n",
      "Epoch 490/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0110\n",
      "Epoch 491/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 492/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 493/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0112\n",
      "Epoch 494/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 495/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 496/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 497/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0108\n",
      "Epoch 498/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0109\n",
      "Epoch 499/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0106\n",
      "Epoch 500/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0107\n",
      "Epoch 501/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0112\n",
      "Epoch 502/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 503/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0110\n",
      "Epoch 504/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0113\n",
      "Epoch 505/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 506/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0117\n",
      "Epoch 507/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 508/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 509/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0111\n",
      "Epoch 510/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0107\n",
      "Epoch 511/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 512/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 513/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0115\n",
      "Epoch 514/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 515/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0106\n",
      "Epoch 516/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0111\n",
      "Epoch 517/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 518/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 519/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 520/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 521/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0117\n",
      "Epoch 522/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 523/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0109\n",
      "Epoch 524/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0108\n",
      "Epoch 525/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0109\n",
      "Epoch 526/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 527/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0108\n",
      "Epoch 528/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 529/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 530/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 531/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0113\n",
      "Epoch 532/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0118\n",
      "Epoch 533/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0106\n",
      "Epoch 534/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 535/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0108\n",
      "Epoch 536/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0113\n",
      "Epoch 537/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 538/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0109\n",
      "Epoch 539/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 540/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0106\n",
      "Epoch 541/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0111\n",
      "Epoch 542/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 543/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 544/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0129\n",
      "Epoch 545/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0109\n",
      "Epoch 546/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 547/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 548/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0111\n",
      "Epoch 549/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 550/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 551/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 552/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 553/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 554/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 555/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 556/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0112\n",
      "Epoch 557/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 558/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0143\n",
      "Epoch 559/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0111\n",
      "Epoch 560/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 561/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0114\n",
      "Epoch 562/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 563/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 564/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 565/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0107\n",
      "Epoch 566/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 567/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0126\n",
      "Epoch 568/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0114\n",
      "Epoch 569/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0119\n",
      "Epoch 570/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0113\n",
      "Epoch 571/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 572/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 573/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 574/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0111\n",
      "Epoch 575/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0107\n",
      "Epoch 576/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 577/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0116\n",
      "Epoch 578/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0110\n",
      "Epoch 579/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 580/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 581/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 582/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 583/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 584/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 585/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 586/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 587/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 588/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0114\n",
      "Epoch 589/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0113\n",
      "Epoch 590/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0115\n",
      "Epoch 591/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 592/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 593/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 594/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 595/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 596/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0107\n",
      "Epoch 597/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 598/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 599/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0111\n",
      "Epoch 600/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 601/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 602/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 603/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 604/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0109\n",
      "Epoch 605/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 606/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 607/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 608/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0107\n",
      "Epoch 609/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 610/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0113\n",
      "Epoch 611/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 612/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 613/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 614/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0119\n",
      "Epoch 615/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0125\n",
      "Epoch 616/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0108\n",
      "Epoch 617/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 618/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 619/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0116\n",
      "Epoch 620/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 621/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 622/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 623/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0107\n",
      "Epoch 624/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 625/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0106\n",
      "Epoch 626/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0114\n",
      "Epoch 627/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0109\n",
      "Epoch 628/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 629/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 630/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 631/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 632/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 633/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0107\n",
      "Epoch 634/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 635/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 636/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0107\n",
      "Epoch 637/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0113\n",
      "Epoch 638/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 639/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 640/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 641/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 642/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 643/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 644/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 645/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0114\n",
      "Epoch 646/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0131\n",
      "Epoch 647/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 648/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 649/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 650/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0120\n",
      "Epoch 651/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 652/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 653/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 654/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 655/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0111\n",
      "Epoch 656/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 657/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 658/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 659/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 660/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 661/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0104\n",
      "Epoch 662/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 663/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0109\n",
      "Epoch 664/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 665/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0109\n",
      "Epoch 666/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 667/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0108\n",
      "Epoch 668/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0109\n",
      "Epoch 669/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 670/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 671/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0124\n",
      "Epoch 672/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0109\n",
      "Epoch 673/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0110\n",
      "Epoch 674/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0118\n",
      "Epoch 675/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 676/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 677/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0107\n",
      "Epoch 678/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 679/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 680/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0109\n",
      "Epoch 681/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 682/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 683/10000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.008 - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 684/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 685/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 686/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 687/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 688/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 689/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0113\n",
      "Epoch 690/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0107\n",
      "Epoch 691/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 692/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 693/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0107\n",
      "Epoch 694/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 695/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0108\n",
      "Epoch 696/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 697/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 698/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0107\n",
      "Epoch 699/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0111\n",
      "Epoch 700/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 701/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0109\n",
      "Epoch 702/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0107\n",
      "Epoch 703/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0108\n",
      "Epoch 704/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 705/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 706/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 707/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0107\n",
      "Epoch 708/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 709/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0114\n",
      "Epoch 710/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 711/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 712/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0109\n",
      "Epoch 713/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 714/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0104\n",
      "Epoch 715/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 716/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 717/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0109\n",
      "Epoch 718/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 719/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 720/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0107\n",
      "Epoch 721/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0109\n",
      "Epoch 722/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 723/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0115\n",
      "Epoch 724/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 725/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0107\n",
      "Epoch 726/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0108\n",
      "Epoch 727/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0120\n",
      "Epoch 728/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0117\n",
      "Epoch 729/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 730/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0103\n",
      "Epoch 731/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0118\n",
      "Epoch 732/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 733/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 734/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 735/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0121\n",
      "Epoch 736/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 737/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 738/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0110\n",
      "Epoch 739/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 740/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 741/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 742/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0103\n",
      "Epoch 743/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0104\n",
      "Epoch 744/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0110\n",
      "Epoch 745/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 746/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0111\n",
      "Epoch 747/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 748/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 749/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0108\n",
      "Epoch 750/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 751/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 752/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0107\n",
      "Epoch 753/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 754/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 755/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 756/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0110\n",
      "Epoch 757/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0119\n",
      "Epoch 758/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 759/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0103\n",
      "Epoch 760/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0108\n",
      "Epoch 761/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 762/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 763/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 764/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0110\n",
      "Epoch 765/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0121\n",
      "Epoch 766/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0103\n",
      "Epoch 767/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 768/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 769/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 770/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 771/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 772/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0109\n",
      "Epoch 773/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0107\n",
      "Epoch 774/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 775/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 776/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0102\n",
      "Epoch 777/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0117\n",
      "Epoch 778/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0112\n",
      "Epoch 779/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 780/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0103\n",
      "Epoch 781/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 782/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 783/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0103\n",
      "Epoch 784/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0106\n",
      "Epoch 785/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0108\n",
      "Epoch 786/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 787/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 788/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 789/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0108\n",
      "Epoch 790/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0125\n",
      "Epoch 791/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0115\n",
      "Epoch 792/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 793/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 794/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 795/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 796/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0107\n",
      "Epoch 797/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0111\n",
      "Epoch 798/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0112\n",
      "Epoch 799/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0112\n",
      "Epoch 800/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 801/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 802/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0107\n",
      "Epoch 803/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 804/10000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.012 - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 805/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 806/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 807/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 808/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0106\n",
      "Epoch 809/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 810/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 811/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0109\n",
      "Epoch 812/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 813/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 814/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 815/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0108\n",
      "Epoch 816/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 817/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 818/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0101\n",
      "Epoch 819/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 820/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 821/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 822/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0115\n",
      "Epoch 823/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0105\n",
      "Epoch 824/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 825/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 826/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0106\n",
      "Epoch 827/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0109\n",
      "Epoch 828/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0108\n",
      "Epoch 829/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 830/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0108\n",
      "Epoch 831/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 832/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0111\n",
      "Epoch 833/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 834/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 835/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 836/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 837/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0107\n",
      "Epoch 838/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0115\n",
      "Epoch 839/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0108\n",
      "Epoch 840/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 841/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0108\n",
      "Epoch 842/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 843/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 844/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0110\n",
      "Epoch 845/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0101\n",
      "Epoch 846/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0109\n",
      "Epoch 847/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 848/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0108\n",
      "Epoch 849/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 850/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 851/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0104\n",
      "Epoch 852/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 853/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 854/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 855/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 856/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0104\n",
      "Epoch 857/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0104\n",
      "Epoch 858/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0106\n",
      "Epoch 859/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 860/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 861/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0103\n",
      "Epoch 862/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0103\n",
      "Epoch 863/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 864/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0120\n",
      "Epoch 865/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0103\n",
      "Epoch 866/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0115\n",
      "Epoch 867/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 868/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 869/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 870/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 871/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 872/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 873/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 874/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0108\n",
      "Epoch 875/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 876/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0107\n",
      "Epoch 877/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 878/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0104\n",
      "Epoch 879/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 880/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 881/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 882/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0114\n",
      "Epoch 883/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 884/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 885/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 886/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 887/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0103\n",
      "Epoch 888/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 889/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0103\n",
      "Epoch 890/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0107\n",
      "Epoch 891/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 892/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 893/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 894/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 895/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0118\n",
      "Epoch 896/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 897/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0111\n",
      "Epoch 898/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0112\n",
      "Epoch 899/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 900/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 901/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 902/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 903/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0104\n",
      "Epoch 904/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 905/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 906/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 907/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 908/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0108\n",
      "Epoch 909/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 910/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 911/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0099\n",
      "Epoch 912/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 913/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0135\n",
      "Epoch 914/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0121\n",
      "Epoch 915/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 916/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 917/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 918/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 919/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0101\n",
      "Epoch 920/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 921/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0107\n",
      "Epoch 922/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 923/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 924/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0111\n",
      "Epoch 925/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0112\n",
      "Epoch 926/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0101\n",
      "Epoch 927/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0100\n",
      "Epoch 928/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 929/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 930/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 931/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 932/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0100\n",
      "Epoch 933/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0101\n",
      "Epoch 934/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0107\n",
      "Epoch 935/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 936/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0116\n",
      "Epoch 937/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 938/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 939/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 940/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 941/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 942/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 943/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 944/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 945/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 946/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 947/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0100\n",
      "Epoch 948/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 949/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0100\n",
      "Epoch 950/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 951/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0107\n",
      "Epoch 952/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 953/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0099\n",
      "Epoch 954/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0100\n",
      "Epoch 955/10000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.007 - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0104\n",
      "Epoch 956/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 957/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0116\n",
      "Epoch 958/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 959/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 960/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0102\n",
      "Epoch 961/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 962/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 963/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 964/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0100\n",
      "Epoch 965/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 966/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 967/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0113\n",
      "Epoch 968/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 969/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0100\n",
      "Epoch 970/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0099\n",
      "Epoch 971/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 972/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0099\n",
      "Epoch 973/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0099\n",
      "Epoch 974/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0102\n",
      "Epoch 975/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0107\n",
      "Epoch 976/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 977/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0109\n",
      "Epoch 978/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0100\n",
      "Epoch 979/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 980/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 981/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0108\n",
      "Epoch 982/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0116\n",
      "Epoch 983/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 984/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0103\n",
      "Epoch 985/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 986/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 987/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0122\n",
      "Epoch 988/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 989/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0118\n",
      "Epoch 990/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0110\n",
      "Epoch 991/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0115\n",
      "Epoch 992/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 993/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0101\n",
      "Epoch 994/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 995/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 996/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 997/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 998/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 999/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0135\n",
      "Epoch 1000/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 1001/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0100\n",
      "Epoch 1002/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0098\n",
      "Epoch 1003/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0126\n",
      "Epoch 1004/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 1005/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0104\n",
      "Epoch 1006/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0106\n",
      "Epoch 1007/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 1008/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 1009/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 1010/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 1011/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 1012/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 1013/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 1014/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0109\n",
      "Epoch 1015/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 1016/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 1017/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0109\n",
      "Epoch 1018/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0103\n",
      "Epoch 1019/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0101\n",
      "Epoch 1020/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0106\n",
      "Epoch 1021/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0098\n",
      "Epoch 1022/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0101\n",
      "Epoch 1023/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 1024/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 1025/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0118\n",
      "Epoch 1026/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 1027/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0104\n",
      "Epoch 1028/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0100\n",
      "Epoch 1029/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 1030/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 1031/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 1032/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0102\n",
      "Epoch 1033/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 1034/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 1035/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 1036/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 1037/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0107\n",
      "Epoch 1038/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0106\n",
      "Epoch 1039/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 1040/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0117\n",
      "Epoch 1041/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 1042/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0107\n",
      "Epoch 1043/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 1044/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 1045/10000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.009 - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 1046/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 1047/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0099\n",
      "Epoch 1048/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0114\n",
      "Epoch 1049/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0100\n",
      "Epoch 1050/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 1051/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0104\n",
      "Epoch 1052/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0100\n",
      "Epoch 1053/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 1054/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0109\n",
      "Epoch 1055/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1056/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 1057/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0101\n",
      "Epoch 1058/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 1059/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0098\n",
      "Epoch 1060/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0111\n",
      "Epoch 1061/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0100\n",
      "Epoch 1062/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0102\n",
      "Epoch 1063/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 1064/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 1065/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0099\n",
      "Epoch 1066/10000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.009 - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 1067/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0109\n",
      "Epoch 1068/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0101\n",
      "Epoch 1069/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 1070/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 1071/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 1072/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0102\n",
      "Epoch 1073/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 1074/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0106\n",
      "Epoch 1075/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 1076/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0100\n",
      "Epoch 1077/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 1078/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0105\n",
      "Epoch 1079/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 1080/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 1081/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0099\n",
      "Epoch 1082/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0100\n",
      "Epoch 1083/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 1084/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0100\n",
      "Epoch 1085/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 1086/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 1087/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 1088/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 1089/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0113\n",
      "Epoch 1090/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 1091/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 1092/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0100\n",
      "Epoch 1093/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 1094/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0113\n",
      "Epoch 1095/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0100\n",
      "Epoch 1096/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0099\n",
      "Epoch 1097/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0099\n",
      "Epoch 1098/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0097\n",
      "Epoch 1099/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 1100/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0108\n",
      "Epoch 1101/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 1102/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 1103/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0118\n",
      "Epoch 1104/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0102\n",
      "Epoch 1105/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0103\n",
      "Epoch 1106/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 1107/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0100\n",
      "Epoch 1108/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0122\n",
      "Epoch 1109/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0100\n",
      "Epoch 1110/10000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.008 - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0111\n",
      "Epoch 1111/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 1112/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 1113/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 1114/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0099\n",
      "Epoch 1115/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 1116/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0097\n",
      "Epoch 1117/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0110\n",
      "Epoch 1118/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 1119/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 1120/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0099\n",
      "Epoch 1121/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 1122/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0099\n",
      "Epoch 1123/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0097\n",
      "Epoch 1124/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 1125/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0102\n",
      "Epoch 1126/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0100\n",
      "Epoch 1127/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0100\n",
      "Epoch 1128/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0174\n",
      "Epoch 1129/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0104\n",
      "Epoch 1130/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 1131/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 1132/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 1133/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 1134/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 1135/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 1136/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0098\n",
      "Epoch 1137/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 1138/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0104\n",
      "Epoch 1139/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 1140/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0098\n",
      "Epoch 1141/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 1142/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0104\n",
      "Epoch 1143/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 1144/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0099\n",
      "Epoch 1145/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0102\n",
      "Epoch 1146/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0099\n",
      "Epoch 1147/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0107\n",
      "Epoch 1148/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0098\n",
      "Epoch 1149/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0102\n",
      "Epoch 1150/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 1151/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 1152/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 1153/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0100\n",
      "Epoch 1154/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 1155/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 1156/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 1157/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0098\n",
      "Epoch 1158/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0106\n",
      "Epoch 1159/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0098\n",
      "Epoch 1160/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 1161/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0101\n",
      "Epoch 1162/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 1163/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 1164/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0100\n",
      "Epoch 1165/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 1166/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 1167/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 1168/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 1169/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 1170/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 1171/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0123\n",
      "Epoch 1172/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0103\n",
      "Epoch 1173/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0112\n",
      "Epoch 1174/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 1175/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0097\n",
      "Epoch 1176/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0109\n",
      "Epoch 1177/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0097\n",
      "Epoch 1178/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0104\n",
      "Epoch 1179/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0101\n",
      "Epoch 1180/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 1181/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0096\n",
      "Epoch 1182/10000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.009 - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0110\n",
      "Epoch 1183/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0117\n",
      "Epoch 1184/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0100\n",
      "Epoch 1185/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0098\n",
      "Epoch 1186/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0100\n",
      "Epoch 1187/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 1188/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 1189/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 1190/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0100\n",
      "Epoch 1191/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0124\n",
      "Epoch 1192/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0112\n",
      "Epoch 1193/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0109\n",
      "Epoch 1194/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 1195/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0115\n",
      "Epoch 1196/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0109\n",
      "Epoch 1197/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0099\n",
      "Epoch 1198/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 1199/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0100\n",
      "Epoch 1200/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 1201/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0099\n",
      "Epoch 1202/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 1203/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0102\n",
      "Epoch 1204/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0100\n",
      "Epoch 1205/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0098\n",
      "Epoch 1206/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 1207/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 1208/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0098\n",
      "Epoch 1209/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0098\n",
      "Epoch 1210/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 1211/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 1212/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0114\n",
      "Epoch 1213/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0099\n",
      "Epoch 1214/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0097\n",
      "Epoch 1215/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 1216/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0098\n",
      "Epoch 1217/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0098\n",
      "Epoch 1218/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0097\n",
      "Epoch 1219/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 1220/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 1221/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 1222/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0098\n",
      "Epoch 1223/10000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.009 - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 1224/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0099\n",
      "Epoch 1225/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 1226/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 1227/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0121\n",
      "Epoch 1228/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 1229/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 1230/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0112\n",
      "Epoch 1231/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 1232/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 1233/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 1234/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0096\n",
      "Epoch 1235/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0096\n",
      "Epoch 1236/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 1237/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0097\n",
      "Epoch 1238/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0097\n",
      "Epoch 1239/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0115\n",
      "Epoch 1240/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0104\n",
      "Epoch 1241/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0107\n",
      "Epoch 1242/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0099\n",
      "Epoch 1243/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0097\n",
      "Epoch 1244/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0111\n",
      "Epoch 1245/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 1246/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 1247/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0100\n",
      "Epoch 1248/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 1249/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 1250/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 1251/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0099\n",
      "Epoch 1252/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0112\n",
      "Epoch 1253/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 1254/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0100\n",
      "Epoch 1255/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 1256/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0096\n",
      "Epoch 1257/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 1258/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0100\n",
      "Epoch 1259/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 1260/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0100\n",
      "Epoch 1261/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0099\n",
      "Epoch 1262/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 1263/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 1264/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0106\n",
      "Epoch 1265/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0107\n",
      "Epoch 1266/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 1267/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0110\n",
      "Epoch 1268/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0100\n",
      "Epoch 1269/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0100\n",
      "Epoch 1270/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0097\n",
      "Epoch 1271/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 1272/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 1273/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 1274/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0110\n",
      "Epoch 1275/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0118\n",
      "Epoch 1276/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0100\n",
      "Epoch 1277/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 1278/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 1279/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0107\n",
      "Epoch 1280/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0097\n",
      "Epoch 1281/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0099\n",
      "Epoch 1282/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0110\n",
      "Epoch 1283/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0122\n",
      "Epoch 1284/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0108\n",
      "Epoch 1285/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 1286/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 1287/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 1288/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0099\n",
      "Epoch 1289/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 1290/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0099\n",
      "Epoch 1291/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 1292/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0096\n",
      "Epoch 1293/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0100\n",
      "Epoch 1294/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0106\n",
      "Epoch 1295/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 1296/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0096\n",
      "Epoch 1297/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 1298/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0096\n",
      "Epoch 1299/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0097\n",
      "Epoch 1300/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0104\n",
      "Epoch 1301/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0112\n",
      "Epoch 1302/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 1303/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 1304/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0096\n",
      "Epoch 1305/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 1306/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 1307/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 1308/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 1309/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0096\n",
      "Epoch 1310/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 1311/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 1312/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0096\n",
      "Epoch 1313/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0096\n",
      "Epoch 1314/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0113\n",
      "Epoch 1315/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0098\n",
      "Epoch 1316/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 1317/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 1318/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 1319/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 1320/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0098\n",
      "Epoch 1321/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0097\n",
      "Epoch 1322/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0126\n",
      "Epoch 1323/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0107\n",
      "Epoch 1324/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0101\n",
      "Epoch 1325/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 1326/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0098\n",
      "Epoch 1327/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 1328/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 1329/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0109\n",
      "Epoch 1330/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0103\n",
      "Epoch 1331/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 1332/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0100\n",
      "Epoch 1333/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 1334/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0097\n",
      "Epoch 01334: early stopping\n",
      "Epoch 1/10000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3143 - val_loss: 0.0395\n",
      "Epoch 2/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0921 - val_loss: 0.0307\n",
      "Epoch 3/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0702 - val_loss: 0.0217\n",
      "Epoch 4/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0168\n",
      "Epoch 5/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0514 - val_loss: 0.0183\n",
      "Epoch 6/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0427 - val_loss: 0.0152\n",
      "Epoch 7/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0365 - val_loss: 0.0211\n",
      "Epoch 8/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0346 - val_loss: 0.0141\n",
      "Epoch 9/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0299 - val_loss: 0.0145\n",
      "Epoch 10/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.0128\n",
      "Epoch 11/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0250 - val_loss: 0.0134\n",
      "Epoch 12/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.0120\n",
      "Epoch 13/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.0118\n",
      "Epoch 14/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.0129\n",
      "Epoch 15/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0122\n",
      "Epoch 16/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0126\n",
      "Epoch 17/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0121\n",
      "Epoch 18/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0121\n",
      "Epoch 19/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0114\n",
      "Epoch 20/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0112\n",
      "Epoch 21/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0116\n",
      "Epoch 22/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0106\n",
      "Epoch 23/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0101\n",
      "Epoch 24/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0105\n",
      "Epoch 25/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0093\n",
      "Epoch 26/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0091\n",
      "Epoch 27/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0090\n",
      "Epoch 28/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0088\n",
      "Epoch 29/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0088\n",
      "Epoch 30/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0086\n",
      "Epoch 31/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0087\n",
      "Epoch 32/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0089\n",
      "Epoch 33/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0085\n",
      "Epoch 34/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0086\n",
      "Epoch 35/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0084\n",
      "Epoch 36/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 37/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0089\n",
      "Epoch 38/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0088\n",
      "Epoch 39/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0087\n",
      "Epoch 40/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0087\n",
      "Epoch 41/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0089\n",
      "Epoch 42/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0093\n",
      "Epoch 43/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0096\n",
      "Epoch 44/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0092\n",
      "Epoch 45/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0086\n",
      "Epoch 46/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0089\n",
      "Epoch 47/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0085\n",
      "Epoch 48/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0085\n",
      "Epoch 49/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0084\n",
      "Epoch 50/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0084\n",
      "Epoch 51/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0084\n",
      "Epoch 52/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0087\n",
      "Epoch 53/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0086\n",
      "Epoch 54/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0088\n",
      "Epoch 55/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 56/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0086\n",
      "Epoch 57/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0084\n",
      "Epoch 58/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0089\n",
      "Epoch 59/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0085\n",
      "Epoch 60/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0085\n",
      "Epoch 61/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0089\n",
      "Epoch 62/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0096\n",
      "Epoch 63/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0084\n",
      "Epoch 64/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0092\n",
      "Epoch 65/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0085\n",
      "Epoch 66/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0083\n",
      "Epoch 67/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0082\n",
      "Epoch 68/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0091\n",
      "Epoch 69/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0084\n",
      "Epoch 70/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0083\n",
      "Epoch 71/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0083\n",
      "Epoch 72/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0089\n",
      "Epoch 73/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0084\n",
      "Epoch 74/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0084\n",
      "Epoch 75/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0082\n",
      "Epoch 76/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0083\n",
      "Epoch 77/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0083\n",
      "Epoch 78/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0083\n",
      "Epoch 79/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0088\n",
      "Epoch 80/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0084\n",
      "Epoch 81/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 82/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0085\n",
      "Epoch 83/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0086\n",
      "Epoch 84/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0084\n",
      "Epoch 85/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0089\n",
      "Epoch 86/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0088\n",
      "Epoch 87/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0112\n",
      "Epoch 88/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0106\n",
      "Epoch 89/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0083\n",
      "Epoch 90/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0084\n",
      "Epoch 91/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0083\n",
      "Epoch 92/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 93/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0082\n",
      "Epoch 94/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0083\n",
      "Epoch 95/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 96/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0085\n",
      "Epoch 97/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0087\n",
      "Epoch 98/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0092\n",
      "Epoch 99/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0085\n",
      "Epoch 100/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0084\n",
      "Epoch 101/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0098\n",
      "Epoch 102/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0086\n",
      "Epoch 103/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0092\n",
      "Epoch 104/10000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.010 - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0082\n",
      "Epoch 105/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0112\n",
      "Epoch 106/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0085\n",
      "Epoch 107/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0082\n",
      "Epoch 108/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0084\n",
      "Epoch 109/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0088\n",
      "Epoch 110/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0082\n",
      "Epoch 111/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0093\n",
      "Epoch 112/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0082\n",
      "Epoch 113/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0083\n",
      "Epoch 114/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0088\n",
      "Epoch 115/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0084\n",
      "Epoch 116/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0087\n",
      "Epoch 117/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0082\n",
      "Epoch 118/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0087\n",
      "Epoch 119/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0085\n",
      "Epoch 120/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0090\n",
      "Epoch 121/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0084\n",
      "Epoch 122/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0086\n",
      "Epoch 123/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0092\n",
      "Epoch 124/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0099\n",
      "Epoch 125/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0085\n",
      "Epoch 126/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0083\n",
      "Epoch 127/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0091\n",
      "Epoch 128/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0084\n",
      "Epoch 129/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0085\n",
      "Epoch 130/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0085\n",
      "Epoch 131/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0085\n",
      "Epoch 132/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0082\n",
      "Epoch 133/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0093\n",
      "Epoch 134/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0087\n",
      "Epoch 135/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0084\n",
      "Epoch 136/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0085\n",
      "Epoch 137/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0083\n",
      "Epoch 138/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0084\n",
      "Epoch 139/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0083\n",
      "Epoch 140/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0092\n",
      "Epoch 141/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0086\n",
      "Epoch 142/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0083\n",
      "Epoch 143/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0085\n",
      "Epoch 144/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0083\n",
      "Epoch 145/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0090\n",
      "Epoch 146/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0082\n",
      "Epoch 147/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0089\n",
      "Epoch 148/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0082\n",
      "Epoch 149/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0086\n",
      "Epoch 150/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0097\n",
      "Epoch 151/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0083\n",
      "Epoch 152/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0083\n",
      "Epoch 153/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0091\n",
      "Epoch 154/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0087\n",
      "Epoch 155/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0090\n",
      "Epoch 156/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0103\n",
      "Epoch 157/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0085\n",
      "Epoch 158/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0083\n",
      "Epoch 159/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0098\n",
      "Epoch 160/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0085\n",
      "Epoch 161/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0100\n",
      "Epoch 162/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0088\n",
      "Epoch 163/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0085\n",
      "Epoch 164/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0086\n",
      "Epoch 165/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0089\n",
      "Epoch 166/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0087\n",
      "Epoch 167/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0084\n",
      "Epoch 168/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0093\n",
      "Epoch 169/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0086\n",
      "Epoch 170/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0085\n",
      "Epoch 171/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0084\n",
      "Epoch 172/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0088\n",
      "Epoch 173/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0096\n",
      "Epoch 174/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0086\n",
      "Epoch 175/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0091\n",
      "Epoch 00175: early stopping\n",
      "Epoch 1/10000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3315 - val_loss: 0.0380\n",
      "Epoch 2/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0897 - val_loss: 0.0220\n",
      "Epoch 3/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0653 - val_loss: 0.0184\n",
      "Epoch 4/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0526 - val_loss: 0.0475\n",
      "Epoch 5/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0504 - val_loss: 0.0167\n",
      "Epoch 6/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0393 - val_loss: 0.0220\n",
      "Epoch 7/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0359 - val_loss: 0.0134\n",
      "Epoch 8/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0309 - val_loss: 0.0208\n",
      "Epoch 9/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.0122\n",
      "Epoch 10/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.0106\n",
      "Epoch 11/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.0104\n",
      "Epoch 12/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0119\n",
      "Epoch 13/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0090\n",
      "Epoch 14/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0094\n",
      "Epoch 15/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0090\n",
      "Epoch 16/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0084\n",
      "Epoch 17/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0087\n",
      "Epoch 18/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0095\n",
      "Epoch 19/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0089\n",
      "Epoch 20/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0084\n",
      "Epoch 21/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0081\n",
      "Epoch 22/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0083\n",
      "Epoch 23/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0076\n",
      "Epoch 24/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0088\n",
      "Epoch 25/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0079\n",
      "Epoch 26/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0073\n",
      "Epoch 27/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0071\n",
      "Epoch 28/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0067\n",
      "Epoch 29/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0070\n",
      "Epoch 30/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0074\n",
      "Epoch 31/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0066\n",
      "Epoch 32/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0066\n",
      "Epoch 33/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0068\n",
      "Epoch 34/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0065\n",
      "Epoch 35/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0069\n",
      "Epoch 36/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0069\n",
      "Epoch 37/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0069\n",
      "Epoch 38/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0063\n",
      "Epoch 39/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0065\n",
      "Epoch 40/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0067\n",
      "Epoch 41/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0064\n",
      "Epoch 42/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0076\n",
      "Epoch 43/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0073\n",
      "Epoch 44/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0067\n",
      "Epoch 45/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0069\n",
      "Epoch 46/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0065\n",
      "Epoch 47/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0075\n",
      "Epoch 48/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0068\n",
      "Epoch 49/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0066\n",
      "Epoch 50/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0066\n",
      "Epoch 51/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0066\n",
      "Epoch 52/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0066\n",
      "Epoch 53/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0071\n",
      "Epoch 54/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0081\n",
      "Epoch 55/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0068\n",
      "Epoch 56/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0067\n",
      "Epoch 57/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0072\n",
      "Epoch 58/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0066\n",
      "Epoch 59/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0067\n",
      "Epoch 60/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0081\n",
      "Epoch 61/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0066\n",
      "Epoch 62/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0065\n",
      "Epoch 63/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0069\n",
      "Epoch 64/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0072\n",
      "Epoch 65/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0066\n",
      "Epoch 66/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0066\n",
      "Epoch 67/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0066\n",
      "Epoch 68/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0064\n",
      "Epoch 69/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0065\n",
      "Epoch 70/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0067\n",
      "Epoch 71/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0070\n",
      "Epoch 72/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0063\n",
      "Epoch 73/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0119\n",
      "Epoch 74/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0080\n",
      "Epoch 75/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0081\n",
      "Epoch 76/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0068\n",
      "Epoch 77/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0065\n",
      "Epoch 78/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0064\n",
      "Epoch 79/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0071\n",
      "Epoch 80/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0110\n",
      "Epoch 81/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0099\n",
      "Epoch 82/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0074\n",
      "Epoch 83/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0070\n",
      "Epoch 84/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0078\n",
      "Epoch 85/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0067\n",
      "Epoch 86/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0066\n",
      "Epoch 87/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0066\n",
      "Epoch 88/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0069\n",
      "Epoch 89/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0069\n",
      "Epoch 90/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0078\n",
      "Epoch 91/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0068\n",
      "Epoch 92/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 93/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0067\n",
      "Epoch 94/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0066\n",
      "Epoch 95/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0068\n",
      "Epoch 96/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0065\n",
      "Epoch 97/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0096\n",
      "Epoch 98/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0071\n",
      "Epoch 99/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0068\n",
      "Epoch 100/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0067\n",
      "Epoch 101/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0068\n",
      "Epoch 102/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0075\n",
      "Epoch 103/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0065\n",
      "Epoch 104/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0065\n",
      "Epoch 105/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0067\n",
      "Epoch 106/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0066\n",
      "Epoch 107/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0067\n",
      "Epoch 108/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0064\n",
      "Epoch 109/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0066\n",
      "Epoch 110/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0081\n",
      "Epoch 111/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0070\n",
      "Epoch 112/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0067\n",
      "Epoch 113/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0069\n",
      "Epoch 114/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0069\n",
      "Epoch 115/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0071\n",
      "Epoch 116/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0082\n",
      "Epoch 117/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0071\n",
      "Epoch 118/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0066\n",
      "Epoch 119/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0065\n",
      "Epoch 120/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0068\n",
      "Epoch 121/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0067\n",
      "Epoch 122/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0067\n",
      "Epoch 123/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0070\n",
      "Epoch 124/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0070\n",
      "Epoch 125/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0068\n",
      "Epoch 126/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0078\n",
      "Epoch 127/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0070\n",
      "Epoch 128/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0099\n",
      "Epoch 129/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0080\n",
      "Epoch 130/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0080\n",
      "Epoch 131/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0069\n",
      "Epoch 132/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0070\n",
      "Epoch 133/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0085\n",
      "Epoch 134/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0081\n",
      "Epoch 135/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0068\n",
      "Epoch 136/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0079\n",
      "Epoch 137/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0073\n",
      "Epoch 138/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0066\n",
      "Epoch 139/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0070\n",
      "Epoch 140/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0069\n",
      "Epoch 141/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0072\n",
      "Epoch 142/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0067\n",
      "Epoch 143/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0067\n",
      "Epoch 144/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0075\n",
      "Epoch 145/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0071\n",
      "Epoch 146/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0069\n",
      "Epoch 147/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0069\n",
      "Epoch 148/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0078\n",
      "Epoch 149/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0070\n",
      "Epoch 150/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0072\n",
      "Epoch 151/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0082\n",
      "Epoch 152/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0068\n",
      "Epoch 153/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0070\n",
      "Epoch 154/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0086\n",
      "Epoch 155/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0075\n",
      "Epoch 156/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0072\n",
      "Epoch 157/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0068\n",
      "Epoch 158/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0081\n",
      "Epoch 159/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0072\n",
      "Epoch 160/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0073\n",
      "Epoch 161/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0069\n",
      "Epoch 162/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0074\n",
      "Epoch 163/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0072\n",
      "Epoch 164/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0070\n",
      "Epoch 165/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0075\n",
      "Epoch 166/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0069\n",
      "Epoch 167/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0072\n",
      "Epoch 168/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0069\n",
      "Epoch 169/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0072\n",
      "Epoch 170/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0071\n",
      "Epoch 171/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0072\n",
      "Epoch 172/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0076\n",
      "Epoch 00172: early stopping\n",
      "Epoch 1/10000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2980 - val_loss: 0.0417\n",
      "Epoch 2/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0934 - val_loss: 0.0287\n",
      "Epoch 3/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0692 - val_loss: 0.0185\n",
      "Epoch 4/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0542 - val_loss: 0.0185\n",
      "Epoch 5/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0441 - val_loss: 0.0183\n",
      "Epoch 6/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0386 - val_loss: 0.0187\n",
      "Epoch 7/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0346 - val_loss: 0.0275\n",
      "Epoch 8/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0313 - val_loss: 0.0123\n",
      "Epoch 9/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0256 - val_loss: 0.0099\n",
      "Epoch 10/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.0101\n",
      "Epoch 11/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0102\n",
      "Epoch 12/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0092\n",
      "Epoch 13/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0090\n",
      "Epoch 14/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0083\n",
      "Epoch 15/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0088\n",
      "Epoch 16/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0087\n",
      "Epoch 17/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0080\n",
      "Epoch 18/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0077\n",
      "Epoch 19/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0076\n",
      "Epoch 20/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0068\n",
      "Epoch 21/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0070\n",
      "Epoch 22/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0067\n",
      "Epoch 23/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0070\n",
      "Epoch 24/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0076\n",
      "Epoch 25/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0063\n",
      "Epoch 26/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0059\n",
      "Epoch 27/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0057\n",
      "Epoch 28/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0054\n",
      "Epoch 29/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0056\n",
      "Epoch 30/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0066\n",
      "Epoch 31/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0056\n",
      "Epoch 32/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0052\n",
      "Epoch 33/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0059\n",
      "Epoch 34/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 35/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0052\n",
      "Epoch 36/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0060\n",
      "Epoch 37/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0054\n",
      "Epoch 38/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0054\n",
      "Epoch 39/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0072\n",
      "Epoch 40/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0054\n",
      "Epoch 41/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0055\n",
      "Epoch 42/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0052\n",
      "Epoch 43/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0053\n",
      "Epoch 44/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0052\n",
      "Epoch 45/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0052\n",
      "Epoch 46/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0056\n",
      "Epoch 47/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0051\n",
      "Epoch 48/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0053\n",
      "Epoch 49/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0051\n",
      "Epoch 50/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0071\n",
      "Epoch 51/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0051\n",
      "Epoch 52/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0057\n",
      "Epoch 53/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0056\n",
      "Epoch 54/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0050\n",
      "Epoch 55/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0059\n",
      "Epoch 56/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0050\n",
      "Epoch 57/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0054\n",
      "Epoch 58/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0052\n",
      "Epoch 59/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0054\n",
      "Epoch 60/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0050\n",
      "Epoch 61/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0055\n",
      "Epoch 62/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0050\n",
      "Epoch 63/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0051\n",
      "Epoch 64/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0049\n",
      "Epoch 65/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0050\n",
      "Epoch 66/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0056\n",
      "Epoch 67/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0056\n",
      "Epoch 68/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0052\n",
      "Epoch 69/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0049\n",
      "Epoch 70/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0053\n",
      "Epoch 71/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0053\n",
      "Epoch 72/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0055\n",
      "Epoch 73/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0051\n",
      "Epoch 74/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0054\n",
      "Epoch 75/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0053\n",
      "Epoch 76/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0055\n",
      "Epoch 77/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0053\n",
      "Epoch 78/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0059\n",
      "Epoch 79/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0050\n",
      "Epoch 80/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0050\n",
      "Epoch 81/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0054\n",
      "Epoch 82/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0053\n",
      "Epoch 83/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0054\n",
      "Epoch 84/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0048\n",
      "Epoch 85/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0066\n",
      "Epoch 86/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0052\n",
      "Epoch 87/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0053\n",
      "Epoch 88/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0058\n",
      "Epoch 89/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0055\n",
      "Epoch 90/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0049\n",
      "Epoch 91/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0057\n",
      "Epoch 92/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0052\n",
      "Epoch 93/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0048\n",
      "Epoch 94/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0054\n",
      "Epoch 95/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0052\n",
      "Epoch 96/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0050\n",
      "Epoch 97/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0062\n",
      "Epoch 98/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0051\n",
      "Epoch 99/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0048\n",
      "Epoch 100/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0052\n",
      "Epoch 101/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0053\n",
      "Epoch 102/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 103/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0051\n",
      "Epoch 104/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0068\n",
      "Epoch 105/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0075\n",
      "Epoch 106/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0059\n",
      "Epoch 107/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0051\n",
      "Epoch 108/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0048\n",
      "Epoch 109/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0050\n",
      "Epoch 110/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0052\n",
      "Epoch 111/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 112/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0051\n",
      "Epoch 113/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0052\n",
      "Epoch 114/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 115/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0052\n",
      "Epoch 116/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0054\n",
      "Epoch 117/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0051\n",
      "Epoch 118/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0049\n",
      "Epoch 119/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 120/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 121/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0050\n",
      "Epoch 122/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 123/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0057\n",
      "Epoch 124/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 125/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0048\n",
      "Epoch 126/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 127/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0049\n",
      "Epoch 128/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0050\n",
      "Epoch 129/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0052\n",
      "Epoch 130/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0055\n",
      "Epoch 131/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 132/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0064\n",
      "Epoch 133/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0056\n",
      "Epoch 134/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0057\n",
      "Epoch 135/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 136/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 137/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0049\n",
      "Epoch 138/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 139/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 140/10000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.006 - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0055\n",
      "Epoch 141/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0053\n",
      "Epoch 142/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 143/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0056\n",
      "Epoch 144/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0049\n",
      "Epoch 145/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 146/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 147/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 148/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0051\n",
      "Epoch 149/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0062\n",
      "Epoch 150/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 151/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 152/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 153/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0059\n",
      "Epoch 154/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 155/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0050\n",
      "Epoch 156/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0055\n",
      "Epoch 157/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0063\n",
      "Epoch 158/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0055\n",
      "Epoch 159/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0054\n",
      "Epoch 160/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0050\n",
      "Epoch 161/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0052\n",
      "Epoch 162/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0051\n",
      "Epoch 163/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 164/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0050\n",
      "Epoch 165/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0050\n",
      "Epoch 166/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0057\n",
      "Epoch 167/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0051\n",
      "Epoch 168/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0068\n",
      "Epoch 169/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0056\n",
      "Epoch 170/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0056\n",
      "Epoch 171/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 172/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 173/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 174/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0052\n",
      "Epoch 175/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0056\n",
      "Epoch 176/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0067\n",
      "Epoch 177/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 178/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0054\n",
      "Epoch 179/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 180/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0055\n",
      "Epoch 181/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 182/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0054\n",
      "Epoch 183/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0050\n",
      "Epoch 184/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 185/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 186/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 187/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 188/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0055\n",
      "Epoch 189/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0051\n",
      "Epoch 190/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 191/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0052\n",
      "Epoch 192/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 193/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 194/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 195/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 196/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 197/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0056\n",
      "Epoch 198/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0065\n",
      "Epoch 199/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 200/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0052\n",
      "Epoch 201/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 202/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 203/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0055\n",
      "Epoch 204/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0050\n",
      "Epoch 205/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 206/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 207/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 208/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 209/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 210/10000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.006 - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0051\n",
      "Epoch 211/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0059\n",
      "Epoch 212/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0057\n",
      "Epoch 213/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 214/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0101\n",
      "Epoch 215/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0053\n",
      "Epoch 216/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 217/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0055\n",
      "Epoch 218/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 219/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 220/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 221/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 222/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 223/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 224/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 225/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 00225: early stopping\n",
      "Epoch 1/10000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2782 - val_loss: 0.0409\n",
      "Epoch 2/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0900 - val_loss: 0.0226\n",
      "Epoch 3/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0622 - val_loss: 0.0183\n",
      "Epoch 4/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0495 - val_loss: 0.0217\n",
      "Epoch 5/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0412 - val_loss: 0.0140\n",
      "Epoch 6/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0360 - val_loss: 0.0157\n",
      "Epoch 7/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0324 - val_loss: 0.0130\n",
      "Epoch 8/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0301 - val_loss: 0.0100\n",
      "Epoch 9/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0253 - val_loss: 0.0092\n",
      "Epoch 10/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0094\n",
      "Epoch 11/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.0086\n",
      "Epoch 12/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0075\n",
      "Epoch 13/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0070\n",
      "Epoch 14/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0070\n",
      "Epoch 15/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0074\n",
      "Epoch 16/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0059\n",
      "Epoch 17/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0067\n",
      "Epoch 18/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0062\n",
      "Epoch 19/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0056\n",
      "Epoch 20/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0059\n",
      "Epoch 21/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0063\n",
      "Epoch 22/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0053\n",
      "Epoch 23/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0060\n",
      "Epoch 24/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0054\n",
      "Epoch 25/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0056\n",
      "Epoch 26/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0053\n",
      "Epoch 27/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0052\n",
      "Epoch 28/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0055\n",
      "Epoch 29/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0054\n",
      "Epoch 30/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0054\n",
      "Epoch 31/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0053\n",
      "Epoch 32/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0051\n",
      "Epoch 33/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0051\n",
      "Epoch 34/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0054\n",
      "Epoch 35/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0056\n",
      "Epoch 36/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0056\n",
      "Epoch 37/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0054\n",
      "Epoch 38/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0053\n",
      "Epoch 39/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0052\n",
      "Epoch 40/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0049\n",
      "Epoch 41/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0054\n",
      "Epoch 42/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0049\n",
      "Epoch 43/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0049\n",
      "Epoch 44/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0047\n",
      "Epoch 45/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0044\n",
      "Epoch 46/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0042\n",
      "Epoch 47/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0045\n",
      "Epoch 48/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 49/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0048\n",
      "Epoch 50/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0046\n",
      "Epoch 51/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0044\n",
      "Epoch 52/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0047\n",
      "Epoch 53/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0043\n",
      "Epoch 54/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0063\n",
      "Epoch 55/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0042\n",
      "Epoch 56/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0047\n",
      "Epoch 57/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0058\n",
      "Epoch 58/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0048\n",
      "Epoch 59/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0045\n",
      "Epoch 60/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0043\n",
      "Epoch 61/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0051\n",
      "Epoch 62/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0044\n",
      "Epoch 63/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0042\n",
      "Epoch 64/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0047\n",
      "Epoch 65/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0042\n",
      "Epoch 66/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0048\n",
      "Epoch 67/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0041\n",
      "Epoch 68/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0045\n",
      "Epoch 69/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0044\n",
      "Epoch 70/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0043\n",
      "Epoch 71/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0045\n",
      "Epoch 72/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0041\n",
      "Epoch 73/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0041\n",
      "Epoch 74/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0042\n",
      "Epoch 75/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0046\n",
      "Epoch 76/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0042\n",
      "Epoch 77/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0041\n",
      "Epoch 78/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0041\n",
      "Epoch 79/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0043\n",
      "Epoch 80/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0043\n",
      "Epoch 81/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0042\n",
      "Epoch 82/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0043\n",
      "Epoch 83/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0046\n",
      "Epoch 84/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0043\n",
      "Epoch 85/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0043\n",
      "Epoch 86/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0044\n",
      "Epoch 87/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0041\n",
      "Epoch 88/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0049\n",
      "Epoch 89/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0048\n",
      "Epoch 90/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0046\n",
      "Epoch 91/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0045\n",
      "Epoch 92/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0041\n",
      "Epoch 93/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0043\n",
      "Epoch 94/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 95/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0073\n",
      "Epoch 96/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0047\n",
      "Epoch 97/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0059\n",
      "Epoch 98/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0044\n",
      "Epoch 99/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 100/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 101/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0042\n",
      "Epoch 102/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 103/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0040\n",
      "Epoch 104/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 105/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0040\n",
      "Epoch 106/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0059\n",
      "Epoch 107/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0047\n",
      "Epoch 108/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 109/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 110/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 111/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0046\n",
      "Epoch 112/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0041\n",
      "Epoch 113/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 114/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 115/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0057\n",
      "Epoch 116/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0044\n",
      "Epoch 117/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 118/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 119/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 120/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 121/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 122/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 123/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0065\n",
      "Epoch 124/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0048\n",
      "Epoch 125/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 126/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 127/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 128/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 129/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0060\n",
      "Epoch 130/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 131/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 132/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 133/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 134/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 135/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 136/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 137/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 138/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 139/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 140/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 141/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 142/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0054\n",
      "Epoch 143/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 144/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0060\n",
      "Epoch 145/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 146/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 147/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 148/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 149/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 150/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 151/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 152/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 153/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 154/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 155/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 156/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0069\n",
      "Epoch 157/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 158/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0052\n",
      "Epoch 159/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 160/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 161/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 162/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 163/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0076\n",
      "Epoch 164/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 165/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 166/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0061\n",
      "Epoch 167/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 168/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0041\n",
      "Epoch 169/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0060\n",
      "Epoch 170/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 171/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 172/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 173/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 174/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 175/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0043\n",
      "Epoch 176/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 177/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 178/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 179/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 180/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 181/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 182/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 183/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 184/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 185/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 186/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 187/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0078\n",
      "Epoch 188/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0047\n",
      "Epoch 189/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 190/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 191/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 192/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 193/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 194/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 195/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 196/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 197/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 198/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 199/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 200/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 201/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 202/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 203/10000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 00203: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make architectural choices\n",
    "# The architecture choices below represent our suggestions -- but\n",
    "# feel free to change these\n",
    "h_nodes = [25, 50, 100, 200] # number of nodes per hidden layer\n",
    "bn_nodes = [1, 2, 3, 4, 5, 6] # number of bottleneck layer nodes\n",
    "h_layers = [2] # number of hidden layers\n",
    "patience_st = 50 # patience for early stopping. We suggeset between 25-250,\n",
    "# with smaller patiences being used for larger data sets\n",
    "patience_co = 100\n",
    "\n",
    "# Train structural and compositional autoencoders\n",
    "core.train_autoencoders(x_train_st, \n",
    "                        x_val_st, \n",
    "                        x_test_st, \n",
    "                        h_nodes, \n",
    "                        bn_nodes, \n",
    "                        h_layers, \n",
    "                        patience_st, \n",
    "                        mother_dir)\n",
    "\n",
    "core.train_autoencoders(x_train_co, \n",
    "                        x_val_co, \n",
    "                        x_test_co, \n",
    "                        h_nodes, \n",
    "                        bn_nodes, \n",
    "                        h_layers, \n",
    "                        patience_co, \n",
    "                        mother_dir)\n",
    "   \n",
    "\n",
    "# Create elbow plots -- only options for model type are \"struct\" and \"comp\"\n",
    "core.create_elbow(mother_dir, \n",
    "                  model_type = \"struct\")\n",
    "\n",
    "core.create_elbow(mother_dir, \n",
    "                  model_type = \"comp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make final autoencoder architectural choices\n",
    "\n",
    "After examining the elbow plots, choose the \"final\" architectural choices for both the structural and compositional autoencoders below. Note that the \"encoders\" are extracted from the \"autoencoders\" for dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make final architectural choices for structrual autoencoder\n",
    "hn_st = 50 # number of nodes per hidden layer\n",
    "bn_st = 3 # number of bottleneck layer nodes\n",
    "hl_st = 2 # number of hidden layers\n",
    "\n",
    "# Make final architectural choices for compositional autoencoder\n",
    "hn_co = 50 # number of nodes per hidden layer\n",
    "bn_co = 3 # number of bottleneck layer nodes\n",
    "hl_co = 2 # number of hidden layers\n",
    "\n",
    "# Load chosen structural and compositional encoders (and directories\n",
    "# in which these encoders are saved)\n",
    "[enc_st, \n",
    " enc_dir_st] = core.get_encoder(hn_st, \n",
    "                                bn_st, \n",
    "                                hl_st, \n",
    "                                mother_dir, \n",
    "                                model_type = \"struct\")\n",
    "[enc_co, \n",
    " enc_dir_co] = core.get_encoder(hn_co, \n",
    "                                bn_co, \n",
    "                                hl_co, \n",
    "                                mother_dir, \n",
    "                                model_type = \"comp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce dimensionality of the neighborhood graphs using the  models\n",
    "\n",
    "Now that the encoder models are chosen, the dimensionality of the unique neighborhood graphs and the neighborhood graphs corresponding to each particle in each .xyz/.gdv file is reduced. \n",
    "\n",
    "**Note** All results are saved under the folder of the appropriate autoencoder architecture (i.e., mother_dir/Autoencoder_Struct/xx_HL_xx_Nodes/xx_OP or mother_dir/Autoencoder_Comp/xx_HL_xx_Nodes/xx_OP). This trend continues for the rest of the code blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensionality of unique neighborhood graphs\n",
    "lowd_st_unique = core.reduce_dim_uniquegdvs(enc_st, \n",
    "                                            gdv_unique_st, \n",
    "                                            min_st, \n",
    "                                            max_st, \n",
    "                                            enc_dir_st)\n",
    "\n",
    "lowd_co_unique = core.reduce_dim_uniquegdvs(enc_co, \n",
    "                                            gdv_unique_co, \n",
    "                                            min_co, \n",
    "                                            max_co, \n",
    "                                            enc_dir_co)\n",
    "\n",
    "# Reduce dimensionality of each neighborhood graph of each particle in each .xyz file\n",
    "lowd_all_st = {}\n",
    "for traj_dir in traj_dirs:\n",
    "    lowd_all_st[traj_dir] = core.reduce_dim_allgdvs(enc_st, \n",
    "                                                    min_st, \n",
    "                                                    max_st, \n",
    "                                                    traj_dir, \n",
    "                                                    enc_dir_st)\n",
    "\n",
    "lowd_all_co = {}\n",
    "for traj_dir in traj_dirs:\n",
    "    lowd_all_co[traj_dir] = core.reduce_dim_allgdvs(enc_co, \n",
    "                                                    min_co, \n",
    "                                                    max_co,\n",
    "                                                    traj_dir, \n",
    "                                                    enc_dir_co)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create cluster trees\n",
    "Agglomerative hierarchical clustering (via Ward's linkage) is next implemented to cluster the low-dimensional representations of all unique neighborhood graphs. The first step here is to create a cluster tree, which is done below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cluster trees (i.e., linkage) based on low-dimensional representations of\n",
    "# unique stuctural and compositional neighborhood graphs\n",
    "Z_st = core.calc_linkage(lowd_st_unique)\n",
    "Z_co = core.calc_linkage(lowd_co_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the \"best\" number of clusters for classification\n",
    "Because agglomerative hierarchical clustering creates a \"cluster tree\", it is important to find the \"best\" number of clusters for classification.\n",
    "\n",
    "To choose the \"best\" number of clusters, the code below plots the number of low-dimensional points (i.e., neighborhood graphs) corresponding to \"target lattices\" against the number of clusters in each branch of the resulting cluster tree. The \"best' cluster number can be chosen as the point in which the target lattice cluster sizes (qualitatively) stabilize. \n",
    "\n",
    "Here, a \"target lattice\" cluster is defined as a cluster that contains a low-dimensional coordinate that corresponds to a theoretically perfect lattice. So, a \"BCC\" cluster contains the low-dimensional representation of the theoretically perfect BCC neighborhood graph.\n",
    "\n",
    "The attached works classifiy colloidal lattices that form FCC, HCP, BCC, DCsCl, and IrV-like structures. In this code, the target choices currently available are:\n",
    "\n",
    "Structural: \"FCC\", \"HCP\", \"BCC\", \"IrVA\", \"IrVB\", \"DCsClA\", \"DCsClB\", \"Weak\"\n",
    "Compositional: \"FCC_HCP_IrVB\", \"BCC_DCsClB\", \"IrVA_DCsClA\"\n",
    "\n",
    "However, more structures can easily be added into core.py.\n",
    "\n",
    "**Note #1**: We recognize that the user's trajectory data may form BCC/FCC/HCP-like structures but not actually contain particles that have \"theoretically perfect\" lattice neighborhood graphs/low-dimensional coordinates. As a result, the target lattice cluster is defined as a cluster that contains the low-dimensional coordinate with the smallest distance to its theoretically perfect analog. For example, let's say the low-dimensional representation of the perfect BCC lattice is [1, 1, 1]<sup>T</sup>, but only [1 ,1, 1.01]<sup>T</sup> exists in the provided data. Then, [1, 1, 1.01]<sup>T</sup> will be treated as the \"perfect\" BCC coordinate.\n",
    "\n",
    "**Note #2**: We further recognize that the user may not want to choose the cluster number based on the use of target lattices. If this is the case, feel free to skip this step.\n",
    "\n",
    "**Note #3**: Notice that certain structures (e.g., FCC/HCP/IrVB) have identical compositional neighborhood graphs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose target lattices for structrual and compositional models\n",
    "target_st = [\"FCC\", \"HCP\", \"BCC\"]\n",
    "target_co = [\"FCC_HCP_IrVB\", \"BCC_DCsClB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot populations of structural and compositional target clusters versus\n",
    "# the total number of clusters in each branch of the cluster tree\n",
    "# Note that the indices of the these target clusters are also returned.\n",
    "# These indices are useful for tracking/book-keeping\n",
    "[lowd_target_st, \n",
    " target_ind_st, \n",
    " clust_count_st] = core.choose_cluster_num(enc_st,\n",
    "                                           target_st, \n",
    "                                           min_st, \n",
    "                                           max_st, \n",
    "                                           lowd_st_unique, \n",
    "                                           Z_st,\n",
    "                                           enc_dir_st, \n",
    "                                           model_type=\"struct\")\n",
    "\n",
    "\n",
    "[lowd_target_co, \n",
    " target_ind_co, \n",
    " clust_count_co] = core.choose_cluster_num(enc_co,\n",
    "                                           target_co, \n",
    "                                           min_co, \n",
    "                                           max_co, \n",
    "                                           lowd_co_unique, \n",
    "                                           Z_co,\n",
    "                                           enc_dir_co, \n",
    "                                           model_type=\"comp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster the low-dimensional spaces\n",
    "\n",
    "Based on the above plots (or not), choose the number of structural and compositonal clusters you would like to continue with. The code below then clusters these low-dimensional spaces according to this cluster number. The code even outputs associated dendograms that show the hierarchical structure of the resulting clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 5760x3240 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 5760x3240 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose number of clusters for structural and compositional spaces\n",
    "nc_st = 210\n",
    "nc_co = 180\n",
    "\n",
    "# Cluster structural and compositional low-dimensional spaces. Note that these\n",
    "# are the cluster ids of the unique neighborhood graphs\n",
    "clust_ids_st = core.cluster(lowd_st_unique, \n",
    "                            Z_st, \n",
    "                            target_ind_st, \n",
    "                            nc_st, \n",
    "                            enc_dir_st, \n",
    "                            model_type=\"struct\")\n",
    "\n",
    "clust_ids_co = core.cluster(lowd_co_unique, \n",
    "                            Z_co, target_ind_co, \n",
    "                            nc_co, \n",
    "                            enc_dir_co, \n",
    "                            model_type=\"comp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign structrual and compositional clusters to all particles in all .xyz files\n",
    "clust_ids_all_st = {}\n",
    "clust_ids_all_co = {}\n",
    "for traj_dir in traj_dirs:\n",
    "    clust_ids_all_st[traj_dir] = core.assign_clusters(lowd_st_unique, \n",
    "                                                     clust_ids_st, \n",
    "                                                     lowd_all_st[traj_dir],\n",
    "                                                     traj_dir, \n",
    "                                                     enc_dir_st)\n",
    "    \n",
    "    clust_ids_all_co[traj_dir] = core.assign_clusters(lowd_co_unique,\n",
    "                                                     clust_ids_co, \n",
    "                                                     lowd_all_co[traj_dir],\n",
    "                                                     traj_dir, \n",
    "                                                     enc_dir_co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cluster labels of target lattices for structrual and compositional models\n",
    "target_clust_st = core.get_target_clusters(clust_ids_st, \n",
    "                                           target_ind_st)\n",
    "\n",
    "target_clust_co = core.get_target_clusters(clust_ids_co, \n",
    "                                           target_ind_co)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Classification\n",
    "\n",
    "Now the structural and compositional low-dimensional spaces have been clustered, it is time to classify the particles in the XYZ files. We determine this classification based on the chosen target lattices, and structural and compositional clusters.For example, if a given particle’s structural and compositional low-dimensional representations fall under “FCC” identified clusters, the particle will be labeled as a “structurally and compositionally ordered FCC particle” (i.e., “CO-FCC”). If only the particle’s structural low-dimensional representation falls under an FCC cluster, the particle will be labeled as “structurally ordered, yet compositionally disordered FCC” (i.e., “CD-FCC”). If the particle’s low dimensional representation does not fall under any target lattice cluster, the particle is left unlabeled. These “unlabeled” particles often correspond to vapor particles, structurally defective particles, surface particles, etc. Note that we will use the \"CO\" and \"CD\" abbreviations in the next few code blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on target lattices from before, we create and assign clusters for \"CO\" and \"CD\"\n",
    "# target lattices.\n",
    "target_comb = core.get_combined_cluster_ids(target_clust_st, target_clust_co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classify all particles in all provided trajectories\n",
    "clust_ids_all_comb = {}\n",
    "for traj_dir in traj_dirs:\n",
    "    clust_ids_all_comb[traj_dir] = core.assign_clusters_combined(target_comb,\n",
    "                                                                clust_ids_all_st[traj_dir], \n",
    "                                                                clust_ids_all_co[traj_dir], \n",
    "                                                                traj_dir, \n",
    "                                                                enc_dir_st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OVITO Visualization and Classification\n",
    "\n",
    "The original .xyz files are re-written such that each particle is colored according to its classification. These .xyz files can be visualized in OVITO. Use the qualitative analyses from these visualizations along with the cluster tree to assign physical meaning(s) to each class.\n",
    "\n",
    "**Note** The re-written  are saved under the folder of the appropriate structural autoencoder architecture (i.e., mother_dir/Autoencoder_Struct/xx_HL_xx_Nodes/xx_OP/traj_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CO-FCC': ['Red', 238, 32, 77], 'CD-FCC': ['Light Red', 246.5, 143.5, 166.0], 'CO-HCP': ['Green', 28, 172, 120], 'CD-HCP': ['Light Green', 141.5, 213.5, 187.5], 'CO-BCC': ['Blue', 31, 117, 254], 'CD-BCC': ['Light Blue', 143.0, 186.0, 254.5]}\n"
     ]
    }
   ],
   "source": [
    "# First assign colors to combined cluster IDs. Note that this function assigns \"true\"\n",
    "# colors to \"CO\" particles, light colors to \"CD\" particles, and white to unabeled particles.\n",
    "# Feel free to modify this in the core.py file. For example, CO-FCC could be red, while CD-\n",
    "# CD-FCC would be light red. The function outputs a list of used colors (and their RGB\n",
    "# values) and their corresponding classifications.\n",
    "colors_list, colors_dict = core.assign_colors(target_comb,\n",
    "                                              mother_dir)\n",
    "\n",
    "# Print color/classification assignments for user clarity. Dictionary is also saved as\n",
    "# text file\n",
    "print (colors_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write XYZ files \n",
    "for traj_dir in traj_dirs:\n",
    "    core.create_XYZ(clust_ids_all_comb[traj_dir], \n",
    "                    colors_list, \n",
    "                    traj_dir, \n",
    "                    enc_dir_st)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
